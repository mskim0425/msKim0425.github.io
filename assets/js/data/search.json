[ { "title": "Ruby on Rails Exception 그리고 트랜잭션", "url": "/posts/exception_rails/", "categories": "Web Development, Performance Optimization", "tags": "ruby-on-rails, exception, transaction", "date": "2025-02-16 11:40:00 +0900", "snippet": "예외처리프로그램 실행중에 발생할 수 있는 예외를 처리하고 무엇보다 중단되지않도록 사용하는 기법이다. 루비에서의 예외처리 기본구조는 아래와같다.begin # 예외가 발생할 수 있는 코드rescue Exception =&gt; e # 예외가 발생했을 때 처리할 코드else # 예외가 발생하지 않았을 때 실행할 코드ensure # 항상 실행되는 코드end# 커스텀 기본적인 예외처리 구조def controller # 작동 raise '에러메시지' if problem? # 비즈니스 로직상 예외처리rescue Exception -&gt; e #작동중 에러가 터지면 여기로 작동되게 함endrescue_fromrescue_from는 Ruby on Rails에서 Controller 수준에서 예외를 처리하는 데 사용되는 메서드이다. 이 메서드는 특정 예외가 발생했을 때, 지정된 메서드나 블록을 호출하여 예외를 처리할 수 있도록 함.class ApplicationController &lt; ActionController::Base rescue_from ActiveRecord::RecordNotFound, with: :record_not_found private def record_not_found(exception) render json: { error: exception.message }, status: :not_found endend이 코드는 ActiveRecord::RecordNotFound 예외가 발생하면 record_not_found 메서드를 호출하여 JSON 응답을 반환하는 구조이다. 상속: rescue_from는 Controller 계층에서 상속된다. 즉, ApplicationController에서 정의한 예외 처리는 모든 Controller에서 자동으로 적용됨. 우선순위: 예외 처리는 정의된 순서에 따라 우선순위가 결정되고 가장 구체적인 예외 처리가 먼저 호출된다. 예외 전파: 예외 처리 메서드 내에서 또 다른 예외가 발생하면, 그 예외는 외부로 전파되지 않는다. rescue_from는 ActionController::BadRequest 예외를 처리할 수 없다.조건부 예외 처리조건부로 예외를 처리하고 싶다면, 메서드 내에서 조건문을 사용할 수 있다. 하지만 rescue_from 자체에서 조건을 지정하는 것은 불가능하다.def record_not_found(exception) if request.local? # 로컬 환경에서의 처리 else # 다른 환경에서의 처리 endendrescue_from 서비스단에서 사용가능rescue_from는 기본적으로 Controller에서만 사용할 수 있다. 하지만 ActiveSupport::Rescuable 모듈을 포함하여 다른 객체에서도 유사한 기능을 구현할 수 있다.class MyService include ActiveSupport::Rescuable rescue_from MyCustomError do |exception| # 예외 처리 코드 end def perform # 코드 endend이렇게 하면 서비스 객체에서도 rescue_from와 같은 예외 처리 DSL을 사용할 수 있다. (굳이….)트랜젝션트랜잭션은 여러 데이터베이스 작업을 하나의 논리적 단위로 묶어, 작업이 모두 성공하거나 모두 실패하는 것을 보장한다. Rails에서는 기본적으로 ActiveRecord::Base.transaction을 사용하여 트랜잭션을 구현할 수 있다.ActiveRecord::Base.transaction do # 여러 데이터베이스 작업endrequires_new새로운 독립적인 트랜잭션 생성을 하는 기능이다.해당기능의 사용 예시를 들어보자, 사용자가 결제를 진행할 때, 결제 정보는 별도의 시스템에 저장되어야한다.이때, 결제 정보 저장이 실패하더라도 메인 주문 정보는 저장되게하려고할때의 예시의 코드.class OrderController &lt; ApplicationController def create Order.transaction do # 주 주문 정보 저장 order = Order.create!(user_id: current_user.id, total: 100) # 결제 정보 저장 (독립적인 트랜잭션) Payment.transaction(requires_new: true) do Payment.create!(order_id: order.id, amount: 100) # 결제 시스템과 통신하는 코드 # 여기서 예외가 발생하면 결제 정보만 롤백 raise ActiveRecord::Rollback if payment_failed? end end end private def payment_failed? # 결제 실패 여부를 판단하는 코드 endendjoinable루비 온 레일즈에서 joinable 옵션은 트랜잭션의 중첩 방식을 제어하는 데 사용된다. joinable 옵션은 기본적으로 true로 설정되어 있으며, 내부 트랜잭션이 외부 트랜잭션에 참여할 수 있다. 반면에 joinable: false를 설정하면 내부 트랜잭션이 외부 트랜잭션과 독립적으로 동작한다.User.transaction do User.create(username: 'Minsub') # 내부 트랜잭션이 외부 트랜잭션에 참여하지 않도록 설정 User.transaction(joinable: false) do User.create(username: 'Sothoughtful') raise ActiveRecord::Rollback endend트랜잭션 전파루비 온 레일즈에서는 자바의 스프링처럼 명시적인 트랜잭션 전파 옵션이 제공되지 않는다고 한다. but requires_new 옵션을 사용하여 독립적인 트랜잭션을 생성할 수 있고, 자바의 REQUIRES_NEW 전파와 유사한 효과를 낼 수있다. 개념 루비 온 레일즈 자바 스프링 새로운 트랜잭션 생성 requires_new: true Propagation.REQUIRES_NEW 기존 트랜잭션 참여 joinable: true (기본값) Propagation.REQUIRED 옵션 트랜잭션 동작 내부 트랜잭션에서 예외 발생 시 requires_new: true 새로운 독립적인 트랜잭션 생성 외부 트랜잭션에 영향을 미치지 않음 joinable: true 기존 트랜잭션에 참여 외부 트랜잭션도 롤백됨 joinable: false 기존 트랜잭션에 참여하지 않음 (독립적인 트랜잭션 생성) 외부 트랜잭션에 영향을 미치지 않음 # requires_new 사용User.transaction do User.create(username: 'Minsub') User.transaction(requires_new: true) do User.create(username: 'Sothoughtful') raise ActiveRecord::Rollback # 외부 트랜잭션에 영향을 미치지 않음 endend# joinable: true (기본값)User.transaction do User.create(username: 'Minsub') User.transaction do User.create(username: 'Sothoughtful') raise ActiveRecord::Rollback # 외부 트랜잭션도 롤백됨 endend# joinable: falseUser.transaction do User.create(username: 'Minsub') User.transaction(joinable: false) do User.create(username: 'Sothoughtful') raise ActiveRecord::Rollback # 외부 트랜잭션에 영향을 미치지 않음 endend requires_new: 내부 트랜잭션이 외부 트랜잭션과 독립적으로 동작해야 할 때 사용joinable: false: 내부 트랜잭션이 외부 트랜잭션에 영향을 미치지 않도록 할 때 사용 requires_new 와 joinable: false 가 비슷해 보이지만, requires_new: true는 명시적으로 새로운 독립적인 트랜잭션을 생성하도록 설계된 반면, joinable: false는 기존 트랜잭션에 참여하지 않도록 설정하는 것이다." }, { "title": "Ruby on Rails 성능 최적화: 레일즈 캐싱", "url": "/posts/rails_cache/", "categories": "Web Development, Performance Optimization", "tags": "ruby-on-rails, cache, memory-management, performance-tuning, rails-optimization", "date": "2025-01-25 19:40:00 +0900", "snippet": "Rails에서 제공하는 캐싱(Caching)은 웹 애플리케이션의 성능을 향상시키기 위해 자주 사용되는 데이터나 결과를 저장하여 불필요한 데이터베이스 호출이나 복잡한 연산을 줄이는 기술이다. Rails는 다양한 캐싱 메커니즘을 제공하며, 각각의 용도와 특징이 있다.1. Page Caching페이지 캐싱은 컨트롤러 액션의 전체 HTML 출력을 정적 HTML 파일로 저장하여 처리 속도를 높이는 방식이다. 이 방식은 인증이 필요 없는 정적 페이지에 적합하다. 동적 컨텐츠에는 부적합해보인다.exclass ProductsController &lt; ActionController::Base caches_page :index def index @products = Product.all endend /products 요청 시 Rails는 public/products.html 파일을 생성하고, 이후 요청은 이 정적 파일을 반환한다. Rails 4 이후에는 actionpack-page_caching gem을 설치해야 사용 가능하다.2. Action Caching액션 캐싱은 페이지 캐싱과 유사하지만, 인증이나 필터와 같은 로직을 포함할 수 있다.exclass ProductsController &lt; ActionController::Base caches_action :show def show @product = Product.find(params[:id]) endend /products/:id 요청 시 해당 액션의 결과가 캐싱된다. 이 방식도 Rails 4 이후에는 actionpack-action_caching gem이 필요하다.3. Fragment Caching프래그먼트 캐싱은 페이지 일부(뷰 템플릿의 특정 부분)를 캐싱하는 방식으로, 동적 컨텐츠를 포함한 페이지에서 유용하다.ex: 제품 목록 캐싱&lt;% cache 'recent_products' do %&gt; &lt;ul&gt; &lt;% @products.each do |product| %&gt; &lt;li&gt;&lt;%= product.name %&gt;&lt;/li&gt; &lt;% end %&gt; &lt;/ul&gt;&lt;% end %&gt; recent_products라는 키로 HTML 조각이 캐시되며, 동일한 키를 가진 요청 시 캐시된 데이터를 반환한다.ex: 컬렉션 렌더링 캐싱&lt;%= render partial: 'products/product', collection: @products, cached: true %&gt; @products 컬렉션의 각 항목에 대해 개별적으로 캐싱된다.4. Russian Doll Caching러시안 돌 캐싱은 중첩된 프래그먼트 캐싱으로, 부모와 자식 요소가 서로 독립적으로 갱신될 수 있도록 한다. (이름 잘지은듯ㅋㅋ)ex: 댓글이 포함된 게시물 캐싱&lt;% cache @post do %&gt; &lt;h1&gt;&lt;%= @post.title %&gt;&lt;/h1&gt; &lt;% cache [@post, @post.comments] do %&gt; # 제목을 호출하고 댓글을 호출 &lt;ul&gt; &lt;% @post.comments.each do |comment| %&gt; &lt;li&gt;&lt;%= comment.body %&gt;&lt;/li&gt; # 제목하나당 각 댓글을 순회하며 내용을 표시한다. &lt;% end %&gt; &lt;/ul&gt; &lt;% end %&gt;&lt;% end %&gt; 게시물과 댓글 각각을 별도로 캐싱하여 효율적으로 관리한다.5. Low-Level Caching저수준 캐싱은 특정 데이터나 연산 결과를 직접 저장하고 읽는 방식으로, 가장 세밀하게 제어할 수 있다.ex: Rails.cache.fetchclass Product &lt; ApplicationRecord def competing_price Rails.cache.fetch(\"#{cache_key_with_version}/competing_price\", expires_in: 12.hours) do Competitor::API.find_price(id) end endend# 사용 예시:price = Rails.cache.fetch('product_price') { calculate_price } fetch는 키(cache_key_with_version/competing_price)로 값을 검색하고, 없으면 블록을 실행해 값을 저장한다. 만료 시간(expires_in)을 설정해 자동으로 갱신할 수 있다.저수준 API 사용 ex# 값 쓰기Rails.cache.write('key', 'value', expires_in: 5.minutes)# 값 읽기Rails.cache.read('key')# 값 삭제Rails.cache.delete('key')6. Cache Store 설정Rails는 다양한 캐시 스토어를 지원하며, 필요에 따라 선택할 수 있다. 기본적으로 file_store, memory_store, mem_cache_store, redis_cache_store 등을 사용 가능하다. 설정 ex (config/environments/production.rb): config.cache_store = :redis_cache_store, { url: ENV['REDIS_URL'] } Memory Store (:memory_store) 가장 빠른 캐시 스토어로, Ruby 웹 서버의 프로세스 메모리에 데이터를 저장한다. 기본적으로 32MB의 메모리를 사용하며, 설정을 통해 크기를 조절할 수 있다. 개발 환경에서 주로 사용되며, Rails 5 이후 새로운 애플리케이션 생성 시 개발 환경의 기본 캐시 스토어로 설정된다. 서버 재시작 시 캐시가 자동으로 초기화되어 개발 중 편리하다. 여러 서버 프로세스를 사용하는 환경에서는 적합하지 않다.File Store (:file_store) 캐시 데이터를 파일 시스템에 저장한다. 디스크 용량이 허용하는 한 많은 데이터를 저장할 수 있지만, 다른 스토어에 비해 속도가 느리다. 하나 또는 두 개의 호스트에서 서비스되는 중소 규모 사이트에 적합하다. 주기적으로 오래된 캐시 항목을 정리해야 한다.Memcached Store (:mem_cache_store) Dalli gem과 Memcached를 사용하여 중앙 집중식 인메모리 캐시를 제공한다. 기본적으로 64MB의 캐시 크기를 사용하며, 설정을 통해 조정 가능하다. 여러 서버 프로세스나 호스트 간에 캐시를 공유할 수 있어 대규모 프로덕션 환경에 적합하다. Memcached 서버가 재시작되면 모든 캐시가 초기화된다.Redis Cache Store (:redis_cache_store) Redis를 사용하여 캐시 데이터를 저장한다. Rails 5.2에서 도입되었으며, Memcached와 유사한 기능을 제공한다. 분산 캐싱에 적합하며, 여러 애플리케이션 서버 인스턴스가 공통 캐시를 공유할 수 있다. 자동 만료 정책을 설정할 수 있어 메모리 관리가 용이하다. Redis의 영속성 기능으로 인해 서버 재시작 후에도 캐시 데이터가 유지될 수 있다.개발 환경에서는 Memory Store나 File Store를, 프로덕션 환경에서는 Memcached Store나 Redis Cache Store를 사용하는 것이 좋다.Redis Cache Store와 Memcached Store 비교 특징 Redis Cache Store Memcached Store 데이터 구조 다양한 데이터 구조 지원 (문자열, 리스트, 해시, 셋 등) 단순 키-값 저장만 지원 영속성 디스크에 데이터 저장 가능 (RDB, AOF) 메모리에만 저장, 영속성 없음 복제 마스터-슬레이브 복제 지원 복제 기능 없음 트랜잭션 트랜잭션 지원 트랜잭션 지원 안 함 메모리 효율성 Memcached에 비해 상대적으로 낮음 매우 높음 속도 매우 빠름 매우 빠름 (일부 작업에서 Redis보다 빠를 수 있음) 확장성 클러스터링 지원 샤딩은 가능하지만 클러스터링은 제한적 키 크기 제한 512MB 250 바이트 값 크기 제한 512MB 1MB 용도 캐싱, 세션 저장, 실시간 분석 등 다양한 용도 주로 단순 캐싱에 사용 Rails 통합 Rails 5.2 이후 기본 지원 오래전부터 지원됨 설정 복잡도 약간 복잡함 비교적 간단함 모니터링 도구 다양한 모니터링 도구 제공 제한적인 모니터링 도구 Redis는 더 다양한 기능과 데이터 구조를 제공하지만, Memcached는 단순하고 효율적인 캐싱에 특화되어 있다. 샤딩은 대규모 데이터셋을 여러개 작은 샤드로 나누는 서버분산 기술 클러스터링은 여러서버를 하나의 시스템처럼 작동하는 기술" }, { "title": "Ruby on Rails 성능 최적화: 가비지 컬렉션", "url": "/posts/rails_gc/", "categories": "Web Development, Performance Optimization", "tags": "ruby-on-rails, garbage-collection, memory-management, performance-tuning, rails-optimization", "date": "2025-01-19 19:40:00 +0900", "snippet": "정리하게된 계기Rails App 경우 자바와 같이 object가 생성될떄 힙에 실제데이터를 올리고 있는데 메모리를 해제를 어떻게하는지 궁금해서 찾아보게 되었다. Ruby의 가비지 컬렉션(GC) 메커니즘은 메모리 관리의 핵심 부분이다. GC 모듈을 통해 이 과정을 이해하고 최적화할 수 있다. Rails 애플리케이션에서 메모리 사용량이 높아지는 주요 원인 중 하나는 객체 보유이다. (전부 다 객체화 하기때문인듯)수명이 짧은 객체(Short-Lived Objects)보통의 루비 객체는 짧은 생명 주기를 가진다:User.where(name: \"kms\") ORM 쿼리 실행 시 여러 객체가 생성된다 (예: where 메서드, :name 심볼, \"kms\" 문자열). 쿼리 실행 후 이 객체들은 더 이상 참조되지 않아 GC 대상이 된다.전역 변수와 객체 보유$retain_data = []999_999.times { $retain_data &lt;&lt; \"김나박이\" }이 경우: 999,999개의 문자열 객체에 대한 포인터가 힙에 생성된다. 이 객체들은 전역 변수 $retain_data에 의해 참조되므로 GC 대상이 되지 않는다.참고사항 상수, 전역 변수, 모듈, 클래스가 참조하는 객체는 GC 대상이 되지 않는다. 전역적으로 접근 가능한 객체를 참조할 때는 주의가 필요하다. 자주 사용해야하는 상수가 있다면, freeze 메서드를 사용하여 메모리 사용을 최적화할 수 있다.객체 해제(Object Freeing)전역 변수 없이 실행하면:def foo 999_999.times { \"김나박이\" }endfoo이 경우: GC.stat[:total_freed_objects]는 약 1,000,004개로 높게 나타난다. foo 메서드가 종료되면 객체들이 더 이상 참조되지 않아 GC 대상이 된다. 메모리 사용량이 전역에 비해 휠씬 줄어듬.Ruby on Rails 가비지 컬렉션(GC) 최적화Ruby의 GC는 애플리케이션의 메모리 관리를 담당한다. rails c로 접근해서 아래와같이 실행하면 된다.GC 상태확인 및 기능들Ruby의 GC.stat 메서드는 가비지 컬렉션의 상세한 통계를 제공한다. 이 통계를 이해하면 애플리케이션의 메모리 사용 패턴과 GC 동작을 파악할 수 있다.기본 GC 통계 count: 총 GC 실행 횟수 minor_gc_count: 마이너 GC 실행 횟 major_gc_count: 메이저 GC 실행 횟수이 통계는 GC가 얼마나 자주 실행되었는지를 보여준다. 마이너 GC가 메이저 GC보다 더 자주 실행되는 것이 일반적이다.힙 관련 정보 heap_allocated_pages: 할당된 힙 페이지 수 heap_sorted_length: 정렬된 힙의 길이 heap_allocatable_pages: 추가 GC 없이 할당 가능한 페이지 수 heap_available_slots: 총 사용 가능한 슬롯 수 heap_live_slots: 현재 사용 중인 슬롯 수 heap_free_slots: 사용 가능한 빈 슬롯 수이 정보는 Ruby의 메모리 할당 상태를 보여준다. 특히 heap_free_slots가 낮으면 GC가 곧 실행될 가능성이 높다. heap_available_slots와 heap_live_slots 의 이 두 값의 차이가 작아지면 마이너 GC가 실행될 가능성이 높다. 메이저 GC는 이 차이가 지속적으로 작을 때 실행된다객체 관련 통계 total_allocated_objects: 총 할당된 객체 수 total_freed_objects: 총 해제된 객체 수 old_objects: 오래된 세대의 객체 수 old_objects_limit: 오래된 세대 객체 수 제한이 통계는 객체의 생성과 소멸 패턴을 보여준다. old_objects가 old_objects_limit에 가까워지면 메이저 GC가 실행될 가능성이 높아진다. 마이너 GC는 주로 새로 생성된 객체(young 객체)를 대상으로 한다.메모리 관련 정보 malloc_increase_bytes: 마지막 GC 이후 증가한 메모리 양 malloc_increase_bytes_limit: 다음 GC 트리거 전 허용되는 메모리 증가량이 정보는 메모리 사용량의 증가를 추적한다. malloc_increase_bytes가 malloc_increase_bytes_limit에 가까워지면 GC가 트리거될 가능성이 높다. malloc_increase_bytes가 급격히 증가하면 마이너 GC가 먼저 실행되고 헤당 값이 지속적으로 높게 유지되면 메이저 GC가 실행될 수 있다.Ruby의 GC는 이러한 지표들을 복합적으로 고려하여 마이너 GC와 메이저 GC를 실행한다. 마이너 GC는 더 자주, 더 빠르게 실행되며, 메이저 GC는 전체 힙을 대상으로 하므로 더 오래 걸리지만 덜 실행된다.GC 환경변수 튜닝GC의 동작을 최적화하기 위해 다양한 환경 변수를… 셀에서 직접, ruby 스크립트 내에서, config/application.rb에서 설정할 수 있다.# config 파일config.before_initialize do GC.configure do |config| config.heap_init_slots = 1000000 endend# 스크립트 스타일...# 초기 힙 슰롯수 설정 값이 커질수록 초기 메모리 할당은 올라간다. but gc빈도 줄어듬# 메모리가 충분한 환경에서 대규모 객체생성이 필요할때 증가시키면 좋을듯ENV['RUBY_GC_HEAP_INIT_SLOTS'] = '1000000' # GC실행후 유지할 최소 빈 슬롯 수를 설정# 값이 늘수록 GC 실행빈도는 줄어들지만, 메모리 사용량이 올라감# 잦은 객체할당과 해제가 빈번한 app에서 GC 오버헤드를 줄이기 위해 사용하면 좋을듯ENV['RUBY_GC_HEAP_FREE_SLOTS'] = '10000'# 힙 크기 증가비율을 설정# 값을 높이면 힙 크기가 증가해서 GC 실행빈도가 줄어들미잔 메모리 사용량 증가# GC 빈도를 줄이고 넉넉한 메모리 사용증가를 감당하는 환경에서 사용ENV['RUBY_GC_HEAP_GROWTH_FACTOR'] = '1.1' #RUBY_GC_HEAP_GROWTH_MAX_SLOTS#RUBY_GC_MALLOC_LIMIT#RUBY_GC_OLDMALLOC_LIMIT#RUBY_GC_HEAP_OLDOBJECT_LIMIT_FACTORGC 수동제어특정 작업 동안 GC를 일시적으로 비활성화하여 성능을 향상시킬 수 있다.GC.disable# 메모리 집약적인 작업 수행GC.enableGC.start # 수동으로 GC 실행https://ruby-doc.org/core-2.7.4/GC/Profiler.html" }, { "title": "비슷하면서 다른 SQL 정리", "url": "/posts/groupby_-partition/", "categories": "PARTITION, GROUP", "tags": "mysql, PARTITION, GROUPBY", "date": "2025-01-14 19:40:00 +0900", "snippet": "GROUP BY와 PARTITION BYGROUP BY와 PARTITION BY는 SQL에서 데이터를 그룹화하는 데 사용되는 중요한 구문이다. 두 구문은 유사한 기능을 하지만, 결과 데이터의 구조와 사용 목적에 차이가 있다.주요 차이점 특성 GROUP BY PARTITION BY 결과 행의 수 그룹화된 결과만 반환하여 감소 모든 원본 행 유지 데이터 집계 방식 그룹별로 집계하여 하나의 결과 행 생성 각 행에 그룹의 집계 결과 추가 사용 위치 SELECT 문의 마지막 부분 윈도우 함수와 함께 OVER 절 내에서 사용 GROUP BYSELECT department, AVG(salary) as avg_salaryFROM employeesGROUP BY department;| department | avg_salary ||------------|------------|| IT | 75000 || Sales | 65000 || HR | 55000 |이 쿼리는 부서별 평균 급여를 계산하며, 결과는 부서 수만큼의 행을 반환한다. 주로 총매출 계산이나 제품 카테고별 평균 가격 산출에 용이하다.PARTITION BYSELECT employee_name, department, salary, AVG(salary) OVER (PARTITION BY department) as dept_avg_salaryFROM employees;| employee_name | department | salary | dept_avg_salary ||---------------|------------|--------|-----------------|| 도비 | IT | 80000 | 75000 || 헤르미온느 | IT | 70000 | 75000 || 해리포터 | Sales | 60000 | 65000 || 존시나 | Sales | 70000 | 65000 || 다비드 | HR | 55000 | 55000 |이 쿼리는 모든 직원의 정보를 유지하면서 각 부서의 평균 급여를 함께 표시한다. 각각의 지원급여와 해당 부서평균 급여나 월별 매출과 연각 누적 매출을 동시에 보고 싶을떄 사용결론GROUP BY는 데이터를 요약하고 집계할 때 유용하며, PARTITION BY는 원본 데이터를 유지하면서 그룹별 계산 결과를 함께 보여주고자 할 때 효과적이다. 분석 목적과 필요한 결과 형태에 따라 적절한 구문을 선택하여 사용하면 된다.&lt; 정리중 &gt;UNION vs. UNION ALL 특성 UNION UNION ALL 중복 제거 중복 행 제거 중복 행 유지 성능 중복 검사로 인해 상대적으로 느림 중복 검사 없어 빠름 결과 정렬 자동으로 결과 정렬 정렬하지 않음 JOIN vs. SUBQUERY 특성 JOIN SUBQUERY 데이터 결합 방식 테이블 간 직접 결합 쿼리 내 다른 쿼리 포함 성능 대체로 빠름 복잡한 경우 느릴 수 있음 가독성 복잡한 조인에서 가독성 떨어질 수 있음 간단한 경우 가독성 좋음 유연성 다중 테이블 조인 가능 단일 값 또는 행 집합 반환 WHERE vs. HAVING 특성 WHERE HAVING 필터링 시점 그룹화 전 행 필터링 그룹화 후 결과 필터링 집계 함수 사용 사용 불가 사용 가능 성능 일반적으로 더 빠름 WHERE로 먼저 필터링한 후 사용 시 효율적 사용 위치 GROUP BY 이전 GROUP BY 이후 INNER JOIN vs. OUTER JOIN 특성 INNER JOIN OUTER JOIN 결과 행 양쪽 테이블에서 일치하는 행만 한쪽 또는 양쪽 테이블의 모든 행 포함 가능 NULL 처리 NULL 값 제외 NULL 값 포함 가능 사용 사례 두 테이블 간 공통 데이터 필요 시 한 테이블의 모든 데이터와 매칭 정보 필요 시 " }, { "title": "가상테이블", "url": "/posts/virtual_table/", "categories": "virtual_table", "tags": "mysql, virtual_table", "date": "2024-12-28 09:40:00 +0900", "snippet": "MySQL에서 가상 테이블은 실제 데이터를 저장하지 않고 쿼리 결과를 임시로 저장하는 객체아다. 가상 테이블의 주요 형태로는 View, 파생 테이블(Derived Table), CTE(Common Table Expression), Temporary Table이 있다.1. 뷰(View)뷰는 하나 이상의 테이블에서 원하는 데이터를 선택하여 만든 가상 테이블이다. 뷰는 데이터베이스에 저장되며, 재사용이 가능하다.특징: 실제 데이터를 저장하지 않고, 쿼리 정의만 저장한다. 기본 테이블의 데이터가 변경되면 뷰의 데이터도 자동으로 변경된다. 복잡한 쿼리를 단순화할 수 있다.예시:-- 뷰 생성CREATE VIEW high_salary_employees ASSELECT employee_id, first_name, last_name, salaryFROM employeesWHERE salary &gt; 5000;-- 뷰 테이블 조회SELECT * FROM high_salary_employees;이 예시에서는 급여가 5000 이상인 직원들의 정보를 보여주는 뷰를 생성했다. 이 뷰는 마치 실제 테이블처럼 사용할 수 있다. 또한 별도의 수동 삭제가 필요하다.DROP VIEW {테이블 명}2. 파생 테이블(Derived Table)파생 테이블은 FROM 절에서 서브쿼리로 만들어지는 임시 테이블이다. 쿼리 실행 중에만 존재하며, 쿼리가 끝나면 사라진다.특징: 복잡한 조인이나 집계 연산을 단순화할 수 있다. 메인 쿼리의 가독성을 높일 수 있다. 일회성으로 사용된다.예시:SELECT dept_name, avg_salaryFROM ( SELECT department_id, AVG(salary) as avg_salary FROM employees GROUP BY department_id) AS dept_salariesJOIN departments d ON dept_salaries.department_id = d.department_id;이 예시에서는 각 부서의 평균 급여를 계산하는 서브쿼리를 파생 테이블로 사용했다.3. CTE(Common Table Expression)CTE는 WITH 절을 사용하여 이름이 부여된 임시 결과 집합을 정의한다. 복잡한 쿼리를 더 읽기 쉽고 관리하기 쉽게 만들어준다.특징: 쿼리 내에서 여러 번 참조할 수 있다. 재귀적 쿼리를 작성할 수 있다. 쿼리의 가독성과 유지보수성을 향상시킨다.예시:WITH RECURSIVE employee_hierarchy AS ( -- 기준 행 (최상위 관리자) SELECT employee_id, first_name, last_name, manager_id, 0 AS level FROM employees WHERE manager_id IS NULL UNION ALL -- 재귀 부분 SELECT e.employee_id, e.first_name, e.last_name, e.manager_id, eh.level + 1 FROM employees e JOIN employee_hierarchy eh ON e.manager_id = eh.employee_id)SELECT * FROM employee_hierarchy;이 예시는 재귀적 CTE를 사용하여 직원들의 계층 구조를 표현했다. 최상위 관리자부터 시작해서 모든 하위 직원들을 레벨별로 보여준다.4. 임시 테이블 TEMPORARY TABLE임시 테이블은 CREATE TEMPORARY TABLE 명령으로 생성되며, 세션이 종료될 때까지 존재한다.-- 임시 테이블 생성CREATE TEMPORARY TABLE temp_sales ( id INT AUTO_INCREMENT PRIMARY KEY, product_name VARCHAR(100), total_sales DECIMAL(10,2));-- 데이터 삽입INSERT INTO temp_sales (product_name, total_sales)SELECT p.name, SUM(o.quantity * o.price)FROM products pJOIN orders o ON p.id = o.product_idGROUP BY p.id;-- 임시 테이블 사용SELECT * FROM temp_sales WHERE total_sales &gt; 10000;세션이 종료되는 시점은 명시적으로 연결 종료를 하던지, DB 커낵션이 끊킨다던가, 타임아웃, 임시테이블 자동삭제 마지막으로 새로운 세션시작 (동알한 테이블 생성 쿼리)시 종료된다고 보면된다.정리 특성 View 파생 테이블 CTE 임시 테이블 정의 저장된 쿼리 결과를 가상 테이블로 표현 FROM 절의 서브쿼리로 생성되는 임시 결과셋 WITH 절을 사용해 정의되는 명명된 임시 결과셋 CREATE TEMPORARY TABLE로 생성되는 실제 테이블 지속성 데이터베이스에 영구 저장 쿼리 실행 중에만 존재 쿼리 실행 중에만 존재 세션 종료 시까지 존재 재사용성 여러 쿼리에서 재사용 가능 단일 쿼리 내에서만 사용 단일 쿼리 내에서 여러 번 참조 가능 세션 내에서 여러 쿼리에서 재사용 가능 데이터 수정 일부 경우 가능 불가능 불가능 가능 (INSERT, UPDATE, DELETE) 인덱싱 일부 DBMS에서 가능 불가능 불가능 가능 복잡성 처리 복잡한 쿼리 단순화 중간 결과 생성으로 복잡한 연산 단순화 복잡한 쿼리를 논리적 부분으로 분해 복잡한 중간 결과 저장 및 처리 성능 자주 사용 시 성능 향상 가능 대규모 데이터에서 성능 저하 가능 복잡한 쿼리에서 성능 향상 가능 대량 데이터 처리 시 유리 재귀 쿼리 지원하지 않음 지원하지 않음 지원 지원하지 않음 생성 방법 CREATE VIEW 서브쿼리 WITH 절 CREATE TEMPORARY TABLE " }, { "title": "내가 이해하려고 적는 카프카", "url": "/posts/kafka/", "categories": "kafka", "tags": "kafka", "date": "2024-12-22 13:40:00 +0900", "snippet": "카프카란카프카는 대규모 실시간 데이터 스트리밍을 위해 설계된 분산 이벤트 스트리밍 플랫폼이다. 대략적인 구조는 시스템에서는 프로듀서가 메시지를 생성하고, 이를 카프카 클러스터의 토픽으로 전송한다. 토픽은 여러 파티션으로 나뉘어 있어 병렬 처리가 가능하고, 컨슈머는 만들어진 파티션에서 메시지를 읽어 처리한다. 이런 구조로 인해 카프카는 높은 처리량과 확장성을 제공하며, 데이터의 영속성도 보장한다.코드로 가보자 온라인 쇼핑몰에서 주문이 들어올 때마다 이를 처리하고, 재고를 업데이트하는 시스템을 Kafka를 이용해 예시를 들겠다.Producer(주문 접수) 코드: 주문 정보를 생성하고 ‘sinsang-orders’ 토픽으로 전송한다.require 'kafka'# Kafka 브로커 주소 설정# 브로커란? --&gt; 카프카 클러스터를 구성하는 서버로 기본단위이자 # 메시지를 저장하고 관리하는 역할을 한다. # 여러 브로커가 클러스터를 이루어 고가용성과 확장성을 제공한다.kafka = Kafka.new([\"localhost:9092\"])# 주문 정보 생성 (웹 요청이 왔다고 가정)order = { id: \"12345\", product_id: \"ABC123\", quantity: 2, customer_id: \"CUST001\"}.to_json# 'sinsang-orders' 토픽으로 주문 정보 전송# 토픽이란? 카프카에서 메시지를 카테고리화하는 논리적 단위다. 각 토픽은 여러 파티션으로 나뉘어 # 병렬 처리와 확장성을 제공한다.kafka.deliver_message(order, topic: \"sinsang-orders\")puts \"주문이 접수되었습니다: #{order}\"Consumer(주문 처리) 코드require 'kafka'kafka = Kafka.new([\"localhost:9092\"])# 컨슈머 그룹 생성 # 컨슈머란? --&gt; 토픽에서 메시지를 읽고 처리하는 애플리케이션이다.# 컨슈머 그룹을 통해 여러 컨슈머가 협력하여 메시지를 병렬로 처리할 수 있다.consumer = kafka.consumer(group_id: \"order-processing-group\")# 'new-orders' 토픽 구독consumer.subscribe(\"sinsang-orders\")# 메시지 처리consumer.each_message do |message| order = JSON.parse(message.value) puts \"새로운 주문을 처리합니다: #{order}\" process_order(order) # 주문이 처리되고 DB에 저장하는 로직 # 재고 업데이트를 위한 새로운 메시지 발행 update_stock_message = { product_id: order['product_id'], quantity: order['quantity'] }.to_json # 재고업데이트를 위한 새 메시지 토픽을 발행 kafka.deliver_message(update_stock_message, topic: \"stock-updates\")end이 컨슈머 코드는 ‘sinsang-orders’ 토픽에서 메시지를 읽어 처리하고, 재고 업데이트를 위한 새 메시지를 ‘stock-updates’ 토픽으로 발행한다. 카프카는 주문 정보를 안정적으로 전달하고, 여러 컨슈머가 병렬로 주문을 처리할 수 있게 해준다. 시스템 간 느슨한 결합으로 주문저장과 재고 업데이트와 같은 후속 작업을 위한 새로운 메시지를 생성하여 서버의 부담을 줄인다.추가적인 설명 파티션: 각 토픽은 여러 파티션으로 나뉘어 있다. 이를 통해 데이터를 병렬로 처리할 수 있고, 시스템의 처리량을 높일 수 있다. 오프셋: 각 메시지는 파티션 내에서 고유한 오프셋 값을 가진다. 컨슈머는 이 오프셋을 이용해 자신이 어디까지 메시지를 처리했는지 추적한다. 복제: 데이터 안정성을 위해 각 파티션은 여러 브로커에 복제될 수 있다. 이를 통해 일부 브로커에 장애가 발생해도 시스템이 계속 작동할 수 있다.더 디테일한 내용은 이 블로그 글을 참고하면 좋을듯하다.그럼 이걸 왜 다안쓰냐…? 내가 경험해본 바로는 분산시스템이기에 완벽한 무결성을 보장하기 어렵다. 예시로 들었지만 재고같은 숫자를 다루는 데이터보다 상대적으로 인스타의 좋아요나 대규모 로그처리 실시간 행동분석 등에서는 적합하나 금전거래나 의료기록같은 1원까지 틀어지면 안되는 곳에서는 사용을 지양하는것이 좋은 것 같다." }, { "title": "INDEX에 관하여", "url": "/posts/about_index/", "categories": "index, single, multi", "tags": "mysql, index", "date": "2024-12-21 13:40:00 +0900", "snippet": "전에 클러스터인덱스와 넌클러스터 인덱스에 대해 다뤄봤었는데 복습겸 다시 한번 적자면 클러스터 인덱스는 기본키나 빈번하게 검색이나 정렬이 필요한 열에 사용하고(자동으로 기본키가 됨) 넌클러스터 인덱스는 WHERE 절에 자주 사용되고 여러조합에 쿼리 성능을 뽑아낼때 쓴다고 한다. 그래서 이참에 인덱스에 대해 정리해볼까 하고 글을 쓴다.단순한 회원테이블이 있다고 가정해보자.CREATE TABLE members ( id INT NOT NULL AUTO_INCREMENT, name VARCHAR(100) NOT NULL, email VARCHAR(100) NOT NULL, birthdate DATE, age INT, created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP, PRIMARY KEY (id));단일 인덱스단일 인덱스는 하나의 컬럼에 대해서만 생성된 인덱스이다.CREATE INDEX idx_name ON members (name);CREATE INDEX idx_email ON members (email);복합 인덱스복합 인덱스는 두 개 이상의 컬럼을 조합해 생성된 인덱스이다.CREATE INDEX idx_name_email ON members (name, email);성능 비교 및 최적화예시 1: 단일 컬럼 검색SELECT * FROM members WHERE name = 'John Kim';이 경우, 단일 인덱스 idx_name이 복합 인덱스 idx_name_email보다 약간 더 효율적일 수 있다. 이유는 단일 인덱스가 더 작고 검색해야 할 데이터가 적기 떄문이다.예시 2: 복수 컬럼 검색SELECT * FROM members WHERE name = 'John Doe' AND email = 'john@example.com';이 경우, 복합 인덱스 idx_name_email이 단일 인덱스들보다 훨씬 효율적이다. 복합 인덱스는 두 컬럼을 모두 커버하므로 테이블 액세스 없이 인덱스만으로 결과를 반환하기 떄문이다.예시 3: 부분 일치 검색SELECT * FROM members WHERE name = 'John Doe';복합 인덱스 idx_name_email만 있는 경우에도 이 쿼리도 효율적으로 처리할 수 있다. 복합 인덱스의 왼쪽 끝 컬럼(이 경우 ‘name’)만 사용하는 쿼리도 해당 인덱스를 활용할 수 있기 때문.예시 4: ORDER BY에서 활용SELECT * FROM members ORDER BY name, email;복합 인덱스 idx_name_email가 이미 정렬된 순서로 데이터를 저장하고 있기 때문에 추가적인 정렬 작업이 필요 없다.카디널리티를 고려해서 복합 인덱스를 만들 때는 카디널리티(고유값의 수)가 높은 컬럼을 먼저 배치하는 것이 좋고. (한국은 이름이 같은 케이스가 있기에 (email, name)이 (name, email) 보다 효율적) 인덱스 컬럼 순서 WHERE 절에서 자주 사용되는 컬럼을 복합 인덱스의 왼쪽에 배치하고 범위 조건 주의 범위 조건(&gt;,&lt; BETWEEN 등)이 사용되는 컬럼은 복합 인덱스의 마지막에 배치하도록 설게 커버링 인덱스 활용 SELECT 절에서 요청하는 모든 컬럼이 인덱스에 포함되도록 테이블 액세스를 줄이고 불필요한 인덱스 제거 너무 많은 인덱스는 INSERT, UPDATE, DELETE 작업의 성능을 저하시킬 수 있으므로 필요한 것만 인덱스를 만드는걸로 하면 성능이 좋아진다.커버링 인덱스 (Covering Index)커버링 인덱스는 쿼리에 필요한 모든 컬럼을 포함하는 인덱스이다.CREATE INDEX idx_covering_name ON Customer(first_name, last_name);이 인덱스를 사용하면 first_name과 last_name만 필요한 쿼리의 경우 테이블에 접근하지 않고도 결과를 반환한다.접두사 인덱스 (Prefix Index)긴 문자열에서 컬럼에 대해 전체가 아닌 앞부분만 인덱싱하는 기법. 인덱스 크기를 줄이면서도 효과적인 검색유도.CREATE INDEX idx_email ON tb_user(email(5));email 필드의 앞 5자만 인덱싱해서 뒤에 불필요한 @gmail.com 같은 @뒤의 데이터를 저장하지않아도 됨.SELECT * FROM tb_user USE INDEX(idx_user_pro) WHERE professor='Software Engineering';SELECT * FROM tb_user IGNORE INDEX(idx_user_pro) WHERE professor='Software Engineering';SELECT * FROM tb_user FORCE INDEX(idx_user_pro) WHERE professor='Software Engineering';위처럼 옵티마이저의 선택을 오버라이드하거나 특정 인덱스 사용을 강제할 수도 있다.인덱스 갱신기능ANALYZE TABLE table_name;ANALYZE를 통해 인덱스를 재생성해서 성능을 최적화하고 키를 재분배한다는데 알아서 innoDB가 해준다고 한다. 데이터 삽입이 20억행이상 갱신된 경우에 수동으로 해주면 좋다고한다.적응형 해시 인덱스 (Adaptive Hash Index)InnoDB 엔진은 자주 접근되는 데이터에 대해 자동으로 해시 인덱스를 생성해서 B-Tree의 한계를(자주 사용되는 데이터 탐색인데 동일하게 트리의 경로를 쫓아야하는점) 보완해주는 기능이다.특히 단일 랜덤 키 접근이 빈도있게 발생하는 경우, B-Tree 를 통하지 않고 데이터에 접근/처리가 가능하기에 좋은 퍼포먼스를 보여준다. BUT, 옵티마이저가 판단하여 해시 키로 만들기 때문에 제어가 어렵고 테이블 Drop 시, 기존 해시 자료구조에 데이터가 남아있어서 영향을 준다. 해시 인덱스에 의존하여 트래픽이 주로 처리되는 서비스인 경우 고려해볼법하다. 금융거래시스템에서 계좌번호로 누군가에게 송금할떄? 검색하는 기능이나 인기많은 상품에대해 쓸만할지도…?" }, { "title": "mysql 쿼리 기능", "url": "/posts/query_series1/", "categories": "LEAD, LAG, OVER, PARTITION", "tags": "mysql, query", "date": "2024-12-18 22:00:00 +0900", "snippet": "윈도우 함수란? 행과 행 간의 관계를 정의하거나 계산할때 씀. 데이터를 그룹화하지 않고도 각 행을 유지하면서 추가적인 계산을 수행특징으로는 GROUP BY와 다르게 행이 유지되고 OVER절을 써야하고 행간 순위, 누적합계 비교가 가능함.LEAD LEAD 함수는 현재 행을 기준으로 이후 행의 데이터를 가져오는 데 사용. 주로 다음 행의 값과 현재 행의 값을 비교하거나, 다음 데이터의 예측값을 계산할 때 활용.LEAD(&lt;expression&gt;[, offset[, default_value]]) OVER (PARTITION BY &lt;expr&gt; ORDER BY &lt;expr&gt;) expression: 반환할 열(column) 값. offset: 기준 행으로부터 몇 번째 이후 값을 가져올지 지정. 기본값은 1. default_value: 이후 행이 없을 경우 반환할 기본값. 기본값은 NULL. PARTITION BY: 데이터를 그룹화하여 각 그룹 내에서 별도로 계산. ORDER BY: 행의 순서를 지정.SELECT customerName, orderDate, LEAD(orderDate, 1) OVER (PARTITION BY customerNumber ORDER BY orderDate) AS nextOrderDateFROM ordersINNER JOIN customers USING (customerNumber); 위의 이미지 처럼 각각의 고객별로 주문 날짜를 기준으로 정렬하고, 다음 주문 날짜를 조회가 필요할 때 사용LAG LAG 함수는 현재 행을 기준으로 이전 행의 데이터를 가져오는 데 사용 주로 이전 값과 현재 값을 비교하거나 변화 추이를 계산할 때 활용LAG(&lt;expression&gt;[, offset[, default_value]]) OVER (PARTITION BY &lt;expr&gt; ORDER BY &lt;expr&gt;) 구문은 LEAD와 동일하지만 전 상태를 비교할때 씀 productline order_year order_value prev_year_order_value Classic Cars 2022 1500000 NULL Classic Cars 2023 1650000 1500000 Classic Cars 2024 1800000 1650000 Vintage Cars 2022 800000 NULL Vintage Cars 2023 850000 800000 Vintage Cars 2024 900000 850000 Motorcycles 2022 600000 NULL Motorcycles 2023 650000 600000 Motorcycles 2024 700000 650000 WITH productline_sales AS ( SELECT productline, YEAR(orderDate) AS order_year, ROUND(SUM(quantityOrdered * priceEach), 0) AS order_value FROM orders INNER JOIN orderdetails USING (orderNumber) INNER JOIN products USING (productCode) GROUP BY productline, order_year)SELECT productline, order_year, order_value, LAG(order_value, 1) OVER (PARTITION BY productline ORDER BY order_year) AS prev_year_order_valueFROM productline_sales; 각 제품군(productline)의 연도별 매출액을 계산하고, 전년도 매출액(prev_year_order_value)을 비교할떄 씀둘의 비교 기능 LEAD LAG 반환값 현재 행 기준 이후 값 현재 행 기준 이전 값 주요 목적 미래 데이터 참조 과거 데이터 참조 기본값 NULL NULL 활용 예시 다음 주문 날짜 조회 전년도 매출액 비교 OVER 윈도우 함수에서 반드시 사용되는 구문으로, 특정 범위를 정의해야함 ORDER BY를 통해 행의 순서를 지정하거나, PARTITION BY를 통해 그룹화된 데이터 내에서 연산을 수행할 수 있음.PARTITION BY 데이터를 특정 그룹으로 나누어 각 그룹 내에서 독립적으로 연산을 수행 PARTITION BY를 생략하면 전체 데이터셋에 대해 연산이 수행 employeeName department salary rank_in_department John Smith IT 95000 1 Jane Doe IT 92000 2 Mike Johnson IT 88000 3 Emily Brown IT 85000 4 Sarah Lee Sales 110000 1 Tom Wilson Sales 105000 2 Lisa Chen Sales 98000 3 David Kim Sales 95000 4 Mary Taylor HR 88000 1 Robert White HR 85000 2 Anna Garcia HR 82000 3 SELECT employeeName, department, salary, RANK() OVER (PARTITION BY department ORDER BY salary DESC) AS rank_in_departmentFROM employees; 각 부서별로 직원들의 급여 순위를 계산 rank_in_department 구하기" }, { "title": "Ruby GEM 시리즈", "url": "/posts/useful_gems/", "categories": "Rails, Gems", "tags": "rails, gems", "date": "2024-11-27 22:00:00 +0900", "snippet": "ZipLineZipline은 Rails 애플리케이션에서 동적으로 생성된 ZIP 파일을 스트리밍하기 위한 Ruby gem이다. 스트리밍 방식으로 ZIP 파일 생성을 위해 전체 파일이 완성될 때까지 기다리지 않는다. 따라서 대용량 ZIP 파일 생성에도 큰 디스크 공간이나 메모리가 필요하지 않아 대기 시간과 다운로드 시간이 감소한다. ZIP 생성 중 이전으로 되돌아가지 않고 HTTP를 통해 스트리밍한다. “directory/file” 형식으로 파일 이름을 지정하여 디렉토리 구조 생성이 가능하다고함.class MyController &lt; ApplicationController include Zipline def index users = User.all files = users.map{ |user| [user.face, \"#{user.username}.png\"] } zipline(files, 'user_face.zip') endendKaminari페이지네이션을 위한 Ruby gem이다. 풀스택용인듯class User &lt; ApplicationRecord # 기본 페이지네이션 User.page(params[:page]).per(25) # 스코프와 함께 사용 User.where(age: 20..30).page(params[:page])end뷰&lt;%= paginate @users %&gt;&lt;% @users.each do |user| %&gt; &lt;%= user.name %&gt;&lt;% end %&gt;&lt;!-- 부트스트랩 스타일 적용 --&gt;&lt;%= paginate @users, theme: 'bootstrap4' %&gt;PumaRuby/Rack 애플리케이션을 위한 고성능 웹 서버 gem이다. 설정용 GEM 멀티스레드 지원: 각 요청을 별도 스레드에서 처리 멀티프로세스: 클러스터 모드에서 메모리 효율적인 fork 지원 독립 실행형: SSL 지원, 무중단 재시작 가능# config/puma.rbmax_threads_count = ENV.fetch(\"RAILS_MAX_THREADS\") { 5 }min_threads_count = ENV.fetch(\"RAILS_MIN_THREADS\") { max_threads_count }threads min_threads_count, max_threads_count# 클러스터 모드 설정workers ENV.fetch(\"WEB_CONCURRENCY\") { 2 }# 사전 로딩 설정preload_app!# 포트 설정port ENV.fetch(\"PORT\") { 3000 }# 환경 설정environment ENV.fetch(\"RAILS_ENV\") { \"development\" }JbuilderJson을 편하게 처리하기 위한 gemjson.post do json.title @post.title json.content @post.content # 조건을 넣을수 있다. json.author @post.author if @post.author.present? # 중첩을 넣어서 json.comments @post.comments do |comment| json.content comment.content json.user do json.name comment.user.name json.avatar_url comment.user.avatar_url end endend// 결과값{ \"post\": { \"title\": \"첫 번째 게시글\", \"content\": \"안녕하세요\", \"author\": \"김철수\", \"comments\": [ { \"content\": \"좋은 글이네요\", \"user\": { \"name\": \"박영희\", \"avatar_url\": \"https://example.com/avatar.jpg\" } }, { \"content\": \"감사합니다\", \"user\": { \"name\": \"이민수\", \"avatar_url\": \"https://example.com/avatar2.jpg\" } } ] }}json.extract! user, :id, :name, :email// 결과값{ \"id\": 1, \"name\": \"김철수\", \"email\": \"kim@example.com\"}# 복잡한 것은 따로 설정가능 코드의 복잡도를 해소json.array! @users, partial: 'users/user', as: :user// 결과값[ { \"id\": 1, \"name\": \"김철수\", \"email\": \"kim@example.com\" }, { \"id\": 2, \"name\": \"박영희\", \"email\": \"park@example.com\" }]Pundit권한 부여 시스템을 제공하는 gem, 간단하게 정책 기반 인증을 구현가능class PostPolicy attr_reader :user, :post def initialize(user, post) @user = user @post = post end def update? user.admin? || post.user_id == user.id end def destroy? user.admin? || post.user_id == user.id endendclass PostsController &lt; ApplicationController def update @post = Post.find(params[:id]) authorize @post # 정책이 정의된 클래스를 자동으로 찾음 if @post.update(post_params) redirect_to @post end endend# app/policy 디렉토리에 정의함class Policy attr_reader :user, :post def initialize(user, post) @user = user # current_user가 자동으로 전달됨 @post = post # authorize에 전달된 객체 end def update? user.admin? || post.user_id == user.id # 관리자이거나 작성자인 경우만 true endendDraper데코레이터 패턴을 사용하도록 모델에서 자주 사용되는 함수들을 하나의 파일로 만들어 사용함.# app/decorators/user_decorator.rbclass UserDecorator &lt; Draper::Decorator delegate_all def full_name \"#{object.first_name} #{object.last_name}\" end def member_since object.created_at.strftime(\"%B %Y\") end def status_label if object.active? h.content_tag(:span, \"활성\", class: \"badge badge-success\") else h.content_tag(:span, \"비활성\", class: \"badge badge-danger\") end endendclass UsersController &lt; ApplicationController def show @user = User.find(params[:id]).decorate endendPaper Trail모델의 변경 이력을 추적하고 관리할 수 있게 해주는 gemclass Post &lt; ApplicationRecord has_paper_trail # 특정 필드만 추적 has_paper_trail only: [:title, :content] # 메타데이터 추가 has_paper_trail meta: { editor_id: :editor_id, category: :category_name }endSidekiq백그라운드 작업 처리를 위한 gem입니다.설정 예시# app/workers/email_worker.rbclass EmailWorker include Sidekiq::Worker def perform(user_id) user = User.find(user_id) UserMailer.welcome_email(user).deliver_now # 대충 user한테 알림을 보낸 메서드 endend# 기본으로 제공하는 메서드EmailWorker.perform_async(user.id) # 비동기 실행EmailWorker.perform_in(2.hours, user.id) # 2시간 후 실행EmailWorker.perform_at(2.days.from_now, user.id) # 특정 시간에 실행장점 단점 Redis를 사용하여 빠른 처리 속도 하지만 그만큼 비용이 많이 들고 레디스 메모리도 증가함 실시간 모니터링 대시보드 제공 실패한 작업 재시도 기능 다중 큐 지원Carrierwave간단한 코드 작성으로 파일 업로드를 위한 gem. 로컬이나 AWS s3 버킷에 저장가능설정 예시# app/uploaders/image_uploader.rbclass ImageUploader &lt; CarrierWave::Uploader::Base include CarrierWave::MiniMagick # 이미지 처리 storage :file # 로컬 저장 storage :fog # AWS S3 등 클라우드 저장 # 썸네일 생성 version :thumb do process resize_to_fit: [100, 100] end # 허용하는 파일 형식 def extension_allowlist %w(jpg jpeg gif png) endend# 모델에서 사용class User &lt; ApplicationRecord mount_uploader :avatar, ImageUploaderend사용 예시# 컨트롤러def create @user = User.new(user_params) @user.avatar = params[:file] # 파일 업로드 @user.saveend# 뷰&lt;%= image_tag @user.avatar.url %&gt; # 원본 이미지&lt;%= image_tag @user.avatar.thumb.url %&gt; # 썸네일, S3로 부터 받음Figaro환경 변수 관리를 위한 gem. application.yml에 들어가는 민감정보를 방지함.설정 예시# config/application.ymldevelopment: AWS_KEY: \"dev_key_123\" API_SECRET: \"dev_secret_456\"production: AWS_KEY: \"prod_key_789\" API_SECRET: \"prod_secret_012\"사용 예시# 어플리케이션 코드에서 접근ENV[\"AWS_KEY\"]Figaro.env.aws_key# 필수 키 지정Figaro.require_keys(\"aws_key\", \"api_secret\")Figaro를 설치하게되면 config/application.yml 파일 생성되고.gitignore 파일에 /config/application.yml 자동 추가된다. 그래서 직접적인 파일공유를 해야하므로 별도의 환경변수 설정이 필요함. Heroku를 안쓰면 Rails credentials이 난듯?RSpec-RailsRails 애플리케이션을 위한 테스팅 프레임워크테스트 예시# spec/models/user_spec.rbRSpec.describe User, type: :model do # 모델 유효성 검사 it \"vaildation이 잘되나\" do user = User.new( email: \"test@example.com\", password: \"password123\" ) expect(user).to be_valid end # 연관 관계 테스트 it \"has many posts\" do should have_many(:posts) endend# spec/controllers/users_controller_spec.rbRSpec.describe UsersController, type: :controller do describe \"GET #index\" do it \"returns a success response\" do get :index expect(response).to be_successful end end describe \"POST #create\" do it \"creates a new user\" do expect { post :create, params: { user: valid_attributes } }.to change(User, :count).by(1) end endend다양한 테스트 도구 제공 (목업, 스텁 등)과 리포트를 제공함.하지만 나는 rails c or s 하고 직접값 입력하는게 루비를 잘쓰는게 아닐까 싶다." }, { "title": "Rails 디버깅", "url": "/posts/debug_rails/", "categories": "Rails, Debug", "tags": "rails, debug", "date": "2024-11-19 22:00:00 +0900", "snippet": "View 헬퍼 debug: YAML 형식으로 객체를 출력 to_yaml: YAML 변환 inspect: 배열이나 해시 값을 문자열로 출력# 컨트롤러@user = User.find(1)# 뷰에서&lt;%= debug @user %&gt;# --- !ruby/object:User# id: 1# name: \"John\"# email: \"john@example.com\"@items = ['apple', 'banana', 'orange']&lt;%= @items.to_yaml %&gt;# ---# - apple# - banana# - orange@settings = { theme: 'dark', language: 'ko }&lt;%= @settings.inspect %&gt; # 뒤에 안쳐도 동일하게 나오는것으로 보아 default인듯# {:theme=&gt;\"dark\", :language=&gt;\"ko\"}Logger 활용logger.debug \"데이터 확인: #{@data.inspect}\"logger.info \"요청 처리 중...\"logger.error \"심각한 오류 발생!\"로그 레벨: debug &lt; info &lt; warn &lt; error &lt; fatalbyebug 사용법 설치 gem install byebug rails c, byebug에 따른 장점 # byebug rails c 했을때 쓸만한것들 모음 &gt;Order.where(Id: 222441).to_sql &gt;\"SELECT `Order`.* FROM `Order` WHERE `Order`.Id` = 222441\" 주요 명령어 next (n): 다음 줄로 이동 step (s): 메소드 내부로 진입 continue (c): 실행 계속 break: 중단점 설정 실용적인 디버깅 팁중단점 관리break 20 # 20번 줄에 중단점 설정info breakpoints # 중단점 목록 확인delete 1 # 1번 중단점 삭제변수 검사var local # 지역 변수 확인var instance # 인스턴스 변수 확인p @user # 변수 값 출력web-console 활용view나 controller에서 바로 콘솔 사용 가능하다고 한다.&lt;% console %&gt;성능 최적화 팁로그 작성 시 블록 사용이 성능상 유리히다고 한다.# 좋은예logger.debug { \"데이터: #{expensive_operation}\" }# 좋지않은 예logger.debug \"데이터: #{expensive_operation}\"rails 공식 문서" }, { "title": "Rails Internationalization I18n 국제화설정", "url": "/posts/I18n/", "categories": "Rails, I18n", "tags": "rails, I18n", "date": "2024-11-15 22:00:00 +0900", "snippet": "기본 개념 영어 및 유사 언어에 대한 기본 지원 ko, en, jp, zh…etc 다른 언어를 위한 쉬운 커스터마이징과 확장 Rails 프레임워크의 모든 정적 문자열이 국제화되어 있음핵심 메서드: translate (별칭: t) - 텍스트 번역 조회 localize (별칭: l) - 날짜와 시간 객체의 지화 각국에 따른 URL 변경기능Translate (t) 사용 예시# config/locales/ko.ymlko: hello: \"안녕하세요\" welcome_message: \"환영합니다 %{name}님!\" nav: home: \"홈\" about: \"소개\"# 컨트롤러나 뷰에서 사용I18n.t('hello') # =&gt; \"안녕하세요\"t('nav.home') # =&gt; \"홈\"t('welcome_message', name: '홍길동') # =&gt; \"환영합니다 홍길동님!\"Localize (l) 사용 예시# 현재 시간 로컬라이즈I18n.l(Time.now) # =&gt; \"2024년 11월 15일 22:00\"# 다양한 포맷 사용I18n.l(Date.today, format: :short) # =&gt; \"11월 15일\"I18n.l(Date.today, format: :long) # =&gt; \"2024년 11월 15일 금요일\"커스텀 날짜 포맷 정의# config/locales/ko.ymlko: time: formats: custom: \"%Y년 %m월 %d일 %H시 %M분\"# I18n.l(Time.now, format: :custom) # =&gt; \"2024년 11월 15일 22시 00분\"설정# config/application.rbconfig.i18n.{언어설정} += Dir[Rails.root.join('my', 'locales', '*.{rb,yml}')]config.i18n.default_locale = :ko # 한글을 고정하겠다번역은 YAML 또는 Ruby 파일에 저장되며, 기본적으로 config/locales 디렉토리에 위치한다.# config/locales/en.ymlen: hello_world: - Hello - world# config/locales/ko.ymlko: hello_world: - 세상아 - 안녕# 리턴값은 배열의 형태이다.# 단수 복수 설정가능I18n.backend.store_translations :en, inbox: { zero: 'no messages', one: 'one message', other: '%{count} messages'}# I18n.t('inbox', count: 0) # =&gt; \"no messages\"# I18n.t('inbox', count: 1) # =&gt; \"one message\"# I18n.t('inbox', count: 2) # =&gt; \"2 messages\"# I18n.t('inbox', count: 23) # =&gt; \"23 messages\"# 예시 호출함 I18n.t('common.welcome_html', username: '주인장')common: welcome_html: \"&lt;b&gt;Welcome %{username}!&lt;/b&gt;\"View Helper 메서드시간 관련:# 시간 간격을 문자열로 표현distance_of_time_in_words(Time.now, Time.now + 15.minutes)# =&gt; \"15분\" (한국어)# =&gt; \"15 minutes\" (영어)# 날짜 선택 필드 생성datetime_select(\"post\", \"published_at\")# =&gt; 번역된 월 이름으로 select 태그가 생성됨# 월 선택 필드select_month(Date.today)# =&gt; 번역된 월 이름으로 select 태그가 생성됨숫자 관련:# 통화 형식number_to_currency(1234.56)# =&gt; \"₩1,234.56\" (한국어)# =&gt; \"$1,234.56\" (영어)# 정밀도가 있는 숫자number_with_precision(1234.567, precision: 2)# =&gt; \"1,234.57\"# 퍼센트number_to_percentage(65.43)# =&gt; \"65.43%\"Active Model 메서드모델 및 속성 이름 번역:# config/locales/ko.ymlko: activerecord: models: user: \"사용자\" attributes: user: name: \"이름\" email: \"이메일\"# 사용User.model_name.human # =&gt; \"사용자\"User.human_attribute_name('email') # =&gt; \"이메일\"에러 메시지:# 에러 메시지 생성user.errors.generate_message(:email, :blank)# =&gt; \"이메일을 입력해주세요\"# 전체 에러 메시지user.errors.full_messages# =&gt; [\"이메일을 입력해주세요\"]Active Support 메서드배열을 문장으로:# config/locales/ko.ymlko: support: array: words_connector: \", \" two_words_connector: \"와(과) \" last_word_connector: \", 그리고 \"['첫번째', '두번째', '세번째'].to_sentence# =&gt; \"첫번째, 두번째, 그리고 세번째\"이러한 헬퍼 메서드들은 Rails 애플리케이션에서 일관된 다국어 지원을 제공된다고하는데…가독성은 좋을지 몰라도 유지보수에는 좋은지는 모르겠다.참고레일즈 가이드 문서 6.0" }, { "title": "Rails AASM 상태관리와 관계설정", "url": "/posts/assm_releation/", "categories": "Rails, assm, activerecord", "tags": "rails, assm, activerecord", "date": "2024-11-13 22:00:00 +0900", "snippet": "상태 관리에서 매우 중요한 부분이다. Rails에서는 AASM(Acts As State Machine)을 통해 효과적으로 상태를 관리할 수 있다.AASM이란?AASM은 Ruby 클래스에 유한 상태 기계(Finite State Machine) 기능을 추가하는 라이브러리이고. 원래 acts_as_state_machine 플러그인으로 시작했지만, 현재는 ActiveRecord뿐만 아니라 다양한 ORM을 지원하는 독립적인 라이브러리로 발전했다.기본 사용법class Order include AASM aasm do state :draft, initial: true state :confirmed state :shipped state :delivered event :confirm do transitions from: :draft, to: :confirmed end event :ship do transitions from: :confirmed, to: :shipped end event :deliver do transitions from: :shipped, to: :delivered end endend이 코드를 통해 다음과 같은 메서드들이 자동으로 생성된다: draft?, confirmed?, shipped?, delivered? - 상태 확인 confirm!, ship!, deliver! - 상태 변경 may_confirm?, may_ship?, may_deliver? - 상태 변경 가능 여부 확인AASM의 장점 명확한 상태 관리: 상태와 전환 규칙을 명확하게 정의 유연한 확장성: 다양한 ORM 지원 안전한 상태 전환: 유효하지 않은 상태 전환 방지 자동 검증: 상태 변경 전/후 검증 가능AASM을 활용하면 복잡한 상태 관리 로직을 깔끔하게 구현할 수 있고, 코드의 가독성과 유지보수성이 크게 향샹된다. 💡 Tip: 상태 변경 시 발생할 수 있는 예외 상황을 고려하여 적절한 에러 처리를 추가하는 것이 좋다.DB 관계설정belongs_to하나의 다른 모델에 종속되는 관계를 설정할 때 쓴다. 예를 들어 ‘책은 저자에게 속한다’는 관계다.class Book &lt; ApplicationRecord belongs_to :authorendclass Author &lt; ApplicationRecord has_many :booksendbelongs_to 쓸 때는 반드시 단수형으로 써야 한다. 복수형 쓰면 Rails가 클래스를 못 찾는다.has_many한 모델이 다른 모델의 여러 인스턴스를 가질 수 있을 때 쓴다. belongs_to의 반대 관계라고 보면 된다.class User &lt; ApplicationRecord has_many :posts has_many :commentsendclass Post &lt; ApplicationRecord belongs_to :userend이렇게 설정하면 user.posts로 해당 유저의 모든 게시글을 가져올 수 있다.has_one일대일 관계를 설정할 때 쓴다. belongs_to랑 비슷한데, 외래 키가 반대쪽 테이블에 있다는 게 다르다.class Supplier &lt; ApplicationRecord has_one :accountendclass Account &lt; ApplicationRecord belongs_to :supplierendscope모델에서 자주 쓰는 쿼리를 메서드처럼 정의해서 쓸 수 있게 해주는 기능이다.class Article &lt; ApplicationRecord scope :published, -&gt; { where(status: 'published') } scope :recent, -&gt;(limit) { order(created_at: :desc).limit(limit) }end이렇게 정의하면 이런 식으로 체이닝해서 쓸 수 있다:Article.published.recent(5) 💡 Tip: scope는 항상 ActiveRecord::Relation을 반환해서 메서드 체이닝이 된다. scope 내 scope를 사용가능 클래스 메서드로도 같은 걸 할 수 있는데, scope 쓰면 코드가 더 깔끔하다.실전 예시class User &lt; ApplicationRecord has_many :posts has_many :comments has_one :profile scope :active, -&gt; { where(active: true) } scope :recent, -&gt; { order(created_at: :desc) }endclass Post &lt; ApplicationRecord belongs_to :user has_many :comments scope :published, -&gt; { where(published: true) }endclass Comment &lt; ApplicationRecord belongs_to :user belongs_to :postendclass Profile &lt; ApplicationRecord belongs_to :userend이런 식으로 관계 설정하면 이렇게 쓸 수 있다:user = User.active.firstuser.posts.publisheduser.profilepost.comments관계 설정 잘 해두면 복잡한 쿼리도 직관적으로 작성할 수 있고, 코드 관리도 훨씬 편하다! 1대1 1대N으로 생각하면…class User &lt; ApplicationRecord has_one :cart # 1:1 관계 has_many :orders # 1:N 관계 has_many :product_reviews # 1:N 관계 has_many :reviewed_products, through: :product_reviews, source: :product # N:M 관계 JOIN관계 명시endclass Product &lt; ApplicationRecord belongs_to :category # N:1 관계 has_many :order_items # 1:N 관계 has_many :product_reviews # 1:N 관계 has_many :reviewers, through: :product_reviews, source: :user # N:M 관계 JOIN관계 명시end 💡 Tip: N:M 관계를 설정할 때는 through 옵션을 써서 조인 테이블을 명시해야 한다. 이렇게 하면 user.reviewed_products처럼 직관적으로 접근할 수 있다." }, { "title": "ROR 사용시 혼동되는거 정리", "url": "/posts/ruby_confuse/", "categories": "Rails, ruby", "tags": "rails, ruby", "date": "2023-10-29 13:01:04 +0900", "snippet": "&lt;% &gt; 와 &lt;%= &gt; 차이ERB 뷰작업을 하다보면 mybatis 처럼 동적쿼리를 실행하기 위해서, 즉 상황에 따른 데이터값을 보여주기 위해서 &lt;% &gt;, 와 &lt;%= &gt;를 사용하게 된다.&lt;% &gt;는 출력을 안하고 제어흐름을 관리하는데 사용된다.&lt;%= &gt;는 변수의 값을 문자열로 출력하기 위해서 사용된다.&lt;% if user_logged_in? %&gt; &lt;p&gt;Welcome, &lt;%= current_user.name %&gt;!&lt;/p&gt;&lt;% else %&gt; &lt;p&gt;Please log in.&lt;/p&gt;&lt;% end %&gt;버튼 제작시, 중복클릭에 대한 대비버튼을 만들때, 여러번 요청을 하면 서버단에서 해당 이슈를 막을수도 있지만, 프론트단에서도 처리중으로 표현하는 방법이 필요하다.let isClicked = false; $('#create_stop_order').on('click', function () { if (isClicked) { alert('처리중입니다.'); return; } isClicked = true;또는&lt;%= button_tag \"버튼이름\", type: \"submit\", class: \"btn btn-info\", data: { disable_with: \"처리중입니다.\" } %&gt; 이런식으로 처리한다." }, { "title": "cluster-index와 uncluster-index", "url": "/posts/clustered-index/", "categories": "cluster-index, uncluser-index", "tags": "cluster-index, uncluser-index", "date": "2023-05-17 12:01:04 +0900", "snippet": "Cluster 란?Clustered Index는 단어뜻을 생각해보면 군집화된 인덱스이다. 즉 실제 데이터가 인덱스와 군집되어있다는 뜻이다.클러스터링 인덱스와 넌 클러스터링 인덱스는 두 인덱스 모두 데이터베이스에서 데이터의 접근 속도를 높이기 위해 사용한다.위 처럼 데이터가 들어오는데로 삽입된 상황의 테이블 구조가 있다고 가정해보자.위 테이블은 인덱스가 적용이 안된 한국인이 자주 시켜먹는 배달 순위를 나타낸 Table이다.클러스터형 인덱스클러스터형 인덱스는 테이블 전체가 정렬된 인덱스가 되는 방식의 인덱스 종류이다. 인덱스에 따라 데이터가 지정된 열에 맞춰서 자동정렬되고 테이블 당 한개만 생성이 가능하다.innoDB에서는 디볼트 기본키를 기준으로 클러스터링되어 저장된다. 또는 Unique + Not null로 지정된 컬럼도 클러스터형 인덱스가 생성될 수 있다. (하지만 기본키가 더 우선권을 갖음)위 그림처럼 B+Tree 형태로 구성되어있고 순위를 나타내는 컬럼을 PK로 설정해 클러스터형 인덱스를 만든 형태이다.루트페이지가 Key값으로 PK를 가지고 있고 다른페이지의 번호를 포인터로 지니고 있다.이러한 구조는 검색 속도를 빠르게 하지만, 생성, 업데이트, 삭제 부분에서는 새로 정렬을 해야하므로 느릴 수 밖에 없다.넌클러스터형 인덱스넌클러스터형 인덱스는 원본 데이터 페이지 그대로 유지하고 별도의 페이지에 넌 클러스터형 인덱스를 구성한다. 클러스터형 보다 검색속도는 느리지만 CUD는 빠르다. 데이터를 직접가리키는 것이 아닌 데이터의 위치를 가리키는 포인터 이기 떄문이다. 클러스터형과 다르게 여러개 생성 가능하다.위그림을 보면 리프페이지에서 직접적으로 데이터를 가지고 있는 것이 아닌 데이터 페이지 번호와 해당 행의 위치를 저장하고 있다. 인덱스 페이지(Root + Leaf)는 정렬되어있으나 DATA page는 처음에 저장했던 순서 그대로이다.혼합된 클러스터형 인덱스 + 넌 클러스터형 인덱스보통 인덱스 처리를 할때, 위와같이 혼합해서 사용하는 경우가 많다. PK는 기본적으로 존재해야 테이블을 생성할 수 있고, 추가로 조회가 자주 발생하는 부분에 대해 인덱스를 처리하기 떄문이다.이럴경우 위와같은 구조로 작동한다. 순위에대해 PK를 지정하고 음식에 대해 클러스터형 인덱스를 설정한 모습이다.넌클러스터형에 왜 PK값을 넣는거죠? 일 두번하는 거 아닌가요? 라는 의문이 생길수 있다.물론 조회만 일어나면 맞는말이지만, 만약에 테이블에 1순위가 스테이크 로 바뀌고 치킨이 11위로 밀렸다고 가정해보자.기존의 경우에는 아래의 클러스터 인덱스 부분들만 정렬하고 음식 인덱스에 대해서는 값만 추가해주면 된다. 하지만 넌클러스터형의 예시처럼 데이터페이지의 주소와 값을 가지고 있다면 넌 클러스트형 인덱스까지 모두 수정해야하는일이 발생한다.사실, 기본키값인 순위가 변동성이 큰 값이라 해당 예시가 적절지 못할수도 있다고 생각한다. 하지만, 핵심은 이렇게 간접적으로 데이터를 가짐으로써 인덱스의 이점과 CUD가 왔을때 최악의 상황을 방지하는 방지턱의 역할로 이해하면 좋을꺼 같다." }, { "title": "SSE Spring에서 구현하기 A to Z", "url": "/posts/sse/", "categories": "SSE, server side event", "tags": "SSE, server side event", "date": "2023-05-08 13:01:04 +0900", "snippet": "SSE란?SSE(Server-Sent Events)는 웹 애플리케이션에서 서버로부터 데이터를 비동기적으로 전송받을 수 있는 기술 중 하나이다.클라이언트의 별도의 요청이 없이도 알림처럼 실시간으로 서버에서 데이터를 전달해야할때가 있다. 이럴때 단방향으로 통신을 지원하며 서버로 데이터를 보낼수없다는 단점이 있지만, 실시간 업데이트가 필요할때는 효율적으로 데이터를 전달할 수 있다.물론, SSE 방식외에도 클라이언트가 주기적으로 서버로 요청을 보내서 데이터를 받는 Short Polling , 서버의 변경이 일어날때까지 대기하는 Long Polling 방식이 있지만, 해당 프로젝트는 실시간으로 반영되어야하고 빈번하게 발생 될 수있는 상황이기에 SSE를 선택하였다.SSE는 서버와의 한번 연결을 하고나면 HTTP 1.1의 keep alive와 비슷하게 서버에서 변경이 일어날떄마다 데이터를 전송하는 방법이다.SSE 구조와 구현 Client 하나당 sseemitter하나SSE의 기본적인 흐름은 클라이언트가 SSE요청을 보내면 서버에서는 클라이언트와 매핑되는 SSE 통신객체를 만든다(SseEmitter)해당객체가 이벤트 발생시 eventsource를 client에게 전송하면서 데이터가 전달되는 방식이다. sseemitter는 SSE 통신을 지원하는 스프링에서 지원하는 API이다.위 그림은 SSE 플로우이다. 위 그림에 맞춰서 하나하나 Spring에서 구현하고 설명하겠다.맨처음 클라이언트에서 SSE 요청이 오면 서버는 위 그림과 같이 기본적인 응답해더값과 더불어 필요한 헤더들을 반환해야한다. (초록 화살표) 그러기 위해서는 컨트롤러, 서비스에 해당 로직을 작성해야한다. 아래의 controller를 보자.//컨트롤러\t@GetMapping(value = \"/connect\", produces = \"text/event-stream\")\tpublic ResponseEntity&lt;SseEmitter&gt; sseConnection(@RequestHeader(value = \"Last-Event-ID\", required = false, defaultValue = \"\") String lastEventId, HttpServletResponse response) {\t\treturn new ResponseEntity&lt;&gt;(notificationService.connection(lastEventId, response), HttpStatus.OK);\t}lastEventId를 파라미터로 받는 이유는 로그인 정보를 기반으로 미수신 event 유실을 예방하기 위해서이다.자 이제 service를 구현해보겠다. 인터페이스는 따로 작성하지않겠다.해당 서비스는 노란 화살표에 해당되는 내용이다. 클라이언트로부터 SSE 연결 요청을 받아서, user정보와 HttpServletResponse값을 토대로 connection 메서드를 작성한다. //서비스@Service@RequiredArgsConstructorpublic class NotificationServiceImpl implements NotificationService {\tprivate static final Logger log = LoggerFactory.getLogger(NotificationService.class);\tprivate static final Long DEFAULT_TIMEOUT = 120L * 1000 * 60; // SSE 유효시간\tprivate final EmitterRepository emitterRepository;\t@Override\tpublic SseEmitter connection(String lastEventId, HttpServletResponse response) {\t\tString userid = \"user\"; // 로그인 정보를 기반으로 만들어야하는 곳이다.(로그인을 구현하지않아서 user라고 고정함)\t\tString id = userid + \"_\" + System.currentTimeMillis(); // 데이터 유실 시점 파악 위함\t\t// 클라이언트의 sse 연결 요청에 응답하기 위한 SseEmitter 객체 생성\t\t// 유효시간 지정으로 시간이 지나면 클라이언트에서 자동으로 재연결 요청함\t\tSseEmitter emitter = emitterRepository.save(id, new SseEmitter(DEFAULT_TIMEOUT));\t\tresponse.setHeader(\"X-Accel-Buffering\", \"no\"); // NGINX PROXY 에서의 필요설정 불필요한 버퍼링방지\t\t// SseEmitter 의 완료/시간초과/에러로 인한 전송 불가 시 sseEmitter 삭제\t\temitter.onCompletion(() -&gt; emitterRepository.deleteAllStartByWithId(id));\t\temitter.onTimeout(() -&gt; emitterRepository.deleteAllStartByWithId(id));\t\temitter.onError((e) -&gt; emitterRepository.deleteAllStartByWithId(id));\t\t// 연결 직후, 데이터 전송이 없을 시 503 에러 발생. 에러 방지 위한 더미데이터 전송\t\tsendToClient(emitter, id, \"연결되었습니다. \" + id + \"님\");\t\tif (!lastEventId.isEmpty()) { // 클라이언트가 미수신한 Event 유실 예방, 연결이 끊켰거나 미수신된 데이터를 다 찾아서 보내준다.\t\t\tMap&lt;String, SseEmitter&gt; events = emitterRepository.findAllStartById(userid);\t\t\tevents.entrySet().stream()\t\t\t\t\t.filter(entry -&gt; lastEventId.compareTo(entry.getKey()) &lt; 0)\t\t\t\t\t.forEach(entry -&gt; sendToClient(emitter, entry.getKey(), entry.getValue()));\t\t}\t\treturn emitter;\t}... 생략emitterRepo에 save(id, ssemitter(timeout))을 저장함으로써 향후 이벤트가 발생됐을때 클라이언트에게 데이터를 전송할 수있다.이때 repo에서는 sseEmitter를 관리하는 스레드들이 콜백할때 스레드가 다를수 있기에 ThreadSafe한 구조인 ConcurrentHashMap을 사용해서 해당 메시지를 저장해야한다.또한, 초기에 클라이언트에게 메시지를 보내줘야하는데 이유는 데이터의 전송이 없으면 503에러를 발생시키기 떄문이다.\t@Override\tpublic void sendToClient(SseEmitter emitter, String id, Object data) {\t\ttry {\t\t\temitter.send(SseEmitter.event()\t\t\t\t\t.id(id)\t\t\t\t\t.name(\"sse\")\t\t\t\t\t.data(data));\t\t} catch (IOException e) {\t\t\temitterRepository.deleteAllStartByWithId(id);\t\t\tlog.error(\"SSE 연결 오류 발생\", e);\t\t}\t}이를 방지하기 위에 위와같이 간단하게 요청을 보내면된다. 필자는 “000님 연결되었습니다”“로 대체 했다.마지막으로 클라이언트가 미수신한 Event에 대해서 전부 전송을 하기위한 findAllstartById(userId)를 구현해주면 SSE의 기본적인 셋팅이 마무리된다.아래는 Repo를 구현한것이고 repo를 설명한 후에는 send라는 메서드를 만들어서 실시간으로 eventlisten해야하는 곳에 세팅을 하면된다.@Repository@RequiredArgsConstructorpublic class EmitterMyBatisRepository implements EmitterRepository {\tprivate final Map&lt;String, SseEmitter&gt; emitters = new ConcurrentHashMap&lt;&gt;();\tprivate final Map&lt;String, Object&gt; eventCache = new ConcurrentHashMap&lt;&gt;();\t@Override\tpublic SseEmitter save(String id, SseEmitter sseEmitter) {\t\temitters.put(id, sseEmitter);\t\treturn sseEmitter;\t}\t@Override\tpublic void saveEventCache(String id, Object event) {\t\teventCache.put(id, event);\t}\t@Override\tpublic Map&lt;String, SseEmitter&gt; findAllStartById(String id) {\t\treturn emitters.entrySet().stream()\t\t\t\t.filter(entry -&gt; entry.getKey().startsWith(id))\t\t\t\t.collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\t}\t@Override\tpublic void deleteAllStartByWithId(String id) {\t\temitters.forEach((key, emitter) -&gt; {\t\t\tif (key.startsWith(id)) emitters.remove(key);\t\t});\t}}repo는 정말 단순하기 떄문에 별도의 설명은 하지않겠다. 앞서 말한듯이 thread safe하게 설계하면 문제될게 없다.다만 EC2가 두대 이상으로 스케일 아웃을 한다면, concurrentHashMap 이 아닌 redis pub/sub방식을 이용해야 동작할 것이다.다시 서비스단으로 돌아와서 제일 핵심 로직인 send를 구현할 것이다. userId와 title(알림에 사용될 타이틀), content (알림내용), EnumType(입고,출고 여부)를 담은 Notification 클래스를 만들고 위에 ID별로 저장해두었던 데이터를 가져온다. 그리고 초기에 설정해두었던 sendToClient에 데이터를 보내면 SSE통신이 완료된다.//서비스\t@Override\t@Transactional\t// 알림 보낼 로직에 send 메서드 호출하면 됨\tpublic void send(String title, String content, NotificationType notificationType) {\t\tString id = \"user\";\t\tNotification notification = createNotification(id, title, content, notificationType);\t\t// 유저의 모든 SseEmitter 가져옴\t\tMap&lt;String, SseEmitter&gt; sseEmitters = emitterRepository.findAllStartById(id);\t\tsseEmitters.forEach(\t\t\t\t(key, emitter) -&gt; {\t\t\t\t\t// 데이터 캐시 저장 (유실된 데이터 처리 위함)\t\t\t\t\temitterRepository.saveEventCache(key, notification);\t\t\t\t\t// 데이터 전송\t\t\t\t\tsendToClient(emitter, key, notification);\t\t\t\t}\t\t);\t}Nginx 도입시 주의점Nginx가 was로 요청을 보낼때는 http/1.0으로 데이터를 보내는데, 1.0은 connection을 keep alive하지않는다. 그래서 connection 헤더는 close를 사용하게되면서 sse 통신이 close되는 문제점이 발생된다. 그래서 nginx cofig에는 꼭 아래와같이 설정을 해야한다.proxy_set_header Connection '';proxy_http_version 1.1;또한, 위에서 말한것처럼 Nginx는 서버의 응답을 버퍼 형태로 모아두고 서버가 응답 데이터를 모두 보내면 클라이언트로 전송을 하는 구조인데 SSE는 이게 언제 크기가 종료될지 비동기적으로 작동하기에 실시간성이 떨어진다. 따라서 X-accel기능을 헤더에 심어서 보내주면 nginx의 proxy buffering기능을 SSE 통신에는 적용안할수가 있다." }, { "title": "Redis Cache Spring boot에서 사용하기", "url": "/posts/cache/", "categories": "global cache, local cache", "tags": "global cache, local cache", "date": "2023-05-01 13:01:04 +0900", "snippet": "캐시란?동일하면서 반복적인데 연산까지 오래걸리는 것을 미리 저장해서 다시 같은 요청이 왔을때 빠르게 응답하는 것이다.자주 참조되고 변경 사항이 적고 동일한 입력에 대해 동일한 응답이 보장된 데이터를 캐싱처리하는게 좋다. 아래의 그림을 봐도 정말 다양하게 캐시를 처리하는 구간이 많다는걸 알 수 있다.로컬캐싱 글로벌 캐싱이란?로컬 캐싱은 클라이언트 측에서 캐시데이터가 저장되는 걸 의미한다. 즉 유저가 이전에 요청한 데이터나 파일 등을 브라우저 내부에 저장하여, 동일한 요청이 다시 들어올 경우 브라우저가 서버에 요청하는 대신 캐시된 데이터를 반환하는 것이다.글로벌 캐싱은 서버 측에서 캐시데이터가 저장되는 것을 의미한다. 서버에 캐싱된 데이터를 여러 지역에 위치한 캐시 서버에 복제함으로써, 다수의 사용자가 동일한 데이터를 요청할 경우, 가장 가까운 캐시 서버에서 데이터를 제공함으로써, 지연 시간을 최소화하고 대역폭을 효율적으로 사용할 수 있다.로컬 캐싱은 HTTP 캐시 헤더와 같은 클라이언트 측의 기술을 사용하여 이루어지고, 글로벌 캐싱은 CDN (Content Delivery Network)과 같은 서버 측의 기술을 사용하여 이루어진다.MEMCACHE랑 Redis차이« 수정중»" }, { "title": "Jenkins 를 활용해서 도커 이미지 배포 및 실행", "url": "/posts/Jenkins/", "categories": "Docker, Jenkins", "tags": "docker, jenkins", "date": "2023-04-23 11:01:04 +0900", "snippet": "Final Goal젠킨스를 활용하여 CI/CD를 구축하는 것이다.HTTPS에 공개키 비밀키 통신을 원리를 아는사람은 이 플로우가 이해될 것이다. 젠킨스 EC2 : Jenkins, DockerHub, JDK 11, Gradle 7.6.1(젠킨스에서 제공), Docker를 설치. 배포 EC2 : JDK 11, Docker (각자의 스팩에 맞게끔…)최종 서버구조 플로우젠킨스 설치가장 처음으로 해야하는 것은 당연하게도 EC2 인스턴스 2개를 만드는 것이다.필자는 EC2 우분투로 EC2 두개를 만들었다. (참고로 앞으로 sudo 엄청 붙이는데 귀찮으면 sudo su 하고 써도 된다. 권장은 안함)wget -q -O - https://pkg.jenkins.io/debian-stable/jenkins.io.key | sudo apt-key add -sudo sh -c 'echo deb http://pkg.jenkins.io/debian-stable binary/ &gt; /etc/apt/sources.list.d/jenkins.list'이렇게 하다보면 GPG 에러가 나올 수 있는데 서명검증이 안된것이니… 아래와같이 입력한다. GPG error: https://pkg.jenkins.io/debian-stable binary/ Release: The following signatures couldn't be verified because the public key is not available: NO_PUBKEY [16자리키] 로그에 뜬 16자리를 복사해서 아래와 같이 명령어를 넣어주면 된다.sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys [16자리키]그 후… 젠킨스를 업데이트하고 재시작하면된다.sudo apt-get updatesudo apt-get upgrade jenkinssudo systemctl restart jenkins모든 설치가 완료 되었으면 아래의 명령어를 통해 active 중인지 확인하면 된다.systemctl status jenkins젠킨스 설정젠킨스를 접속하기 위해선 {EC2 퍼블릭 IPv4 DNS}:8080 으로 접속하면 아래와 같은 화면이 나온다.이때 비밀번호를 입력하라고 하는데 아래의 명령어를 입력해서 나온 비번을 복붙하자sudo cat /var/lib/jenkins/secrets/initialAdminPassword그 후, Install suggested plugins을 선택하고 설치를 하면 젠킨스를 사용할 수 있는 기본적인 세팅이 된다.어차피, 필요한게 있다면 추후 설치하면된다. 젠킨스를 깃헙에 접근 하는 권한주기젠킨스가 github repository에 접근하려면 github에 배포키를 등록해야한다. 그러므로 젠킨스 ec2에서 SSH키를 만들어야한다.$ sudo mkdir /var/lib/jenkins/.ssh$ sudo ssh-keygen -t -rsa -f /var/lib/jenkis/.ssh/[키명칭]그 후, 깃헙 repo에서 Settings &gt; Deploy Keys &gt; Add deploy key 를 통해서 우리가 만든 SSH키를 등록한다.title은 본인이 식별가능한 값 key는 [키명칭].pub 을 cat해서 복붙. .pub 공개키 아무것도 없으면 비밀키젠킨스 Credential 등록하기공개키를 Github에 등록했으니, 이제 우린 그걸 복호화할 비밀키를 젠킨스에게 등록해야한다.Jenkins관리 -&gt; Manage Credentials -&gt; Stores scoped to Jenkins 에서 아래와 같이 Add Credentials 을 클릭한다.필자는 Credentials에 key가 많은게 추후 빌드 시, 숨겨놓은 키 값을 전달 받기 위해 설정해둔 것이다. 다 완성되면 맨 위처럼 지문 모양의 SSH키등록이 보일 것이다.본론으로 돌아가서 앞서 만든 프라이빗키를 복사해온다.$ cat [키명칭]-----BEGIN OPENSSH PRIVATE KEY-----비밀키 내용들-----END OPENSSH PRIVATE KEY-----Kind는 SSH Username with private key, ID는 식별가능한 크레덴셜 ID 그리고 복사해온 데이터를 Private key에 ADD하고 생성하면 끝!젠킨스 ec2와 배포서버 ec2 SSH 연결젠킨스가 설치된 ec2에서 PEM 형식의 키를 만든다.ssh-keygen -t rsa -C \"키이름\" -m PEM -P \"\" -f /var/lib/jenkins/.ssh/[키이름]젠킨스 ec2에서 만든 SSH키의 공개키를 배포서버에 등록한다.$ sudo cat /var/lib/jenkins/.ssh/[키명칭].pub //젠킨스 ec2나온 데이터를 복사한 후$ sudo nano .ssh/authorized_keys //배포서버 ec2붙여넣기를 한다. 이 작업을 통해 젠킨스가 배포서버에 접근할 권리를 얻었다.젠킨스 Publish Over SSH 플러그인 설치Jenkins 관리-&gt; 플러그인 관리 -&gt; Available plugins 에서 Publish Over SSH 검색 후 설치한다.설치 후 Jenkins 관리 -&gt; Configure System에서 Ctrl+F Publish over SSH를 검색하면 아래와 같은 곳을 볼 수 있는데…Path to key 배포 ec2에게 준 공개키를 읽기 위한 비밀키를 보관한 곳의 경로를 입력하고Key에는 비밀키 내용을 복붙한다.SSH Server 추가 버튼을 누르면…아래의 이미지와같이 추가하면된다. Hostname을 백엔드 인스턴스 IP주소라고 했는데 배포서버 IP주소라고 생각하면된다.aws 인스턴스 대시보드 가면 있다. 모든 내용을 입력한 후 TEST Configuration을 진행해서 확인한다.자 여기까지가 젠킨스와 배포서버, Github과의 통신이 연결된 것이다. 다음으론 도커로 배포하기 위해 도커를 설치하자.DOCKER 설치 + Docker Hub repo 만들기설치를 위해서 apt 업데이트를 하자. 그 후 HTTPS 프로토콜을 통해 안전하게 패키지를 다운로드하고 SSL/TLS 인증서를 받아올 수 있도록 도와주는 패키지들을 설치하는 명령어를 입력한다.그 후 변조된 데이터 방지 및 컴퓨터를 보호하기 위해 GPG 키를 설정한다. 안하면 도커가 설치가 안될 것이다.$ sudo apt update //우분투 패키지 인덱스 업데이트$ sudo apt-get install apt-transport-https ca-certificates curl gnupg-agent software-properties-common //HTTPS를 통해 패키지 다운로드를 지원하는 패키지 설치$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - //Docker GPG 키 추가$ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" //Docker repo 추가$ sudo apt-get install docker-ce docker-ce-cli containerd.io //docker Ce 설치$ sudo systemctl start docker // 도커 재시작 도커를 설치한 후 docker Hub에 들어가서 도커 이미지를 저장할 Repo를 생성하면 도커의 세팅은 끝난다.젠킨스 빌드 결과물을 도커로… 여기서 잠깐! 본인이 프리티어 ec2면 꼭 swap 메모리를 설정하자 swap 메모리 설정 $ sudo dd if=/dev/zero of=/swapfile bs=128M count=16 //스왑 파일 생성 프리티어의 메모리는 1GB이니, 권장사항대로라면 2GB를 증설 $ sudo chmod 600 /swapfile // 스왑 파일에 대한 읽기 및 쓰기 권한을 업데이트$ sudo mkswap /swapfile //Linux 스왑 영역을 설정 $ sudo swapon /swapfile //스왑 공간에 스왑 파일을 추가하여 스왑 파일을 즉시 사용할 수 있도록 만든다$ sudo swapon -s //절차가 성공했는지 확인$ sudo nano /etc/fstab // /etc/fstab 파일을 편집하여 부팅 시 스왑 파일을 활성화/swapfile swap swap defaults 0 0 // &lt;&lt;해당 내용을 입력한다. $ free 명령어를 통해 swap 메모리 설정을 확인한다. 이제 정말 다왔다. 젠킨스 빌드 결과물을 도커로 전송하기만 하면 끝난다.docker 그룹에 젠킨스을 추가하여 도커허브에 빌드한 이미지를 푸쉬할 수 있도록 세팅을 해야한다.$ sudo usermod -aG docker $USER //도커 그룹에 현재 사용자 추가 여기선 $USER = jenkins로해도 무방하다.$ su - ${USER} //새 그룹 구성원 자격을 적용, 명령어 입력시 유저 암호를 입력해야함$ id -nG //를 통해 사용자가 잘 추가 됐는지 확인// jenkins docker$ sudo chmod 666 /var/run/docker.sock //도커 서버와 도커 클라이언트 간의 통신을 위한 Unix 소켓 파일의 권한변경 //젠킨스에서 Docker hub로 로그인 해야할 권한설정$ sudo su - jenkins$ docker login이로써 젠킨스은 도커의 acess 권한까지 얻은 것이다. 자 이제 이 모든걸 정리하는 단계가 남았다.젠킨스 빌드 과정 설정 .feat jenkins item새로운 ITEM을 클릭하면 아래와 같은 페이지가 나온다.한번에 많은 이미지를 동시에 배포하고 순서에 따라 배포를 해야하면 Pipeline을 이용해서 배포하면 된다. 하지만 여기선 Freestyle project를 통해서 배포를 할 예정이다.도커에서 redis는 이미 계속 실행중이기 때문에 굳이 pipeline까지 필요없었다.item name은 본인이 원하는데로!!우선 가장 처음으로 해야하는 것은 소스관리 탭에서 Github repo URL을 지정하는것이다. 그 후, 앞서 설정했던 깃헙 Credentials를 선택한다.(아마 처음 하시면 한개만 있을 것이다.)그리고 우린 프론트와 같은 repo를 쓰기때문에 main 브랜치가 아닌 백엔드 브랜치를(*/bedev) 이용해서 작업을 진행했다.Delete workspace before build starts를 체크해야 작고 소중한 EC2 용량을 아낄 수 있다.Send files or execute commands over SSH after the build runs 을 클릭한다.1번에다가 아래의 내용을 입력한다.sudo docker pull ${docker hub name}sudo docker stop ${docker name} || true &amp;&amp; sudo docker rm ${docker name} || true sudo docker run -d --network=\"host\" --name ${docker name} -p {배포 서버 포트}:{젠킨스 서버 포트} -p {레디스 서버 포트}:{젠킨스 ec2 레디스 서버 포트} -e \"REDIS_HOST=localhost\" ${docker hub name} // redis가 localhost를 못 찾을때 하는 설정이다. sudo docker run -d --name [containerName] -p 8080:8080 [dockerHub UserName]/[dockerHub Repository]:[version] // redis를 사용하지않는다면 이 명령어를 입력하면된다.Build 탭에서 Add build step &gt; Execute shell 선택하여 명령어를 입력한다.// 2sudo chmod +x ./be/gradlew // 프로젝트의 gradlew의 권한을 부여한다. cd /var/lib/jenkins/workspace/asap/be // 저장되어 있는 프로젝트 위치를 찾는다../gradlew clean build //// 3sudo docker build -t {dockerHub UserName} -f {/dockerHub Repo경로/Dockerfile} .sudo docker push {dockerHub UserName}대망의 자동배포 설정플러그인 설치Jenkins 관리-&gt; *플러그인 관리 *-&gt;** Available plugins 에서 github **Integration을 설치한다. **젠킨스 webhook 설정해당 프로젝트 item에서 빌드 유발 탭에서 GitHub hook trigger for GITScm polling 체크한다.Github Webhook 추가Settings &gt; Webhooks &gt; add Webhook을 통해 webhook을 추가한다.Payload URL 설정[구축서버 인스턴스 URL]:[젠킨스 PORT]/github-webhook/content type은 application/json으로 설정한다.이것으로 CI/CD가 완성되었다~~~" }, { "title": "Nginx의 역할과 설정", "url": "/posts/Nginx/", "categories": "Nginx, WEB", "tags": "nginx, web", "date": "2023-04-13 11:01:04 +0900", "snippet": "NGINX란 무엇인가?Nginx는 오픈소스이고 웹 서버와 리버스 프록시 SW이다. 아파치와 마찬가지로 HTTP 요청을 처리하고 다른서버로의 요청을 전달한다.아파치에 비해 기능은 적지만 경량화 되어있어 EC2 프리티어에서 잘돌아가도록 사용할 수 있다. 즉, 고성능과 높은 안정성을 제공한다. 리버스 프록시란? 서버 앞단에서 문지기와 같은 존재, 트래픽 분산과 보안, 캐싱 처리에 좋다. (밑에서 설명예정) 반대로 포워드 프록시 개념은 정부나 보안이 높은 기관에 속한 사람들의 인터넷을 제한적으로 사용할떄 쓰는 개념이다.NGINX와 아파치의 차이점아파치는 클라이언트의 요청이 들어올때마다 하나의 프로세스를 만든다. 프로세스를 만드는 작업에서 많은 시간이 소요되다보니 PREFORK 방식으로 요청이 오기전에 미리 프로세스를 만드는 방식으로 구성되어있다. 하지만, 이러한 구조는 동시에 엄청나게 많은 커넥션이 있을때, 메모리 부족을 야기한다. 그래서 나온 개념이 Nginx이다.※ 참고로 prefork MPM방식 외에도 Worker MPM라는 방식으로 요청을 할 수 있다. prefork와 worker Nginx는 이벤트 기반 처리 구조방식이다. 아까 말한 수많은 커넥션의 메모리 부하를 크게 줄이는 취지에서 나온 웹서버이다. 위의 그림에서 PREFORK 방식을 보면 커낵션마다 프로세스를 만드니까 요청이 많으면 💣하고 메모리가 터질 수 있다. 그럼 도대체 이 많은 커낵션을 어떻게 유지하냐? 비결은 Master process에 있다.cd /etc/nginx/~/ ??.confg 하고 들어가면 있는 설정파일을 읽고 그에 맞는 worker process를 만든다. 그리고 그에 맞는 listen 소캣을 배정받는다. worker process는 보편적으로 CPU 프로세스 수만큼 master가 생성하고 관리한다.공홈에서 가져온 이미지인데 잘 안보이지만 핵심은 Master process, cache loader, cache manager, worker이다.Nginx에서는 커넥션의 생성, 제거, 처리를 이벤트라고 한다. 이러한 이벤트는 OS커널에서 큐형식으로 worker process에게 전달한다. 이런 이벤트들이 하나의 큐상태로 비동기상태로 대기를 하고 있고 worker process는 이벤트를 poll()하며 하나씩 해결해 나아간다. 이러한 방식은 커넥션 낭비현상을 줄여주게 된다.(PREFORK 방식에서는 프로세스는 할당되어있는데 놀고있는 상태가 생길 수 있다.)하나의 이벤트, 즉 큐에 담겨있는 하나의 요청이 다른 큐들에 비해 처리속도가 길면 그 자체로 손해아닌가? 라는 질문이 생길 수 있다. Nginx는 이것 또한 해결할 수 있게 구상을 하였다. Thread pool에 따로 이러한 요청을 처리하는 공간을 마련해두어, 설정을 통해 일정시간 오래 걸리는(용량이 큰)이벤트를 worker process가 Thread pool에게 위임을 하고 큐에 담긴 다른 이벤트를 처리하는 방식으로 문제를 해결한다.이번 프로젝트에서 NGINX를 도입한 이유낮은 EC2 메모리 성능과 은근 많이 사용되는 css, js의 정적페이지를 빠르게 제공을 위해서, 그리고 SSL 인증서를 발급받기 쉬워서? 이다. (그리고 대세이기도 하고….)위처럼 nginx.conf에서 캐싱설정이나 (동적 캐싱은 redis를 사용하기 때문에 따로 안했다) proxy 설정을 쉽게 할 수 있고 Let’s Encrypt를 사용하면 무료로 SSL을 발급시켜주고 인증서를 자동으로 등록시키고 발급해준다. 90일이라는 유효기간이 있지만 이 또한 갱신이 쉬워서 많이들 사용한다.Nginx의 SSL 터미네이션브라우저와는 https로 연결하고 서버와의 통신에서는 http로 통신하는 방법이다.컴퓨터의 성능이 아무리 좋아졌지만, 복호화를 하는 과정은 서버에게 부담이 될 수 밖에없다. 비즈니스 로직에 좀 더 힘을 쓸 수 있도록 구성한 방식이다. http 통신을해서 위험하지 않냐? 라는 의문이 들수도 있지만 하나의 컴퓨터 또는 하나의 네트워크 안에서 통신하기 떄문에 http 통신의 위험 요소가 적다.Nginx config 설정을 바꿀떄마다 restart를 무조건해야하나?우선 정답부터 말하면 그럴필요없다. nginx -s reload 나 systemctl reload nginx를 통해 기존 연결이 종료되지 않고 변경사항이 적용된다.이유는 Nginx는 이벤트 기반 구조로 형성이 되어있어. 개발자가 설정파일을 변경하고 nginx에 적용하면, Master process가 새로운 worker process를 만들어서 해당 설정에 맞는 woker process를 따로 생성한다. 그러면서 기존의 유지되고 있던 커넥션들을 더 이상 사용할 수 없도록 관리해준다. 이런점이 로드 밸런서의 역할을 통해 무중단 배포를 할 수 있는 환경을 제공하는 것이다.이 링크는 Nginx 커스텀 기본세팅을 알려주는 사이트인데 개인적으로는 공식홈피나 블로그를 참고해서 설정하는게 더 빠르고 쉬운거같다." }, { "title": "Spring용어,웹서버 그리고 Spring MVC", "url": "/posts/springMVC/", "categories": "MVC", "tags": "spring, mvc", "date": "2023-03-21 11:01:04 +0900", "snippet": "설명하고자하면 늘 잘 안나왔던 이야기를 정리해보고자 한다.BeanFactory, ApplicationContextBeanFactory는 빈을 생성하고 의존관계를 설정하는 기능을 담당하는 가장 기본적인 IoC 컨테이너이자 클래스를 말한다. ApplicationContext는 BeanFactory의 확장된 버전으로써 별도의 정보를 참고해서 빈의 생성, 관계 설정 등의 제어를 총괄하는 것에 초점을 맞춘 것이다.특히 빈을 생성한 후 로딩하는 방식이 다르다. BeanFactory는 빈을 lazy loading 방식으로 로딩한다. 즉, 빈이 처음으로 요청될 때까지 빈이 초기화되지 않는다. 따라서 애플리케이션이 시작될 때 모든 빈을 로딩하지 않아서 애플리케이션 구동 속도가 빠르고 메모리 사용량이 적다.반면에 ApplicationContext는 빈을 eager loading 방식으로 로딩한다. 즉, 애플리케이션을 시작할 때 모든 빈을 초기화하고 미리 로딩한다. 따라서 애플리케이션 구동 속도가 BeanFactory에 비해 느리고, 메모리 사용량이 많아질 수 있다.대신, ApplicationContext는 BeanFactory보다 다양한 기능을 제공한다. 국제화(i18n), 이벤트 발생, AOP(Aspect Oriented Programming), 메시지 처리 등 다양한 기능을 제공한다.Environment프로파일(Profile)을 설정하고 어떤 것을 사용할지 선택할 수 있게 해주며, 소스 설정 및 프로퍼티 값을 가져오게 해준다.MessageSource메시지에 대한 국제화(i18n)을 제공하는 인터페이스이다.i18n은 internationalization(국제화)의 약칭으로 소프트웨어가 언어에 종속적이지 않고 한국어든 영어든 동시에 입력해서 사용할 수 있어야 하는 것을 만족시켜주는 것을 말한다.메세지 설정 파일을 모아서 그 지역에 걸맞는 언어를 로컬라이징을 함으로써 메시지를 제공하는 기능이다.Bean Scope란? 스코프 = 빈이 존재할 수 있는 범위스프링 빈이 스프링 컨테이너의 시작과 함꼐 생성되어서 스프링 컨테이너가 종료될 때까지 유지된다. 이유는 스프링 빈이 기본적으로 싱글톤 스코프로 생성되기 떄문이다.스코프에는 싱글톤,프로토타입, request, session, application이있다.프로토타입 스코프 같은 경우에는 생성과 의존관계 주입까지만 관여하고 그 이후에는 더이상 관여하지않는다. 즉, 해당 빈을 요청할때마다 새로운 인스턴스를 생성해서 반환한다.Web Serever Apache, nginx웹서버는 정적 컨텐츠(HTML, CSS, IMAGE)의 요청을 바로 응답을 하거나 동적 컨텐츠를 WAS에게 넘겨주는 역할을 한다. 이외에도 SSL에대한 암호화와 복호화 작업을 하기도 한다. 로깅, 가상호스팅, 권한부여, 캐싱 등이있다.Web Application Server앞서 말한대로 동적인 컨텐츠를 처리하기 위한 서버이다. 사실 HTTP API를 응답하는 그 모든 역할을 하는 샘이다. 이렇게만 보면 WAS 하나로 시스템을 구성할수도 있다.그리고 실제로도 가능하다. 하지만 WAS가 너무 많은 역할을 하게되면 서비스 지연이 일어나면서 다운될 수 있다. 실제로 naver에서 개발자모드만 켜봐도 정적인 콘텐츠가 얼마나 많은지 알 수 있다. 그래서 트래픽이 많이 발생하는 사이트는 웹서버를 로드벨런싱을 목적으로 사용하기도 한다.웹서버 = 정적 리소스 WAS = application 로직 Client -&gt; Web Server (정적 컨텐츠) Client -&gt; WAS -&gt; DB (서버 과부하 우려) Client -&gt; Web Server -&gt; WAS -&gt; DB (MVC와 템플릿엔진,API)위 3가지 구조 중 하나를 가질 수 있다. 필자가 자주 사용하는 3번으로 얘기해보고자 한다.Client(브라우저) -&gt; Web Server(Apache) -&gt; WAS(Tomcat) + Servlet(ServletDispatcher) -&gt; DI Container -&gt; ControllerWeb server (아파치)웹서버는 이미 저장되어 있는 정적인 컨텐츠(html)을 응답한다. 만약 사용자가 직접 정보를 검색하거나 저장하려면 web server의 문서를 직접 고쳐야했다.그러기에 이러한 점을 동적으로 변하는 페이지가 필요로 하게 되었고, 동적인 처리를 담당하는 CGI(Common Gateway Interface)가 나왔다. CGI는 서버와 응용 프로그램간에 데이터를 주고받기 위한 방법이나 규약을 뜻한다 웹 브라우저의 HTML의 폼을 통해 요청이 웹 서버로 전달 웹 서버는 요청에 들어 있는 주소가 CGI 프로그램에 대응되는지 확인 대응될 경우 그 프로그램을 실행, 환경 변수와 표준 입력의 형태로 요청을 전달한다. 웹 서버는 CGI 프로그램이 표준 출력으로 돌려 보낸 내용을 그대로 응답으로 돌려 준다. 이러한 CGI 방식은 멀티프로세스 방식을 취하므로 요청이 올때마다 프로세스를 늘려야했고 이는 자원낭비로 이어졌다. 이를 해결하기위해 멀티쓰레드 방식인 자바의 Servlet이 등장했다.참고로, 스프링 부트에서는 resources.static 폴더에 html 파일을 올리면 정적인 콘텐츠를 올려준다. 공식 문서 링크서블릿서블릿은 자바에서 만든 확장된 CGI다. 앞서 설명한 기본 CGI와는 다르게 멀티스레드 방식으로 동작한다. 서버가 시작되고 서블릿을 만들게 되면 메모리에 저장해두고, 같은 서블릿을 사용하여 요청을 처리한다.처음 웹서버로 요청이 전달 되었을때 동적인 컨텐츠를 응답해야 할 경우 동적인 컨텐츠를 전담하는 Web Application Server 로 요청을 전달한다.서블릿의 역할은 서버 TCP/IP 대기, 소캣연결 -&gt; HTTP 요청 메시지를 파싱해서 읽고 -&gt;POST 방식, URL 요청 -&gt; Content-Type 확인 -&gt; HTTP 메시지 바디 내용 파싱 -&gt; 저장 프로세스 실행과 비즈니스 로직으로 부터 받은 데이터를 HTTP 응답메시지로 생성해서 보내느것과 TCP/IP에 응답 전달과 소켓종료의 이런 반복동작을 자동화 해준다.서블릿 컨테이너 (WAS)JAVA의 대표적인 Servlet Container(WAS)는 Apache Tomcat으로 각각의 서블릿을 실행하고 관리하는 역할을 대신해준다. 요청마다 스레드를 만들고, 통신을 위한 소켓을 연결하고, 서블릿의 생성과 소멸 주기 관리를 모두 Container가 담당한다. 서블릿 컨테이너는 서블릿 객체의 생성,초기화, 종료하는 생명주기를 관리 (빈의 생명주기) 서블릿 객체는 싱글톤으로 관리된다. JSP도 서블릿으로 변환되어서 사용된다. 동시 요청을 위한 멀티 쓰레드 처리 지원여기서 발생하는 튜닝실력… 최대 쓰레드 수를 너무 높게 잡으면 서버 리소스가 과하게 사용될 수 있고, 너무 낮게 잡으면 클라이언트가 접속에 불편을 겪게될 수 있기 때문에 개발자가 적절하게 컨트롤할 수 있어야 한다.Annotation 기반 스프링 MVC 등장이제서야 스프링 MVC에 대해 얘기할 수 있다. spring에서 서블릿을 사용하고 있다면 대부분 프론트 컨트롤러인 dipatcher servlet을 사용한다. 여담으로 과거에는 mvc model 1에서는 컨트롤러단에서 view와 자바코드가 혼재되어 유지보수가 어려웠다고 한다.현재는 스프링 MVC는 Front Controller Pattern을 구현하고 있다. 앞단에 Dispatcher Servlet이 하나의 서블릿으로 모든 것을 관리하기 떄문에 코드의 중복도도 엄청나게 줄어 들었다.다시말해 WebServer -&gt; WAS(Tomcat) -&gt; ServletDispatcher 순으로 요청을 전달 받게 된다. Spring MVC 는 ServletDispatcher라는 Servlet으로 요청이 오면 녀석이 요청의 url을 분석하여 해당 요청을 수행할 수 있는 Spring Bean(Controller)에 요청을 보내준다.특이하게도 정적 자원이 오면 컨트롤러를 탐색하고 난뒤에 resourse.static 디렉토리를 탐색하게 된다고 한다.##" }, { "title": "Basic Confusing Questions Ⅲ 🤷‍♂️ ", "url": "/posts/self_Q&A/", "categories": "CS, Questions", "tags": "cs, questions", "date": "2023-03-10 11:01:04 +0900", "snippet": " Servlet과 Spring의 차이 서블릿은 http의 요청이나 응답을 받아 처리하는 기본 클래스입니다. 하나의 요청이왔을때 응답을 주는 구조로 설계된 구조입니다. 하지만 이는 요청마다 서블릿을 정의해야하는 단점이 있었고 그래서 나온개념이 디스패처 서블릿입니다. spring은… 정규화의 장·단점 정규화란?DB의 중복을 제거하고 데이터를 구조화하는 과정입니다. 이를 통해 이상현상을 줄일수 있습니다. 하지만, 과도한 정규화로 인해 복잡한 구조와 성능 저하를 일으킬 수 있습니다. 로드벨런싱 L7과 L4에 대해 설명해보시오 L4 로드밸런싱은 IP 주소와 포트 번호를 기반으로 트래픽을 분산하는 방식입니다. L4 로드밸런서는 OSI 모델의 4계층(전송 계층)에서 동작하며, TCP 및 UDP와 같은 전송 계층 프로토콜을 사용하여 트래픽을 분산합니다. L7 로드밸런서는 HTTP 및 HTTPS와 같은 응용 계층 프로토콜을 사용하여 트래픽을 분산합니다. L7 로드밸런서는 트래픽의 내용에 따라 트래픽을 분산하는 기능을 제공합니다. 예를 들어, L7 로드밸런서는 URL, 쿠키, 헤더 등의 정보를 기반으로 트래픽을 분산할 수 있습니다. 랜덤접근, 순차접근의 장·단점 랜덤접근(Random Access)과 순차접근(Sequential Access)은 컴퓨터에서 데이터에 접근하는 방식입니다. 랜덤접근의 장점은 데이터를 검색하는 데 걸리는 시간이 매우 짧다는 것입니다. 데이터를 삽입하거나 수정하는 작업도 매우 빠르게 처리할 수 있습니다. 그러나 데이터의 크기가 매우 큰 경우에는 처리 시간이 길어질 수 있습니다. 또한 데이터의 구조도 알아야합니다. 순차접근은 데이터의 처음부터 끝까지 순서대로 접근하는 방식입니다. 데이터의 구조에 대한 정보를 미리 알지 못해도 처리할 수 있다는 장점이 있습니다. 하지만 검색, 수정에 있어 매우 느립니다. ArrayList()와 Vector의 차이 ArrayList와 vector의 차이는 thread safe 여부입니다. vetor는 내부적으로 synchronized를 통해 데이터의 일관성을 보장합니다. 하지만 그에따라 속도가 느려집니다. 또한 동적으로 데이터를 할당할때마다 ArrayList는 50% 증가하는 반면 vector는 100% 용량을 증가 시킨다. 응집도와 결합도에 대한 설명 응집도는 높을수록 결합도는 낮을 수록 좋다응집도는 얼마나 모듈 속의 코드들이 단일한 목적으로 수행되는지의 여부 응집도의 좋은예 public class Calculator { public int add(int a, int b) { return a + b; } public int subtract(int a, int b) { return a - b; } public int multiply(int a, int b) { return a * b; } public int divide(int a, int b) { return a / b; }} 메서드가 명확하게 분리되어있고 독립적으로 작동함. 응집도의 나쁜예하나의 class에서 get, set이 있고 불분명한 메소드와 복잡한 리턴값을 가지는 구조를 예로 들수 있다. 결합도는 모듈간의 의존성을 나타낸 것 DI 주입받아 하는게 결합도가 낮은 설계 SOAP와 REST API의 차이 둘다 웹서비스 방식이지만, SOAP은 XML 기반의 메시지 교환을 위한 프로토콜입니다. SOAP은 WSDL (Web Services Description Language)을 사용하여 서비스를 설명하고, 서비스의 메서드를 XML로 정의하며, SOAP 메시지를 보내고 받을 수 있습니다. SOAP는 보안과 트랜잭션 관리를 지원하며, 복잡하고 많은 기능을 제공하지만, 처리 속도가 느리고, 구현이 복잡합니다. REST는 HTTP 프로토콜을 기반으로 구현되는 API입니다. REST는 URL을 사용하여 리소스를 정의하며, HTTP 메서드를 사용하여 리소스에 대한 액션을 정의합니다. REST는 경량화된 구조를 가지고 있으며, 간단하고 빠른 처리가 가능합니다. REST는 보안과 트랜잭션 관리 기능이 SOAP보다 제한적이지만, 구현이 쉽고 성능이 우수합니다.SOAP는 보안이나 복잡한 트랜잭션 처리가 필요한 경우에 적합하며, REST는 간단하고 빠른 처리가 필요한 경우에 적합합니다. JDK JRE JVM 간단하게 설명 JDK는 자바 개발 도구를 제공하는 패키지이며,JRE는 자바 애플리케이션을 실행할 수 있는 런타임 환경이며,JVM은 자바 애플리케이션을 실행하기 위한 가상 머신입니다 Spring과 Springboot 차이 Spring 다양한 모듈과 라이브러리를 지원하여 유연성이 높다. DI, AOP, MVC 등의 기능을 제공하여 개발 생산성을 높일 수 있다. 다양한 데이터베이스와 연동이 가능하며, ORM 프레임워크인 Hibernate와 연동하여 사용이 가능하다. 단점: 설정이 복잡하고, 기능이 복잡한 만큼 학습이 어려울 수 있다. 배포 및 운영에 있어서도 서버의 환경에 맞게 설정하는데 시간이 많이 소요된다. 초기 세팅과 프로젝트 생성이 번거롭다. Spring Boot Spring의 설정을 자동화하여 개발자가 손쉽게 개발할 수 있도록 도와준다. 내장된 톰캣, Jetty 등의 WAS를 이용하여 개발을 진행할 수 있어, 배포와 실행이 간편하다. 간단한 프로젝트나 마이크로서비스 등의 빠른 프로토타이핑 및 개발에 적합하다. 단점 프로젝트의 규모가 커질수록 설정을 추가하거나 수정할 필요가 있다. Spring의 기능과 라이브러리를 모두 내장하고 있어, 불필요한 부분도 함께 내장되어 무거울 수 있다. 기존의 Spring Framework에 비해 고급 설정이나 커스터마이징이 어려울 수 있다. Call by value 와 Call by reference 이 둘은 함수 호출 방식이 어떤 방식으로 매개변수를 전달하는 지에 따라 다릅니다.Call by value는 값에 의한 호출이라고도 하며, 함수가 호출될 때 인자로 전달되는 변수의 값을 복사하여 전달합니다. 따라서 함수 내부에서 매개변수의 값을 변경해도, 호출한 측의 변수 값에는 영향을 미치지 않습니다. 자바가 대표적인 예입니다. public static void swapByValue(int x, int y) { int temp = x; x = y; y = temp;}public static void main(String[] args) { int a = 10; int b = 20; swapByValue(a, b); System.out.println(\"a=\" + a + \", b=\" + b);} call by reference는 참조에 의한 호출이라고도 하며, 함수가 호출될 때 인자로 전달되는 변수의 참조를 전달합니다. 따라서 함수 내부에서 매개변수의 값을 변경하면, 호출한 측의 변수 값도 함께 변경됩니다. public static void swapByReference(int[] arr) { int temp = arr[0]; arr[0] = arr[1]; arr[1] = temp;}public static void main(String[] args) { int[] arr = {10, 20}; swapByReference(arr); System.out.println(\"arr[0]=\" + arr[0] + \", arr[1]=\" + arr[1]);} web server와 was의 차이 Web Server: 정적인 콘텐츠 처리에 최적화되어 있으며, 대체로 WAS보다 빠릅니다.WAS: 애플리케이션 로직을 수행하므로 일반적으로 웹 서버보다 느립니다. Web Server는 주로 정적인 콘텐츠 처리에 중점을 두며, WAS는 애플리케이션 로직을 수행하고 데이터베이스 연동 등의 작업을 처리합니다. 이 두 가지 서버를 적절하게 조합하여 하나의 웹 어플리케이션을 구성할 수 있습니다 API vs 라이브러리 vs Framework 차이 API: 다른 SW에서 개발중인 sw를 사용하도록 정의된 interface입니다. 다른 프로그래머가 작성한 코드를 다른 개발자가 쉽게 이용하도록 만든 인터페이스입니다. 라이브러리는 코드의 모음이고 개발자에 의해 특정 기능을 쉽게 구현할 수 있게해주는것. 프레임워크 코드, 라이브러리의 집합이고, 개발자가 모든 생성과 구조를 만들거나 수정하는 것이 아닌 일부 규격을 따르거나, 프레임워크에게 생명주기를 위임함으로써 로직에 좀더 집중하도록 도움주는 것. 불변객체 가변 객체 불변객체 객체 생성 이후 상태를 변경할 수 없는 객체 = String, 멀티스레드 환경에서 안전하게 객체를 공유할수 있다. 가변객체 객체 생성이후 상태를 변경할 수있는 객체 = ArrayList, 스레드 safe 하지않다. 직렬화 vs 역직렬화 직렬화 : 자바 시스템 내부에서 사용되는 객체 또는 데이터를 외부의 자바 시스템에서도 사용할 수 있도록 바이트(byte) 형태로 데이터 변환하는 기술.캐시와 서블릿 세션을 예로 들수 있습니다. 직렬화를 사용하지 않는 이유:직렬화 데이터는 타입, 클래스 메타정보를 포함하므로 사이즈가 크다. 트래픽에 따라 비용 증가 문제가 발생할 수 있기 때문에 JSON 포맷으로 변경하는 것이 좋다 이진탐색 시간복잡도 이진 탐색은 정렬이 되어있다는 가정하에, 중앙부터 값을 탐색하는 알고리즘입니다.O(logn) 비교로 원하는 값을 찾아 갈 수 있음.이로 인해 삽입, 삭제 이벤트 발생시 등 추가적인 작업이 필요함. 병합 정렬, 퀵정렬 둘다 divide &amp; conquer 알고리즘입니다. 둘다 평균 시간복잡도는 O(nlogn)입니다.퀵정렬의 최악일 경우에는 O(n^2)이고 병합은 항상 nlogn 의 시간복잡도를 가집니다.자바는 ARRAY의 경우 듀얼 피봇, Collections에는 Tim sort를 사용합니다.(병합정렬+삽입정렬) 프로세스와 스레드, 멀티 프로세스, 멀티스레드 프로세스 는 OS에 실행되는 프로그램의 단위입니다. 스레드는 프로세스 내부 실행 단위입니다. 멀티 프로세스는 여러 개의 프로세스를 동시에 실행하는 것을 말하며, 각 프로세스는 독립적으로 메모리 공간을 할당받아 실행됩니다. 따라서 IPC를 이용해 프로세스 간에 통신해야 합니다. 멀티 스레드는 하나의 프로세스 내에서 여러 개의 스레드를 동시에 실행하는 것을 말하며, 각 스레드는 프로세스 내에서 메모리를 공유하면서 실행됩니다. 이러한 멀티 스레드는 프로세스 간 통신이 필요하지 않기 때문에, 멀티 프로세스보다 더 빠르고 경제적으로 동작할 수 있습니다. IPC(Inter-Process Communication)란 무엇인가? IPC(Inter-Process Communication)는 서로 다른 프로세스 간에 데이터를 주고받는 기술을 말합니다. 프로세스 간에 통신을 할 때는 IPC를 이용해야 합니다. 이는 프로세스가 서로 독립적으로 메모리 공간을 가지기 때문에, 각 프로세스가 가진 자원을 공유하거나, 프로세스 간의 데이터 전달이 필요할 때 사용됩니다. IPC 기술에는 파이프, 메시지 큐, 공유 메모리 등이 있습니다. 파이프(Pipe)는 일방향으로 데이터를 전송하는데 사용되며, 부모와 자식 프로세스 간의 통신에 사용됩니다. e.g) 부모 P -&gt; 자식 P or 자식 P -&gt; 부모 P 메시지 큐(Message Queue)는 우편함과 같은 역할로, 여러 프로세스가 메시지를 큐에 보내고 받아서 데이터를 전달할 수 있습니다. e.g) , 서버에서 클라이언트로 메시지를 전송하거나, 다른 어플리케이션으로 데이터를 전달하는 등의 경우에 메시지 큐가 사용 공유 메모리(Shared Memory)는 메모리 공간을 공유하는 것으로, 하나의 프로세스가 공유 메모리에 데이터를 쓰면, 다른 프로세스에서도 해당 데이터를 읽어올 수 있습니다. e.g) 데이터베이스 서버에서 다른 어플리케이션으로 데이터를 전달하거나, 웹 서버에서 백그라운드 작업을 처리하는 등의 경우에 공유 메모리가 사용 IPC를 이용하면, 각각 독립적으로 실행되는 프로세스 간의 데이터 전달이 가능해지므로, 프로세스 간 협력이 필요한 다양한 프로그램에서 유용하게 사용됩니다. 예를 들어, 데이터베이스 서버에서 다른 어플리케이션으로 데이터를 전달하거나, 웹 서버에서 백그라운드 작업을 처리하는 등의 경우에 IPC가 사용됩니다. 뮤텍스 세마포어 모니터락 뮤텍스 락과 언락을 통해 메소드를 제공하는 동기화 기법입니다.임계 구역(critical section)에 하나의 스레드만 진입할 수 있도록 합니다. 뮤텍스는 하나의 스레드만 임계 구역에 진입하도록 보장하지만, 공유 자원에 대한 동기화가 필요한 경우에는 세마포어를 사용합니다. 세마포어는 뮤텍스와 마찬가지로 동기화 기법 중 하나입니다. 공유 자원의 개수를 나타내는 카운터와 wait, signal 메소드를 제공합니다. wait 메소드는 카운터를 감소시키고, 카운터가 0이면 스레드를 대기시킵니다.signal 메소드는 카운터를 증가시키고, 대기 중인 스레드 중 하나를 깨웁니다. 모니터 락은 객체에 대한 상호 배제를 위한 동기화 기법입니다.모니터 락은 자바에서 synchronized 키워드를 이용하여 구현됩니다.모니터 락은 메소드나 블록 단위로 적용되며, 락을 얻은 스레드만 임계 구역에 진입할 수 있습니다.모니터 락은 뮤텍스와 달리 대기 중인 스레드에 대한 우선순위를 지정할 수 있습니다. " }, { "title": "Index... 랜덤 Io, 순차 IO", "url": "/posts/about-index/", "categories": "SQL, index", "tags": "sql, index", "date": "2023-02-23 11:01:04 +0900", "snippet": "인덱스인덱스를 왜쓸까?인덱스는 조회성능 개선 - 디스크 I/O를 줄이는게 핵심이다.테이블의 특정 데이터를 생성한다면, 해당 컬럼의 데이터를 정렬 후, 별도의 메모리 공간에 데이터의 물리적 주소를 Key, Value 형태로 저장한다.많은 쿼리들의 대부분의 요청은 GET요청 방식이다. 수정 삭제에서 손해를 보더라도 검색속도와 시스템의 부하가 작아지기 때문에 사용한다.Where 절 일때, 특정 조건의 데이터를 찾기 위해서 FULL TABLE 스캔을 해야하는데 인덱스를 통해서 전부다 조회할 필요가 없어진다.OrderBy, MIN/MAX 시, DB에서 직접 정렬을 해야하나 인덱스가 설정된 테이블은 정렬이 되어있으므로 읽기만 하면되므로 속도가 빠르다.GroupBy 역시 정렬되어있는상태에서 그룹핑을 하는것이 떄문에 많은 부분을 넘겨서 읽을 수 있다.그럼 인덱스처리를 다하지 왜 다 안하는가?앞서 말한 것 처럼 인덱스는 항상 정렬 상태를 유지해야하므로 IUD(insert,update,delete)시 추가작업이 필요하다. INSERT : 새로운 데이터에 대한 인덱스를 추가 UPDATE : 기존의 인덱스를 사용하지 않음 처리, 갱신된 데이터에 대한 인덱스 추가 DELETE : 삭제하는 데이터의 인덱스를 사용하지 않는다는 작업 수행이처럼 인덱스의 수정도 추가적으로 필요하기 때문에 데이터의 수정이 잦은 경우 성능이 낮아진다. 또 데이터의 인덱스를 제거하는 것이 아니라 ‘사용하지 않음’으로 처리하고 데이터를 남겨두기에, IUD 작업이 많은 경우 실제 데이터에 비해 인덱스가 과도하게 커지는 문제점이 발생할 수 있다. 별도의 메모리 공간에 저장되기 때문에 추가 저장 공간이 많이 필요하게 된다. 아래의 예시를 보자 왼쪽에 index로 정리되어있는 테이블. ID 2 와 4를 삭제함. ID에 auto increment가 적용되어있을떄 2와 4가 비어있는 공간에 6과7이 들어감.인덱스는 전체 데이터의 10 ~ 15% 이상의 데이터를 처리하거나, 데이터의 형식에 따라 오히려 성능이 낮아질 수 있다. 예를 들어 나이나 성별과 같이 값의 range가 적은 컬럼인 경우, 인덱스를 읽고 나서 다시 많은 데이터를 조회해야 하기 때문에 비효율적이다.인덱스를 그럼 언제 쓸까? 데이터의 범위가 크고 중복이 적고 (카디널리티가 높다, 얼마나 유니크한지) 조회가 빈도가 많다 정렬한 이점이 많은경우 사용하는것이 좋다. 규모가 큰 테이블 IUD가 적은 컬럼 JOIN, WHERE, ORDER BY가 자주 호출되는 컬럼필자의 경우 3번과 7번에 해당되는 경우라, cloudFront 서비스에서 인기 객체 지표를 보여주는 사이트를 통해 알아보았다. 보면 memberlist 랭킹을 나타내는 지표가 홈페이지 주소다음으로 많이 요청되는 것을 볼 수 있다.인덱스 실행 계획ALL: 테이블 전체를 스캔Index가 없는경우, 있어도 할때가 있다.–&gt; 옵티마이저가 전체갯수가 적거나 읽고자하는 데이터가 전체 데이터의 20~25퍼 이상일때 Full table Scan 발생Range: 인덱스를 이용하여 범위 검색index full scan: 인덱스 전체를 스캔 all보단 빠르다.복합 인덱스란?두 개 이상의 칼럼을 합쳐서 인덱스를 만드는것. 하나의 컬럼으로 인덱스를 만들었을 때 보다 더 적은 데이터 분포를 보여 탐색할 데이터 수가 줄어든다.결합인덱스, 다중 컬럼 인덱스, Composite index라고도 함.주로 WHERE절에서 조건 컬럼이 2개이상이고 AND절 일때 사용된다 OR에서는 금지예 )서울사는 남자를 조회할 경우SELECT place, sexFROM peopleWHERE place = 'seoul'AND sex = 'M'CREATE INDEX idx_name_sexON people(place, sex);생성시 칼럼의 순서가 중요하다. 남녀가 반반이라고 가정해보자place =&gt; sex 순으로 조회로 했을때 5천만-&gt; 서울인구 1천만 -&gt; 0.5천만 (5000+1000 = 6000번 탐색) sex -&gt; place 순으로 조회로 했을때 5천만-&gt; 남자 2.5천만 -&gt; 0.5천만 (5000+2500= 7500번검색)후자의 방식대로 검사하면 같은 값이 나오지만 1500번 더 일을하게 하므로 생성 시, 순서를 고려해야한다.커버링 인덱스란?인덱스로 설정한 컬럼만 읽어 쿼리를 모두 처리할 수 있는 인덱스, 불필요한 디스크 I/O를 줄여 조회시간을 단축하는 것Select문을 사용할떄 와일드카드 (*) 대신 원하는 값만 적용하여 인덱스 활용인덱스 컨디션 푸쉬다운MySQL이 인덱스를 사용하여 테이블에서 행을 검색하는 경우의 최적화를 의미한다. 인덱스 컨디션 푸시다운을 활성화하고 인덱스의 컬럼만 사용하여 where 조건의 일부를 평가할 수 있는 경우 MySQL 엔진은 WHERE 조건 부분을 스토리지엔진으로 푸시하는 경우다. 5.6부터는 자동으로 적용된다고 한다. 이로인해 그림처럼, DB 내부에서는 불필요한 I/O 및 데이터 전송 과정이 줄어들게 되고, 클라이언트 입장에서는 보다 빠른 응답 성능을 기대할 수 있다.인덱스 자료구조다양한 자료구조가 있지만 해시테이블과 B+Tree를 설명하고자한다.해쉬테이블Hashtable은 Key, Value를 한 쌍으로 데이터를 저장하는 자료구조이다. 해시 충돌이라는 변수를 제외하고 O(1)의 검색속도로 원하는데이터를 구할 수 있다.하지만, 이 해쉬테이블은 인덱스에서 잘 사용하지않는다. key = value 이렇게 1대1 매칭되는 데이터에 대해 빠르지 부등호나 범위에 대해서는 빠르게 찾을 수 없기 떄문에 해쉬테이블을 사용하지 않는다고 한다.B+ Tree기존의 B-Tree 역시 어느 하나의 데이터의 검색은 효율적이지만, 범위, 부등호에 모든 데이터를 한 번 순회하는 데에는 트리의 모든 노드를 방문해야 하므로 비효율적이다. 이러한 B-Tree의 단점을 개선시킨 자료구조가 B+Tree이다.B+Tree는 마지막 노드인 Leaf Node에 데이터를 저장하고 다른 중간노드에는 자식의 포인터만 저장한다. 특이한 점은 데이터가 leaf node에만 저장되기에 중간 노드에 key값이 중복될 수 있다.이로인해 하나의 NODE에 더많은 포인터를 가질 수 있기에 낮은 트리 높이에도 많은 데이터를 저장하고 메모리를 확보할 수 있다. 물론, 특정 Key값에 접근하려면 leaf node까지 가야하는 단점이 있지만, 부등화와 범위 검색에 이점을 가져가고자 나온 자료구조이다.랜덤 I/O 와 순차 I/O 순차 I/O가 훨씬 빠르게 작용한다 MySQL 특성상 순차I/O로 바꾸는게 어렵다. 랜덤I/O를 하되 row의 갯수를 줄이는데 있다.랜덤 I/O는 읽어야하는 데이터가 물리적으로 불연속적으로 있기 때문에 디스크 헤더를 이동 시킨 다음 데이터를 읽는 것을 의미한다.순차 I/O는 읽어야하는 데이터가 연속적으로 있어 쭉 읽기만 하는 경우를 의미한다.데이터를 10번 읽어야 한다고 가정하자. 데이터 위치가 물리적으로 연속적이라면 디스크 헤드를 한번 이동시키면 되지만, 불연속적이라면 디스크 헤더를 10번 이동시켜야한다. 즉, Seek Time(디스크 헤드를 이동시킨 시간)이 사실상 디스크에 데이터를 읽고 쓰는데 걸리는 시간을 좌우한다. 따라서 디스크의 성능은 디스크 헤더의 이동 없이 얼마나 많은 데이터를 순차적으로 저장하느냐에 달렸다.HDD와는 다르게 SSD는 디스크 원판이 없어서 랜덤 I/O와 순차 I/O가 큰 차이가 없을 것 같지만 SSD에서도 랜덤 I/O는 순차 I/O 대비 throughput이 떨어진다.DBMS는 디스크에 데이터를 빈번히 읽고 쓰기 때문에 MySQL 서버에서는 그룹 커밋이나 바이너리 로그, InnoDB 로그 버퍼등의 기능이 내장되어 있다.쿼리를 튜닝한다고 랜덤 I/O가 순차 I/O로 변하는 상황은 많지 않다고 한다. 즉, 쿼리 튜닝의 목적은 랜덤 I/O를 줄이는 것이다. 즉, 꼭 필요한 데이터만 읽도록 쿼리를 개선하는 것이 중요하다.인덱스 레인지 스캔은 데이터를 읽기 위해 주로 랜덤 I/O를 사용하고, 풀 테이블 스캔은 순차 I/O를 사용한다. 따라서 큰 테이블의 레코드를 읽는 작업을 할 때 옵티마이저가 인덱스 대신 풀 테이블 스캔을 하도록 유도하는 경우도 있다고 한다." }, { "title": "OS - Memory", "url": "/posts/vitrualmemory/", "categories": "CS, memory", "tags": "cs, memory", "date": "2023-02-12 11:01:04 +0900", "snippet": "OS 정리운영체제의 역할 CPU 스케줄링과 프로세스 관리 (CPU 소유권을 얼마만큼 할장할지, 프로세스의 생성과 삭제 할당을 관리, 반환함.) 메모리 관리 (한정된 메모리를 어떤 프로세스가 관리할지 할당) 디스크 파일 관리 I/O 디바이스 관리 (키보드 마우스의 데이터 주고받음)이렇게 크게 4가지가있다. 하드웨어와 USER 프로그램 사이에 존재하여 해당 역할들을 수행한다.하드웨어 -&gt; 드라이버, 커널, 시스템콜, GUI or CUI -&gt; USER programGUI or CUICUI는 명령줄 인터페이스로써 도스, CMD, bash를 뜻하는 환경이다.GUI 여기서 좀 더 발달해서 그래픽으로 제어하고 볼 수 있는 환경을 GUI라고 한다.시스템콜OS가 커널에 접근하기 위한 인터페이스이면서 유저 프로그램이 OS의 서비스를 받기 위해 커널 함수를 호출할 때 사용한다.USER PROGRAM이 입/출력을 요청 시, 올바른 요청인지 확인하고 유저 lv이 시스템콜을 통해 커널lv로 변환되어 실행된다.쉽게말해 하나의 추상화 계층으로써, 유저모드의 파일을 그대로 읽는 것이 아닌 시스템 콜을 통해 커널lv로 진입하여 파일을 읽거나 수정하거나 한다. 이런 점은 직접적인 접근을 차단하고 프로그램을 다른 프로그램으로부터 지킬 수 있다. 유저lv : 유저가 접근할 수 있는 영역을 제한적으로 두어 컴퓨터 자원의 무분별한 진입을 막는 모드커널lv: 모든 컴퓨터 자원을 접근할 수 있는 모드커널: OS의 핵심 부분이면서 시스템콜 인터페이스를 제공하며 보안부터 메모리, 프로세스 File 시스템 등 OS의 중추적인 역할을함.드라이버OS와 디바이스가 서로 통신할 수 있는 sw 구성요소. 보통 마우스나 컴퓨터의 I/O를 담당하는 디바이스에 이런 드라이버를 설치하는 경우가 종종있는데 이는 드라이버를 통해 데이터를 가져오거나 입력받은 데이터를 OS가 이해할 수 있도록 변환 시켜주는 역할을 한다고 보면된다.CPU + RAM 사이메모리에 내용을 얘기하기 전, 메모리 앞단에서 일어나는 일에 대해 알필요가 있다. CPU에 해당되는 캐시와 레지스트리인데 둘의 기능과 차이에 대해 알아보자.레지스터란 CPU안에 있는 작은 메모리로써 작은 메모리와 휘발성을 가지고 있으며 용량도 매우 적다. 일반적으로는 현재 계산을 수행중인 값을 저장하는데 사용된다.캐시 메모리란, 속도가 빠른 장치(CPU)와 느린 장치(RAM) 사이에서 속도차에 따른 병목 현상을 줄이기 위한 범용 메모리를 지칭한다. 이를 통해 데이터를 접근하는 시간이 오래 걸리는 경우를 해결하고 다시 계산하는 시간을 절약할 수 있는 것이다. 이 둘은 어떤 명령어나 데이터를 저장하는 공간이지만, 캐시는 CPU에 별도 공간이 있고 메모리와 CPU의 속도차이의 버퍼같은 존재이고 레지스터는 CPU 내에서 연산을 처리하기 위한 데이터 저장공간이다.메모리 관리OS의 대표적인 일 중의 하나인 컴퓨터 내의 한정된 메모리 자원을 극한으로 활용하는 것이다. 그 중 극한으로 사용하는 방법 중 하나인 가상메모리에 대해 알아보자.가상메모리란? 메모리 관리 기법으로 하나로 컴퓨터가 실제 이용 가능한 메모리 자원을 추상화하여 이를 USER에게는 큰 메모리로 보이게하는 방법이다. 그러기 위해선 가상 주소와 실제주소를 연결하는 PAGE TABLE이 있어야한다.PAGE TABLE이란?page table은 위와같이 가상주소와 실제 주소를 mapping하는 테이블이다. 메인 메모리에 존재하며 프로세스마다 고유의 page table을 가진다. context switching(프로세스를 교체) 할 때마다 page table도 변경돼야 한다. 즉, CPU가 어느 page table을 사용할지 알아야 한다.그림처럼 page table는 메인 메모리에 존재한다. CPU는 명령어를 수행하기 위해서 메인 메모리에 최소 2번은 접근해야 원하는 데이터를 얻을 수 있다. 이는 명령어 하나하나에 같은 table이어도 메인메모리에 접근해야하는 불필요한 상황이 연출된다. 이러한 접근을 줄이고자 나온 개념이 Traslation Look-aside Buffer (TLB)이다.TLB이란?메모리와 cpu 사이에 있는 주소 변환을 위한 캐시이다. 페이지 테이블에 있는 리스트를 보관하며 cpu가 페이지 테이블까지 가지않도록 관리하여 속도를 향상시킬 수 있는 캐시 계층이다. 쉽게 말해 page table의 캐시 역할을 한다.TLB에 정보가 없을떈 TLB miss라고 하는데 2가지 상황으로 나뉜다.TLB에는 없지만 Main 메모리에 있을 경우: Page table을 가져와서 (physical memory) 위 그림의 TLB에 저장하면 된다.Page Fault = 요청한 page가 Main 메모리에도 없는 경우 : 이떄는 하드디스크로 부터 데이터를 불러와 TLB에 저장할 수 있고 Main 메모리에서 불러오는 속도에 비해 10000배정도의 차이가 있다고 한다.Page Fault로 스와핑하는 케이스 CPU는 물리메모리를 확인하여 해당 페이지가 없으면 트랩을 발생해서 OS에 알린다. OS는 CPU 동작을 잠시 멈춤 OS는 페이지 테이블을 확인하여 가상 메모리에 페이지가 존재하는지 화깅ㄴ하고, 없으면 프로세스를 중단하고 현재 물리 메모리에 비어있는 공간이 찾는다. 그 조차도 없으면 스와핑이 발동된다. 스와핑메모리에서 당장 사용하지않는 영역을 하드디스크로 옮기고 디스크의 일부분을 마치 메모처럼 불러와 사용하는 행동 비어있는 공간에 해당 페이지를 로드하고 Page table을 업데이트한다. 중단했던 CPU가 다시 시작한다." }, { "title": "Inno DB", "url": "/posts/inno-db/", "categories": "MySQL, InnoDB", "tags": "mysql, innodb", "date": "2023-02-06 11:01:04 +0900", "snippet": "Inno DB란? MySQL architecture 　　 Transaction-safe 한 기본 MySQL Storage Engine이다. 높은 안정성과 고성능을 가지고 균형을 이룬 범용 스토리지 엔진이다. CREATE TABLE문을 실행하면 자동으로 InnoDB 테이블 생성된다. ※ MyISAM와의 차이점: InnoDB와 다르게 table과 index를 각각의 다른 파일로 관리함, Read Only기능면에서는 효율적인 서비스InnoDB 엔진 주요 특징 inno db architecture □□ Tablespace : Segment(오브젝트)라는 □□의 논리적 저장공간의 집합, 크기조절 가능 　　 InnoDB 테이블은 기본 키를 기반으로 쿼리를 최적화하기 위해 디스크의 데이터를 정렬한다. 각 InnoDB 테이블에는 기본 키 조회를 위한 I/O를 최소화하기 위해 데이터를 구성하는 클러스터형 인덱스라는 기본 키 인덱스가 있다.클러스터링 : 여러개를 하나의 기준으로 묶는다. Row Lv 락은 멀티 유저의 동시성과 성능을 향상시켜준다. 락을 걸지않고 작업을 수행하면서, 다른 트랜잭션이 갖고있는 락을 기다리지않고 읽기 작업이 가능함 (MVCC라고도 한다. Multi verson Concurrency Control) In-memory 구조로 데이터와 인덱스를 메모리에 캐싱하기 위한 Buffer Pool이 있다. 데이터의 무결성을 지키기 위해 외래키 제약조건을 지원한다. 외래키를 사용하면 관련 테이블간에 불일치가 발생하지 않도록 CRUD를 검사한다.Buffer Pool버퍼풀은 InnoDB를 엑세스할때 테이블과 인덱스 데이터를 캐시하는 메인메모리 영역이다.자주 사용하는 데이터를 메모리에서 직접 접근할 수 있도록 해서 처리속도를 높인다. 전용서버에서는 물리적 메모리의 최대 80%를 버퍼 풀에 할당한다고 한다.버퍼풀은 LRU (Least Recently Used) 알고리즘으로 가장 최근에 사용되지 않은 페이지를 제거하고 새페이지를 풀러오는 방식으로 데이터를 관리한다. Buffer Pool이 커지면 커질수록 캐싱되는 데이터 양이 늘어나므로 I/O를 상대적으로 적게하면서 성능이 향상된다.Change BufferChange Buffer는 해당 페이지가 버퍼 풀에 없을때 secondery index 페이지에 대해 변경 사항을 캐시하는 구조이다. 페이지가 다른 읽기 작업에 의해 버퍼풀에 반영될때, Change Buffer는 DML(Insert, update, delete)의 결과값을 병합시킨다.Periodic merge(주기적 병합)을 하는 secondary index는 정렬된 순서로 삽입하는 클러스터형 인덱스와는 다르게 고유하지않고 삽입과정 또한 Randomly 하게 진행된다. 이는 최신 상태로 유지하기 위해서는 디스크에 상당한 I/O를 발생시킨다. 이러한 문제점을 해결하기 위해 DML작업이 발생하면 실시간으로 업데이트 하지않고 체인지 버퍼를 통해 변경사항을 캐시하는것이다.체인지 버퍼의 경우 DML 후 보조 인덱스를 최신 상태로 유지하는데 사용되는 상당한 I/O를 줄일 수 있는 장점이 있지만, 다만 과거 디스크가 느린 시절에 큰 효과가 있었지 SSD 등 디스크의 성능이 개선됨에 따라 극적인 성능 개선을 가져오지는 않는다. 또한 변경 사항이 많을 경우 재부팅, 복구 작업이 지연될 수 있기에 주의해야한다. 이러한 이유 때문인지 Aurora MySQL의 경우 체인지 버퍼를 사용하지 않는다고 함.(None으로 설정되어있으며 변경 불가)Log Buffer 와 Redo LogLog Buffer는 디스크의 로그 파일을 기록할 데이터 보관 메모리영역이다. 기본크기는 16MB이고 주기적으로 디스크에 FLUSH된다.Redo Log는 장애시 Buffer Pool에 저장되어 있던 데이터의 유실을 방지, 데이터를 복구 하기 위해 사용된다.DML 문장이 수행되면 데이터가 변경되기 전에 우선 메모리에 변경할 내용을 기록한다. 변경할 내용을 기록하는 메모리 영역을 Redo Log Buffer라고 한다. 메모리 영역은 용량이 제한적이기 때문에 Checkpoint 이벤트 발생시점에 Redo Log Buffer에 있던 데이터들을 Disk에 File로 저장하게 된다. 이 파일을 Redo Log File이라 한다. Redo Log File은 두 개의 파일로 구성되는데, 하나의 파일이 가득차면 ‘log switch’가 발생하며 다른 파일에 쓰게 된다. ‘log switch’가 발생할 때마다 Checkpoint 이벤트도 발생하는데, 이때 InnoDB Buffer Pool Cache에 있던 데이터들이 백그라운드 스레드에 의해 디스크에 기록된다.​다시말하자면, Checkpoint 이벤트가 발생하기전 장애가 발생한다면 Buffer Pool에 있던 데이터들은 유실되지만 마지막 Checkpoint가 수행된 시점 or log switch까지의 데이터가 Redo Log File로 남아있기 때문에 이 파일을 사용하여 데이터를 복구할수 있다.Undo log의 작동 예시Undo log는 디비 작업이 잘못되었을때 되돌리는것 DISK 내에 ID 3의 데이터가 저장되어있는 상황에 ID 3을 저장하려고 했을때를 가정INSERT INTO test (ID) VALUES (1), (2), (3); // TEST 테이블에 명령어를 입력했을때 DISK 에는 TEST ID가 3 값을 지니고 있는 상황. VALUES의 값들을 버퍼 풀에다가 넣음 Buffer Pool Disk Undo Log ID ID   1 3   2     3     DISK에 해당 작업을 수행하기전 Undo Log에 DISK 내용을 기록을 남겨둔다. Buffer Pool Disk Undo Log ID ID ID 1 3 3 2     3     그 후 버퍼 풀 작업을 아래와같은 작업을 수행함 하지만 수행중 기본키 중복조건으로 롤백하는 상황이 발생함 Buffer Pool Disk Undo Log ID ID ID 3 1 3   2     3   기존 DISK 작업을 날리고(123) Undo Log의 데이터(3)를 가져오면서 롤백이 되고 해당 트랜잭션이 종료된다. Buffer Pool Disk Undo Log   ID ID   3 3             참고자료https://dev.mysql.com/doc/refman/8.0/en/https://jojoldu.tistory.com/243" }, { "title": "삼성 SW 역량평가 기출문제 - 피자배달거리", "url": "/posts/algorithm1/", "categories": "Java, Algorithm", "tags": "java, algorithm", "date": "2023-02-01 23:11:04 +0900", "snippet": " 클릭하면 그림이 커집니다.역시 삼성문제답게 한번더 꼬아 냈다.마지막에 조합부분을 반대로 생각해서 정리할겸 풀이를 올린다.public class Main { static int answer = Integer.MAX_VALUE; // 추후 최소값을 비교해서 저장해야하므로 넣은 static int[] combo; //조합을 저장할 공간 static int N,M; // 문제에서 언급한 필요값 static List&lt;Point&gt; home = new ArrayList&lt;&gt;(); // 집의 위치 저장공간 static List&lt;Point&gt; pizza = new ArrayList&lt;&gt;(); // 피자의 위치 저장공간 static class Point{ //집과 피자의 주소값을 담기위한 공간 int x; int y; public Point(int x, int y) { this.x = x; this.y = y; } } public static void main(String[] args) { Scanner sc = new Scanner(System.in); N = sc.nextInt(); M = sc.nextInt(); //1번 for(int i=1;i&lt;=N;i++){ for(int j=1;j&lt;=N;j++){ int tmp = sc.nextInt(); if(tmp == 1) home.add(new Point(i,j)); if(tmp == 2) pizza.add(new Point(i,j)); } } combo = new int[M]; //2 dfs(0, 0); System.out.println(answer); //7 } public static void dfs(int compare, int pizPoint) { //6 if(M == compare){ //3.5 System.out.println(Arrays.toString(combo)); int sum = 0; for(Point h: home) { //4 int min = Integer.MAX_VALUE; for (int loc : combo) { //3번에서 만들어놓은 조합집합 min = Math.min(min, Math.abs(h.x - pizza.get(loc).x) + Math.abs(h.y - pizza.get(loc).y)); } sum += min; //5 } answer = Math.min(answer, sum); } else { for (int i = pizPoint; i &lt; pizza.size(); i++) { //3 combo[compare] = i; dfs(compare+1, i+1); } } }} 문제에서 home -&gt; pizza 거리를 구하는 공식을 알려준다 그래서 좌표를 받으면서 pizza와 home의 위치를 각각 ArrayList형태로 저장한다. 추후에 get을 사용해야하기 떄문 그 후 combo라는 저장공간을 만들어낸다. combo는 pizza집중에 몇개를 선택해서 고민할지 에대한 변수다. 그림 가운데 참고 그후 DFS 메서드를 통해 재귀를 도는데 else부분을 먼저 주목해보자.그림처럼 하나하나 비교해가면서 조합을 만들어낸다. 6C4 즉 6개중에 4개를 뽑는 경우의 수를 나타내는 것이다. 15가지를 출력하면 아래와 같다. [0, 1, 2, 3][0, 1, 2, 4][0, 1, 2, 5][0, 1, 3, 4][0, 1, 3, 5][0, 1, 4, 5][0, 2, 3, 4][0, 2, 3, 5][0, 2, 4, 5][0, 3, 4, 5][1, 2, 3, 4][1, 2, 3, 5][1, 2, 4, 5][1, 3, 4, 5][2, 3, 4, 5] 궁금하면 3.5 주석을 지우면 출력할 수 있다. 이처럼 그림은 1번의 상황을 나타낸것이고, 찾는사이즈가 우리가 처음에 설정한 박스크기가 되었을때 해당 재귀를 끝낸다. 만들어놓은 조합을 가지고 집과 하나하나 대조해본다. 그 후 문제에서 알려준 식을 이용해서 비교하여 최소값을 찾는다. 4번 행동이 끝난 후 그 중 가장 작은 값을 저장하고 4번의 행동을 각 기 다른 HOME들과 비교하여 최소값을 찾는다. 이런식으로 3번에서 언급한 15가지 조합을 전부다 비교해서 최소값을 구하고 6이라는 값을 출력하면서 끝이난다." }, { "title": "Spring boot 3.0.0과 Spring Framework 6.x", "url": "/posts/spring300/", "categories": "Spring, Spring boot", "tags": "spring, spring boot", "date": "2023-01-29 13:20:57 +0900", "snippet": "GPT…아직은…시작하기에 앞서 요즘 ChatGPT의 기능에 감동하는 중이다.아직은 완벽하진 않지만 어느정도 포인트를 잡아서 얘기한다.좀 쉬운 말은 확실히 잘 답변한다. 데이터가 더 쌓이고 경험이 쌓인다면 훨씬 좋아질꺼같다.그리고 클라우드 서비스를 쓴다면 WebFlux와 3.0.0은 선택이 아닌 필수다.본론으로 돌아가서…2022 11월 24일 Spring boot 3.0이 General Availability되었다고 한다. 주요 변경점으로는…✔ ` 자바 17을 써라!`17의 주요 특징으로는 Sealed class, Switch 성능개선, record 클래스가 있다.✔ Spring Boot 3.0은 모든 dependencies에 대해 Java EE에서 Jakarta EE API로 마이그레이션 삼성 SDS 인사이트(javax.* 에서 jakarta.* 로 변경) 상표권 이슈로 이름이 변경 되었다. 자주 사용하는 QueryDSL 설정도 javax.persistence.에서 jakarta.persistence.로 바꿔야한다. 레퍼런스 gitissuedependencies { implementation 'com.querydsl:querydsl-jpa:5.0.0:jakarta' annotationProcessor \"com.querydsl:querydsl-apt:${dependencyManagement.importedProperties['querydsl.version']}:jakarta\" annotationProcessor \"jakarta.annotation:jakarta.annotation-api\" annotationProcessor \"jakarta.persistence:jakarta.persistence-api\"}또한 SecurityConfig에서 사용되던 메서드를 아래와 같이 변경해야 에러가 나지않는다고 한다. 공식 레퍼런스authorizeRequests() ➔ authorizeHttpRequests()antMatchers() ➔ requestMatchers()regexMatchers() ➔ RegexRequestMatchers()✔ GraalVM 기반의 Spring Native가 3년간의 실험을 마치고 공식 지원을 시작JVM대신 GraalVM을 사용하여 native app을 실행 가능하게 하며, 스타트업을 줄여주고 메모리 관리를 더 효율적으로 하게된다.여기서 GraalVm은 Graal (가할)은 큰쟁반이라는 뜻은 지닌 불어이고 VM은 JVM 내부에서 실행된다는 뜻에서 생긴말이다. GraalVM은 JIT(Just-In-Time) 컴파일러를 사용하여 Java 및 JVM 기반 애플리케이션의 성능을 가속화할 수 있는 고성능 JDK이다.GraalVM 정의GraalVM, Spring Native (NHN)메모리를 적게 사용하고 컴파일시 네이티브 이미지들이 빠르게 시작된다고 하니 클라우드 서비스를 진행한다면 고려해볼만한 기술인것 같다.✔ 보안상 이슈로 @GetMapping(“/some/greeting”, “/some/greeting/”) 는 더 이상 일치하지 않는다.그외에도…✔ Spring Webflux 에서 Multipart form upload 스트리밍을 위한 PartEvent API 지원.✔ HTTP/RSocket Interface Client를 제공✔ HTTP API 에러 처리를 위한 RFC 7807 스펙을 지원.✔ Spring Boot 2.7.x 는 2023년 11월까지 지원 예정더 많은 내용은 여기를 클릭Spring Boot 3.0.0 Migration 해보기STEP 1. Java 17을 사용해야하기 떄문에 기존에 쓰고있던 환경변수 11대신 17을 설치해서 설정해야한다.STEP 2. Build.gradle에 있는 plugins의 내용을 아래와 같이 바꿔준다.plugins {\tid 'java'\tid 'org.springframework.boot' version '3.0.2'\tid 'io.spring.dependency-management' version '1.1.0'\tid 'org.graalvm.buildtools.native' version '0.9.18'}STEP 3. Project Settings -&gt; Project structure의 프로젝트 SDK를 17이상으로 설정한다.STEP 4. 그후 앞서 언급한 javax로 된 부분을 jakarta.*로 수정하면…짜자잔….후기아직 많은 부분이 익숙하지 않고 어렵다. 하지만 분명 java 17의 변화의 바람이 불고 있다는 점과 클라우드 서비스를 기반으로 한다면 webflux에대한 공부도 해야겠다는 생각이 들었다. 모르는 용어도 많고 정말 공식문서를 단순 해석이 아닌 완전히 이해하는 날이 오길…출처 및 인용https://github.com/spring-projects/spring-boot/wiki/Spring-Boot-3.0-Release-Noteshttps://github.com/spring-projects/spring-framework/wiki/What%27s-New-in-Spring-Framework-6.x/https://spring.io/blog/2022/05/24/preparing-for-spring-boot-3-0" }, { "title": "Isolation Level + Inno DB Lock", "url": "/posts/IsolationLv/", "categories": "SQL, LOCK", "tags": "sql, db, lock", "date": "2023-01-26 12:20:57 +0900", "snippet": "선착순 이벤트를 한다? 100명까지위와 같은 이벤트를 진행한다고 가정했을 떄, 99번째때 참가자가 0.01초까지 같다고 가정했을 때, 누구를 선택할것인가? 필자같은 경우는 wiselife 프로젝트에서 챌린지 인증시각이 10:00시~ 10:10분까지인데 10:09:59 인 사람이 인증을 했을 때, 서버 응답시간으로 인해 인증을 못한다면? 서비스 센터에 바로 전화가 올 것이다.이렇게 엄격하게 ACID특성을 지키면 동시성(Concurrency)를 해결 할 수 없을 것이다. 이 점을 해결할 수 있는 부분이 Transaction의 격리 레벨인 Isolation LV이다. 격리성을 덜 지키는 대신 더 좋은 동시성을 얻을 수 있다.일관성=정합성 ∝ 동시성동시성 제어란 동시에 실행되는 트랜잭션의 수를 최대화 하는 것과 데이터 CRUD 시 데이터의 무결성을 유지하는 것이다. 이것은 트레이드 오프 관계인지라 동시성이 증가하면 일관성은 감소할 수 밖에 없는 반비례 관계이다.또한 동시성은 ‘낙관적 동시성 제어’와 ‘비관적 동시성 제어’로 나뉘는데,낙관적 동시성 제어같은 데이터를 동시에 수정하지 않을 것으로 가정하고 데이터를 읽는 시점에 락을 걸진 않지만 수정하는 시점에서 기존에 읽어온 데이터가 다른 사용자에 의해 변경되었는지 재검사가 필요한 경우비관적 동시성 제어같은 데이터를 동시에 수정할 것으로 가정하고 데이터를 읽는 시점에서 락을 걸고 조회, 갱신 완료 시까지 락을 유지하는 경우InnoDB LOCKLOCK은 트랜잭션 처리의 절차를 보장하기 위한 방법이다. 격리단계에 따라 더 느슨하게 더 강하게 lock을 거는 것이다. 또한, DBMS별로 구현방식과 세부적인 방법이 제각각이기에 사용법을 알고 사용해한다. 필자는 MySQL의 InnoDB의 LOCK을 말할 예정이다.네임드락SELECT GET_LOCK('락이름', 30); //30초 리밋의 락을 만드는것SELECT IS_FREE_LOC('락이름');디비복제를 하던가 데이터를 넘겨야할떄 사용하는 락Shared and Exclusive LocksInnoDB는 공유(S) 잠금과 배타적(X) 잠금의 두 가지 유형의 잠금이 있는 표준 행 수준 잠금을 구현한다. S lock = Read lock S LOCK을 사용하는 쿼리끼는 같은 row에 접근이 가능하다. 내가 이 테이블 읽을꺼니까 입력하지마!LOCK TABLES test READ;UNLOCK TABLES; X lock = Write lock X LOCK이 걸린 row는 어떠한 쿼리도 접근 불가능내가 이테이블 수정할꺼니까 읽지마!LOCK TABLES test READ;Record lock해당 레코드 락은 row가 아닌 DB의 인덱스 레코드에 걸리는 락이다.트랜잭션 ASELECT s1 FROM studnet WHERE s1 = 1 FOR UPDATE; 트랜잭션 BDELETE FROM student where s1 = 1;트랜잭션 A쿼리가 실행되었을떄 student.s1의 값이 1인 인덱스에 X lock이 걸린다. 이 경우에 트랜잭션 B의 쿼리를 실행하려고하면, student.s1의 값이 1인 인덱스에 똑같이 X lock을 걸려고 시도하지만 이미 선점되어있는 상태이기 떄문에 트랜잭션A가 실행완료되기 전까지는 해당 s1 학생을 삭제할 수 없다.Gap lockGap lock은 DB index record의 gap에 걸리는 lock이다. 여기서 gap이란 index 중 DB에 실제 record가 없는 부분이다. 이게 무슨말이냐 하면..아래와 같은 테이블이 있고 현재 ID 칼럼에 인덱스가 걸려있는 상황이다.1~4까지 락이 걸린상태 SELECT ID from t1 where ID BETWEEN 1 AND 5 FOR UPDATE; ID NAME 2   3 홍길동 4   5 아무개 현재 2와 4는 인덱스 레코드가 없다. 이 부분을 index record의 gap이라한다.위처럼 gap lock은 해당 gap에 접근하려는 다른 쿼리의 접근을 막는다. 이는 Record lock이 해당 index를 탈 때, 다른 쿼리의 접근을 막는 것과 동일하다. 둘의 차이점은 record lock이 이미 존재하는 row가 변경되지 않도록 보호하는 반면 gap lock은 조건에 해당하는 새로운 row가 추가되는 것을 방지하기 위함이다. 그 외에도 다양한 락들이 존재한다. dev.mysql.com 참고하시라격리단계Read Uncommitted 가장 낮은 격리 수준, 커밋되지 않은 데이터를 읽을 수 있다.ROLLBACK이 될 데이터도 읽어올 수 있으므로 주의가 필요하다.LOCK이 발생하지 않는다.Read Committed 커밋된 데이터만 읽을 수 있다.read operation마다 스냅샷을 저장한다. 구현 방식이 차이 때문에 Query를 수행한 시점의 데이터와 정확하게 일치하지 않을 수 있다. LOCK이 발생하지 않는다. MySQL에서 많은 양의 데이터를 복제하거나 이동할 때 이 LEVEL을 추천한다.Repetable Read MySQL Default Level이고, 한 번 조회한 데이터를 반복해서 조회해도 같은 데이터가 조회된다.mysql 디폴트 설정mysql&gt; SHOW VARIABLES WHERE VARIABLE_NAME='tx_isolation';+---------------+-----------------+| Variable_name | Value |+---------------+-----------------+| tx_isolation | REPEATABLE-READ |+---------------+-----------------+1 row in set (0.00 sec) SELECT시 현재 시점의 스냅샷을 만들고 스냅샷을 조회한다. 즉, 처음으로 read operation (SELECT)을 수행한 시간을 기록한다. 그리고 모든 read operation마다 해당 시점을 기준으로 consistent read를 수행한다. 그러므로 트랜잭션 도중에 다른 트랜잭션이 커밋되더라도 새로 커밋된 데이터는 조회되지 않는다. 이유는 첫 read시의 스냅샷이 보이기 떄문이다. record lock과 gap lock이 발생Serializable 가장 엄격한 격리 수준이다. SELECT 문에 사용하는 모든 테이블에 shared lock이 발생한다.(A) SELECT state FROM account WHERE id = 1; (B) SELECT state FROM account WHERE id = 1;(B) UPDATE account SET state = ‘rich’, money = money * 1000 WHERE id = 1; (B) COMMIT;(A) UPDATE account SET state = ‘rich’, money = money * 1000 WHERE id = 1;(A) COMMIT; 트랜잭션 A 트랜잭션 B BEGIN   SELECT state FROM account WHERE id = 1\tS lock 발동     BEGIN   SELECT state FROM account WHERE id = 1 S lock 발동 X lock실패 UPDATE account SET state = ‘rich’, money = money * 1000 WHERE id = 1   COMMIT UPDATE account SET state = ‘rich’, money = money * 1000 WHERE id = 1 X lock실패 COMMIT   row에 S lock이 걸려있으므로 데드락 상태로 전환되고 두 개의 트랜잭션은 모두 timeout된다. 즉, 돈은 원금 그대로 남아있게 된다. 이처럼 데이터는 보호되지만 쉽게 데드락이 될 수 있으므로 무차별적으로 사용하면 안된다. // 별도로 정의하지 않으면 DB의 Isolation Level을 따름 @Transactional(isolation = Isolation.DEFAULT) @Transactional(isolation = Isolation.READ_UNCOMMITTED) @Transactional(isolation = Isolation.READ_COMMITTED) @Transactional(isolation = Isolation.REPEATABLE_READ) @Transactional(isolation = Isolation.SERIALIZABLE) 계속해서 언급된 Consistent read이란?read(=SELECT) operation을 수행할 때 현재 DB의 값이 아닌 특정 시점의 DB snapshot을 읽어오는 것이다. snapshot은 commit 된 변화만이 적용된 상태를 의미한다.row에 lock을 걸어 다른 transaction이 할 수 없도록 하는 방법이 가장 단순한 방법이지만 InnoDB 엔진은 동시성이 매우 떨어지기 때문에 consistent read를 하기 위해 lock을 사용하지 않는다.InnoDB 엔진은 실행했던 쿼리의 log를 통해 consistent read를 지원한다. InnoDB 엔진은 각 쿼리를 실행할 때마다 실행한 쿼리의 log를 차곡차곡 저장한다. 그리고 나중에 consistent read를 할 때 이 log를 통해 특정 시점의 DB snapshot을 복구하여 가져온다. 이 방식은 비록 복구하는 비용이 발생하긴 하지만, lock을 활용하는 방식보다 높은 동시성을 얻을 수 있다.한가지 주의해야하는 점은 Update나 Delete같은 DML 쿼리에서는 해당 Consistent read를 적용받지 않는다. where 조건을 사용해도 내가 수정하려고 한 select쿼리로 읽어온 row와 해당 row들을 수정하기 위해서 update 쿼리를 날렸을때 수정되는 row가 다를수 있다는 것이다.아래는 두 트랜잭션이 REPEATABLE READ가 아래와 같이 일어났을때를 나타낸 것이다.트랜잭션 A - isolation: READ COMMITTEDSELECT COUNT(name) FROM STUDENT WHERE name = 'TOM';DELETE FROM STUDENT WHERE name = 'TOM';COMMIT;트랜잭션 B - isolation: READ COMMITTEDINSERT INTO STUDENT(name,score) VALUES ('TOM',100),('TOM',95),('TOM',90);COMMIT;두 트랜잭션이 아래와같이 일어났을떄(A) SELECT COUNT(name) FROM STUDENT WHERE name = 'TOM'; // 데이터가 없는 상황이므로 실행결과는 0 (B) INSERT INTO STUDENT(name,score) VALUES ('TOM',100),('TOM',95),('TOM',90); //non lock 상태이므로 해당 쿼리 실행(B) COMMIT;(A) DELETE FROM STUDENT WHERE name = 'TOM'; // 3 rows 삭제(A) COMMIT;위처럼 consistent read에는 보이지 않는 row에 DML 쿼리가 영향을 준 경우, 그 시점 이후로는 해당 row가 transaction에 보이기 시작한다.위와같은 상황을 회피하기 위해 SERIALIZABLE을 써야한다는 것이다.격리 수준이 낮을때 발생되는 문제점Dirty read커밋이 완료되지 않은 데이터를 다른 트랜잭션이 읽는 케이스. 이로인해 최종 결과가 비일관적으로 저장될 수 있다. Transaction A에서 row를 삽입했다.READ UNCOMMITTED transaction B가 해당 row를 읽는다.Transaction A가 rollback 된다.B는 존재하지않은 데이터를 읽은 케이스르 Dirty read라고 한다.이것이 가능한 이유는 InnoDB 엔진이 transaction을 commit 하는 방법 때문이다. InnoDB 엔진은 커밋이 적용됐던 안됐던 일단 실행된 모든 쿼리를 DB에 적용한다. 즉, 특정 log를 보고 특정 시점의 snapshot을 복구하는 consistent read를 하지 않고 그냥 해당 시점의 DB를 읽으면 dirty read가 된다. 아래는 해당 내용을 언급한 MySQL reference의 내용이다. InnoDB는 커밋에 낙관적 메커니즘을 사용하므로 커밋이 실제로 발생하기 전에 데이터 파일에 변경 사항을 기록할 수 있습니다. 이 기술은 롤백의 경우 더 많은 작업이 필요하다는 단점과 함께 커밋 자체를 더 빠르게 만듭니다.Non Repeatable Read반복해서 같은 데이터를 읽을 수 없게 되는 케이스. 한 트랜잭션에서 같은 쿼리를 두 번 수행할 때 그 사이에 다른 트랜잭션이 값을 수정/삭제하므로 두 쿼리의 결과가 상이하게 나타나는 비 일관성의 문제가 발생한다.Phantom Read반복 조회 시, 결과 집합이 달라지는 케이스. 한 트랜잭션 안에서 일정 범위의 레코드를 두 번 읽을 때, 처음 결과에 없던 레코드가 두 번째에서는 나타나는 문제이렇게 총 4가지 케이스가 있는데 격리수준을 낮게 했을 때, 발생되는 문제점은 아래와 같다.   Dirty read Non Repeatable Read Phantom Read Read Uncommitted 0 0 0 Read Committed   0 0 Repetable Read     0 Serializable       what I learnrow를 읽을떄는 디폴트 설정인 Repetable Read, CRUD를 진행할떄는 Serializable을 사용해서 진행했는데, 이젠 적절하게 isolation을 낮추면서 동시성을 높일수 있는 여러 LV을 고려하여 선택해야겠다.출처https://dev.mysql.com/doc/refman/5.6/en/innodb-transaction-isolation-levels.html) https://dev.mysql.com/doc/refman/5.6/en/innodb-locking.htmlhttps://dev.mysql.com/doc/refman/8.0/en/innodb-locking-transaction-model.htmlhttps://blog.sapzil.org/2017/04/01/do-not-trust-sql-transactionhttps://jupiny.com/2018/11/30/mysql-transaction-isolation-levels" }, { "title": "Java 8-17 정리", "url": "/posts/java-version/", "categories": "Java, Basic", "tags": "java, basic", "date": "2023-01-21 21:20:57 +0900", "snippet": "자바 8…30년까지?이번 프로젝트를 하면서 자바 11을 VAR특성과 LTS(Long Term Support)이길래 사용해보았다…그런데 Oracle 사에서 Java8을 사용한 레거시 프로젝트들이 너무 많음을 고려하여 Java8이 Java11,Java17 보다 더 긴 지원기간을 갖게되었다. 🤷‍♂️자바 8이 2030년까지 지원한다는 소리를 듣고 이 참에 한번 각 버젼별로 괜찮은 기능을 정리해볼까한다.JAVA 8자바8 Lambda Stream interface default Method Optional LocalDateTime이번 프로젝트에서도 많이 사용한 interface default Method, null이 올 수 있는 값을 감싸는 Wrapper 클래스로 감싸 NPE를 방지해주는 Optional, 컬랙션 연산을 더 효율적으로 하는 Stream 등 왜 오라클에서 30년까지 지원하는지 잘 알 수 있는 대목이다. 조만간 해당 점들을 블로깅 할 예정이다.아래는 interface default Method의 예로 exec를 따로 구현하지않고도 메서드를 사용하는 예이다.public interface Calculator {\tpublic int plus(int i, int j);\tpublic int multiple(int i, int j);\tdefault int exec(int i, int j){ //interface default Method\t\treturn i + j;\t}}//Calculator인터페이스를 구현한 MyCalculator클래스public class MyCalculator implements Calculator {\t@Override\tpublic int plus(int i, int j) {\t\treturn i + j;\t}\t@Override\tpublic int multiple(int i, int j) {\t\treturn i * j;\t}}public class MyCalculatorExam {\tpublic static void main(String[] args){\t\tCalculator cal = new MyCalculator();\t\tint value = cal.exec(5, 10);\t\tSystem.out.println(value);\t}}JAVA 9 모듈시스템의 등장(Jigsaw) streamtakeWhile, dropWhile, iterate 등 Stream&lt;String&gt; stream = Stream.iterate(*\"\"*, s -&gt; s + *\"s\"*) .takeWhile(s -&gt; s.length() &lt; 10); optionalifPresentOrElse 추가 interfaceprivate method 추가JAVA 10 var 추가 //타입을 명시하지않아도 사용하는데 문제가 없다. String name = \"홍길동\"; var name = \"홍길동\"; var age = 25; Garbage Collector(GC) 병렬 처리 도입으로 인한 성능 향상 JVM heap 영역을 시스템 메모리가 아닌 다른 종류의 메모리에도 할당 가능JAVA 11 Java 소스 파일 을 먼저 컴파일 하지 않고도 실행할 수 있다. 엑셀 함수같은 스크립팅 기능 Lambda에 var 사용 가능 Oracle JDK와 OpenJDK 통합 JAVA 13 유니코드 11 지원 간편해진? switch문 String time;switch (weekday) { case MONDAY: case FRIDAY: time = \"09:00-18:00\"; break; case TUESDAY: case THURSDAY: time = \"10:00-19:00\"; break; default: time = \"휴일\";}//일일히 브레이크를 넣어줘야했던 스위치문이String time = switch (weekday) { case MONDAY, FRIDAY -&gt; \"09:00-18:00\"; case TUESDAY, THURSDAY -&gt; \"10:00-19:00\"; default -&gt; \"휴일\";}; JAVA 17자바 17은 11이후의 LTS이다.스위치문에 다양한 타입을 선언할 수 있도록 바뀌었다.이젠 obj를 전달하여 기능을 전환하고 특정 유형을 확인할 수 있다.public String test(Object obj) { return switch(obj) { case Integer i -&gt; \"An integer\"; case String s -&gt; \"A string\"; case Cat c -&gt; \"A Cat\"; default -&gt; \"I don't know what it is\"; };}Sealed Class (최종)public abstract sealed class Shape permits Circle, Rectangle, Square {...}위와같은 퍼블릭 Shape class가 있을떄 Shape을 만들수 있는 하위 클래스는 Circle, Rectangle, Square 3개뿐이다.JAVA 19가상스레드, 새로운 메모리 API, Vector API등등 보이지만 이건 맛보기인듯 싶다. 궁금하면 클릭#출처baeldungHappyCoders" }, { "title": "Marvin 라이브러리를 활용한 S3에 리사이징된 이미지 업로드", "url": "/posts/image-resizing/", "categories": "Spring, troubleshooting", "tags": "spring, troubleshooting", "date": "2023-01-20 13:11:04 +0900", "snippet": "이미지 리사이징을 하게 된 계기S3 프리티어 저장공간의 수용량이 90%가 넘으면서 이미지에 대한 용량관리를 해야할 필요성을 느꼈다. 초고화질 이미지가 우리의 서비스에서는 굳이 원본상태로 보일 필요성을 못느꼈다. 400px*300px 정도의 이미지면 충분한 서비스에 배경화면 2450x1440 사이즈를 그대로 저장할 필요가 없었다.#1 해결과정 3mb 이상 이미지를 허용하지않는다.단순하게 용량을 제한 하는것 만으로도 무지막지한 용량의 이미지를 차단할 수 있는 장점이 있었다.또한, java.awt.Graphics2D, Imgscalr, Marvin 등 이미지 리사이징 라이브러리 사용 시 ,이미지IO와 변환과정에서 3mb이상의 이미지는 리사이징하는데 상당히 오랜 시간이 소요된다.따라서, 아래와 같이 multipart 사이즈에 제약 조건을 application.yml파일에 설정하였다.spring: servlet: multipart: max-file-size: 3MB max-request-size: 3MB#2 해결과정 AWS LAMBDA앞서 언급한 3mb이상의 이미지 IO 발생 시, 제약없이 빠르게 업로드 후 리사이징 할 수 있는 방법이 있었다. CloudFront와 AWS LAMBDA를 사용하여 온디멘드 방식의 리사이징을 하는 것이다. Serverless인 람다에서 이미지를 리사이징하는 방법은 저장된 큰 이미지의 용량을 줄이고 좀 더 빠른 업로드를 하는 이점은 있었으나, 하나의 이미지가 원본 S3공간과 리사이징된 S3공간 두 곳으로 저장되어 관리포인트가 더 늘어났고 그 결과 용량절감의 효과가 떨어졌다.쇼핑몰처럼 원본이미지가 필요한 서비스가 아니기에 이 방법을 선택하지 않았다.#3 해결과정 Marvin 라이브러리 사용java.awt.Graphics2D 라이브러리처음엔 Graphics2D를 이용해서 구현하였으나, 이미지가 점묘화되는 현상으로 다른 방안을 찾아야했다.Marvin 라이브러리marvin 라이브러리를 사용하기 위해선 build.gradle에 아래의 내용을 추가해야한다.implementation 'com.github.downgoon:marvin:1.5.5'implementation 'com.github.downgoon:MarvinPlugins:1.5.5'S3에 업로드하는 과정에서 List의 형태의 데이터를 이미지 리사이징하는 로직에만 포커싱하여 설명할 것이다.s3업로드 하는 코드는 추후에 올리겠다.//S3UploadServicepublic List&lt;String&gt; uploadAsList(List&lt;MultipartFile&gt; multipartFile) { log.info(\"uploadAsList tx start\"); List&lt;String&gt; imageList = new ArrayList&lt;&gt;(); // 리사이징된 이미지를 저장할 공간 multipartFile.forEach(image -&gt; { if(Objects.requireNonNull(image.getContentType()).contains(\"image\")) { //이미지가 있다면 실행하고 없다면 패스 String fileName = createFileName(image.getOriginalFilename());//중복되지않게 이름을 randomUUID()를 사용해서 생성함 String fileFormat = image.getContentType().substrin(image.getContentType().lastIndexOf(\"/\") + 1); //파일 확장자명 추출 MultipartFile resizedImage = resizer(fileName, fileFormat, image, 400); //오늘의 핵심 메서드//========아래부터는 리사이징 된 후 이미지를 S3에다가 업로드하는 방법이다.========= ObjectMetadata objectMetadata = new ObjectMetadata(); objectMetadata.setContentLength(resizedImage.getSize()); //사이즈를 전달한다. objectMetadata.setContentType(resizedImage.getContentType()); //이미지 타입을 전달한다. try (InputStream inputStream = resizedImage.getInputStream()) { s3.putObject(new PutObjectRequest(bucket, fileName, inputStream, objectMetadata) .withCannedAcl(CannedAccessControlList.PublicRead)); } catch (IOException e) { throw new BusinessLogicException(ExceptionCode.FILEUPLOAD_FAILED); } imageList.add(s3.getUrl(bucket, fileName).toString()); } }); log.info(\"uploadAsList tx end\"); return imageList; }위처럼 UUID를 사용하여 난수화된 이름, 파일 확장자명, 리스트에서 나온 이미지, 희망하는 너비값을 resizer 메서드에게 넘기면서 리사이징이 시작된다.resizer 메서드 details @Transactional public MultipartFile resizer(String fileName, String fileFormat, MultipartFile originalImage, int width) { try { BufferedImage image = ImageIO.read(originalImage.getInputStream());// MultipartFile -&gt; BufferedImage Convert int originWidth = image.getWidth(); int originHeight = image.getHeight(); // origin 이미지가 400보다 작으면 패스 if(originWidth &lt; width) return originalImage; MarvinImage imageMarvin = new MarvinImage(image); Scale scale = new Scale(); scale.load(); scale.setAttribute(\"newWidth\", width); scale.setAttribute(\"newHeight\", width * originHeight / originWidth);//비율유지를 위해 높이 유지 scale.process(imageMarvin.clone(), imageMarvin, null, null, false); BufferedImage imageNoAlpha = imageMarvin.getBufferedImageNoAlpha(); ByteArrayOutputStream baos = new ByteArrayOutputStream(); ImageIO.write(imageNoAlpha, fileFormat, baos); baos.flush(); return new CustomMultipartFile(fileName,fileFormat,originalImage.getContentType(), baos.toByteArray()); } catch (IOException e) { throw new ResponseStatusException(HttpStatus.INTERNAL_SERVER_ERROR, \"파일을 줄이는데 실패했습니다.\"); } } marvin은 멀티쓰레드, 병렬처리방식으로 이미지를 리사이징한다. 트랜잭션 선언을 안하면 충돌이 일어나서 Input not set error 혹은 null point exception을 마주하게된다. @Transactional을 선언하자! marvin 라이브러리에서 생성자 요구사항이 BufferedImage 형태이므로 ImageIO.read를 활용하여 BufferedImage로 변경할 필요가 있다. 비율을 유지하기 위해 너비값 * 원래너비/원래높이를 이용해 적용했다. 리사이징 작업이 끝나면 byte[]타입으로 저장되는데 이를 다시 s3에서 요구하는 MultipartFile로 변환하기 위해 MultipartFile interface를 implement 받아 구현했다.단순 타입변환이라 생성자만 잘 만들어주면 된다.public class CustomMultipartFile implements MultipartFile { private final String name; private String originalFilename; private String contentType; private final byte[] content; boolean isEmpty; public CustomMultipartFile(String name, String originalFilename, String contentType, byte[] content) { Assert.hasLength(name, \"Name must not be null\"); this.name = name; this.originalFilename = (originalFilename != null ? originalFilename : \"\"); this.contentType = contentType; this.content = (content != null ? content : new byte[0]); this.isEmpty = false; } @Override public String getName() { return this.name; } @Override public String getOriginalFilename() { return this.originalFilename; } @Override public String getContentType() { return this.contentType; } @Override public boolean isEmpty() { return (this.content.length == 0); } @Override public long getSize() { return this.content.length; } @Override public byte[] getBytes() throws IOException { return this.content; } @Override public InputStream getInputStream() throws IOException { return new ByteArrayInputStream(this.content); } @Override public void transferTo(File dest) throws IOException, IllegalStateException { FileCopyUtils.copy(this.content, dest); }}결과눈에 띄게 줄어든 용량과 이미지가 꺠지지 않음을 확인 할 수 있었다.또한 원본 이미지들을 다운로드 후, 다시 업로드는 하는 형태로 s3 프리티어 저장공간도 45%정도 확보하는 결과를 도출해 냈다.출처ImageIo 공식문서Maven repoBaeldung" }, { "title": "Algorithm just for memo", "url": "/posts/note_algo/", "categories": "Java, Algorithm", "tags": "java, algorithm", "date": "2023-01-19 13:11:04 +0900", "snippet": "결정알고리즘결정 알고리즘의 핵심은 lp 처음 시작점과 rp 끝지점의 설정while문안에서 lp와 rp가 만나서 lp와 rp의 이동을 어찌할지에 따라 달렸다.비교 시, 메서드를 하나 추가해 검증로직을 짜는 식으로 구현한다.public class Main{ private static void solution(int horse, int house, int[] arr) { Arrays.sort(arr); //정렬하고 int lp = 1; //1 int rp = arr[house-1]; //9 int answer = 0; while (lp &lt;= rp){ int mid = (lp + rp) / 2; //5 간격 예시 if(testing(arr,mid) &gt;= horse) { answer = mid; lp = mid + 1; } else rp = mid - 1; } System.out.println(answer); } private static int testing(int[] arr, int mid) { int pointer = arr[0]; int counter = 1; for (int i = 1; i &lt; arr.length; i++) { if(pointer + mid &lt;= arr[i]) { counter++; pointer = arr[i]; } } return counter; }}메모이제이션5C3 조합문제를 구할때 공식은 4C2 + 4C3이다.이런식으로 3C1+ 3C2 + 3C2 + 3C3 쭉쭉 재귀를 타면~ 해당값이 구해지는데 문제는 33C19 이런식의 데이터를 구할때 엄청나게 메모리소모와 시간이 소요되므로 메모이제이션 을 이용해서 미리 계산한 값은 계산하지 않는 방식으로 진행하는 테크닉이다.public class Main { int[][] memo = new int[35][35]; //메모이제이션 35C35 기준으로 구한 값이다. public static void main(String[] args) { Main m = new Main(); Scanner sc = new Scanner(System.in); int i = sc.nextInt(); int j = sc.nextInt(); System.out.println(m.dfs(i, j)); } private int dfs(int i, int j) { if(memo[i][j]&gt;0) return memo[i][j]; //해당 구한 값을 수행했느냐? if(j==0 || i==j) return 1; else return memo[i][j] = dfs(i-1, j-1) + dfs(i-1, j); //값을 기록하고 리턴하는 방법 }}DFS와 BFS로 풀수있는 문제를 가져왔다.공통적인 특징public class Main{ static int[] px = {-1, -1, 0, 1, 1, 1, 0, -1}; static int[] py = {0, -1, -1, -1, 0, 1, 1, 1}; static int[][] maze; public static void main(String[] args) { Scanner sc = new Scanner(System.in); int num = sc.nextInt(); maze = new int[num][num]; for (int i = 0; i &lt; num; i++) { for (int j = 0; j &lt; num; j++) { maze[i][j] = sc.nextInt(); } } int answer = 0; for (int i = 0; i &lt; num; i++) { for (int j = 0; j &lt; num; j++) { if(maze[i][j] == 1) { dfs(i, j); // dfs로 풀때 bfs(i,j); // bfs로 풀때 answer++; } } } System.out.println(Arrays.deepToString(maze)); System.out.println(answer); static class Point{ int x; int y; public Point(int x, int y) { this.x = x; this.y = y; } }}BFS최단거리, 최소00 을 구할떄 자주 사용하는 기법Queue를 쓰는게 포인트 public static void bfs(int x, int y) { Queue&lt;Point&gt; que = new LinkedList&lt;&gt;(); que.add(new Point(x,y)); maze[x][y] = 0; while (!que.isEmpty()) { Point tmp = que.poll(); for (int i = 0; i &lt; px.length; i++) { int nx = tmp.x + px[i]; int ny = tmp.y + py[i]; if(nx &gt;=0 &amp;&amp; ny &gt;= 0 &amp;&amp; nx&lt; maze.length &amp;&amp; ny &lt; maze.length &amp;&amp; maze[nx][ny] == 1) { maze[nx][ny] = 0; que.add(new Point(nx, ny)); } } } }DFS총 거리수, 가는방법수 모든 경우의수를 따질떄 유리재귀를 쓰는게 포인트 public static void dfs(int x, int y) { maze[x][y] = 0; for (int i = 0; i &lt; px.length; i++) { int nx = x + px[i]; int ny = y + py[i]; if(nx &gt;=0 &amp;&amp; ny &gt;= 0 &amp;&amp; nx&lt; maze.length &amp;&amp; ny &lt; maze.length &amp;&amp; maze[nx][ny] == 1) dfs(nx,ny); } }" }, { "title": "서버에 저장된 FILE 가져오는 로직", "url": "/posts/tcp-server/", "categories": "CS, Internet", "tags": "cs, internet", "date": "2023-01-18 17:21:07 +0900", "snippet": " 서버에 저장된 FILE 클라이언트에게 가져오기 이 페이지는 다크모드 기반으로 그림을 그렸습니다.클릭하면 더 커집니다.서버에서 저장된 파일을 가져올 떄 어떤 흐름으로 작동되는지 최근 한 영상을 보고 꺠달음을 얻고 해당 지식을 나의 해석방식과 나의 그림으로 그려냈다. 영상 링크 서버 쪽 이미지 　　 　　1 File A.bmp를 찾아 READ를 시작한다.DB → 드라이버 → 파일시스템을 거쳐 웹서버의 메모리영역 (버퍼에 도달.)2 A.bmp 1.4MB파일을 64kb 크기로 쪼개 파일 내용을 TCP Buffered I/O(3번)으로 복사 시킨다.3 IP 단계로 내려오면서 세그먼트로 나누어짐 (퍼즐 4개가 64kb인데 더작게 나눠져 보내짐)4 넘버링을 해서 하나의 패킷이 된다. 그 패킷은 L2에서 프레임 단위로 바뀌어 전송된다.5 인터넷으로 날아갈떄 패킷은 논리적으로 앤드포인트에서 그대로 가지만 프레임은 인터넷을 타고가면서 여러 번 바뀐다.8 window size가 보내려는 사이즈보다 크면 계속 보내고 작다면 wait한다. 이로인해 전송이 상당히 딜레이가 될 수 있다.클라이언트 쪽 이미지　 　　6 인터넷을 타고 클라이언트 사이드로 도착하면서 프레임이 여러번 바뀐다. (택배차가 부산→서울 자주 바뀌는것처럼) 클라이언트에 도착하면 프레임 안에 있는 패킷을 꺼내는 작업한다. 디캡슐화 (왜 택배오면 상자를 까서 내용물을 확인하는것처럼 말이다.)7 받아온 세그먼트를 합치는 공간 window size라고 한다. 전송이 느려질 때, 인터넷의 속도 문제일수도 있지만 TCP버퍼에 서 FILE I/O버퍼로 빨리 읽히지 못해 속도가 느려진걸수도 있다.8 세그먼트를 2개이상 받으면 파일 잘받았다의 의미를 내포하는 ACK를 서버쪽에 반환한다. 이때 TCP버퍼에 남아있는 window size를 보내서 서버측에서 wait하고 있는 상태를 풀거나 자리가 남을떄까지 기다리게 한다.세그먼트(Segment) : 데이터를 네트워크를 통한 실질적인 전송을 위하여 적절한 크기로 분할한 조각.패킷(Packet) : 전송을 위해 분할된 데이터 조각(세그먼트)에 목적지까지의 전달을 위하여 Source IP 와 Destination IP가 포함된 IP Header가 붙은 형태의 메세지프레임(Frame) : 최종적으로 데이터를 전송하기 전에 패킷에 Header(Mac Address 포함)와 CRC를 위한 Trailer가 붙은 메세지" }, { "title": "SOLID 설계원칙", "url": "/posts/SOILD/", "categories": "CS, OOP", "tags": "cs, oop", "date": "2023-01-15 19:41:57 +0900", "snippet": " SOLID 원칙이란? OOP 설계시, SOLID 원칙을 지켜서 개발한다면 변경이 용이하고, 유지보수와 확장이 쉬운 SW를 개발하는데 도움이 된다고한다. SRP : 코드 변경 시, 파급 효과가 적으면 SRP를 잘 따른것OCP : 다형성을 극대화LIP : 명시한 기능대로 구현하자ISP : 여러기능 인터페이스보단 여러개의 인터페이스로 분리하는 것이 낫다.DIP : 추상화에 의존해야지 구현 클래스에 의존하면 안된다. Single Responsibility Principle (SRP) 단일책임원칙이란? 뜻은 하나의 모듈은 하나의 책임을 가져야한다는 뜻인데 실상 책임이라는 표현은 모호한 기준이다. 그래서 로버트 마틴의 말인 어떤 클래스를 변경해야하는 이유는 오직 하나뿐이어야한다를 생각해보면 문제는 쉬워진다.하나의 남자가 있다고 가정해보자. 그 남자는 누구에게는 상사일수도, 부인일수도, 아들일수도있다. 상사일떄는 지시하다()라는 메소드여야하고 아내일떄는 사랑하다(), 아들일떄는 효도하기() 등 메소드 형태로 가정했을떄,이 남자는 남자라는 테이블안에 너무나 많은 책임을 가지고 있다는 것이다.class Man{ final static Boolean boss; final static Boolean husband; final static Boolean son; Boolean role; void 지시하다(){ if(this.role.equals.(boss)) else if(this.role.equals.(son)) else }}이런식으로 남자를 하나의 클래스로 묶어 상사일떄 아들일떄 남편일떄를 모두 구현하는것은 SRP 위반이다.딱봐도 여기서 확장을하거나 유지보수할 때 대공사가 일어날 것이 분명하다.abstract class Man{ abstract void role();}class boss extends Man{ void role();}class husband extends Man{ void role();}class son extends Man{ void role();}추상화를 통해 각자 자신의 특징에 맞게 메소드를 구현하여 하나의 책임만 지는 것을 SRP라고 한다.Open Closed Principle (OCP)개방 폐쇄 원칙이란?SW 엔티티(class,method,function etc)는 확장에 열려 있어야 하나, 변경에 대해서는 닫혀있어야한다.말이 굉장히 난해하지만, 기존 코드를 유지한채 확장을 쉽게 할 수 있어야한다는 뜻이다.OCP의 대표적인 예는 JDBC이다.JDBC는 JAVA와 DB간의 데이터를 주고 받을수 있도록 하는 인터페이스이다.사용자가 MySQL을 MarinaDB든 PostgreSQL든 커낵션만 바꾸면 사용할 수 있는 구조가 OCP를 잘 지킨 케이스이다.OOP의 핵심은 OCP를 지키는데 있다.Liskov Substitution Principle (LSP)리스코프 치환 원칙이란? 서브타입은 언제나 자신의 기반 타입으로 교체할 수 있어야한다.즉 프로그램의 정확성을 깨뜨리지 않으면서 하위 타입의 인스턴스로 바꿀 수 있어야 하는 것을 의미한다. 쉽게 말해 명시한 기능대로 구현해야한다는 것이다. 하위 클래스는 상위 클래스의 한 종류여야한다.즉 사자,기린 클래스가 있다면 상위클래스가 포유류이면 잘 지킨거고, 포유류가 고양이과이면 틀린 것이다.Interface Segregation Principle (ISP)인터페이스 분리 원칙이란? 여러 기능이 하나로 있는 인터페이스보다 여러가지 인터페이스로 분리하는것이 낫다는 것이다.어찌보면 SRP와 같은 맥락으로 보면 된다. 상사일떄는 남자에게 상사역할을 부모님일떄는 아들 역할을 주는것처럼, 각 역할에 맞게 인터페이스를 분리하는 것이다. 상위 클래스가 많을 수록 하위 클래스에게 많은 기능을 확장시켜주고 형변환, 코드 중복을 줄여준다. 인터페이스 내에 메소드는 최소한 일수록 좋다.Dependency Inversion Principle (DIP)의존 역전의 원칙이란? 자신보다 변하기 쉬운 것에 의존하던 것을 추상화된 인터페이스나 상위 클래스를 두어 변하기 쉬운 것의 변화에 영향받지 않게 하는 것이다. 고차원 모듈은 저차원 모듈에 의존하면 안 된다. 이 두 모듈 모두 다른 추상화된 것에 의존해야 한다. 추상화된 것은 구체적인 것에 의존하면 안 된다. 구체적인 것이 추상화된 것에 의존해야 한다. 자주 변경되는 구체(Concrete) 클래스에 의존하지 마라 - 로버트 C.마틴 -이 말을 쉽게 얘기해보면 복서가 권투장갑에 의존하면 권투시합이 끝날때마다 선수가 장갑보다 더 변경사항이 자주일어나는 상황이 발생된다. 이를 방지하기 위해 구현체는 추상화에 의존하게 함으로써 서로 간의 영향을 안받는 것을 얘기한다.class Boxer implements Glove{ @Override public void RedGlove() { } @Override public void GreenGlove() { } @Override public void BlueGlove() { }}interface Glove{ void RedGlove(); void GreenGlove(); void BlueGlove();} 결론SRP, ISP는 한 기능의 변경이 다른 클래스에게 미치는 영향을 최소화 하고, 기능 추가와 변경에 용이하도록 해주고 (객체의 몸집을 줄여준다)LSP, DIP는 OCP의 원칙을 지키도록 도와준다. 즉 OCP의 변화되는 부분을 추상화하도록 하는 개념이 DIP이고 다형성 구현하게 도움을 주는 원칙이 LSP이다." }, { "title": "행위패턴 - 이터레이터 패턴", "url": "/posts/iterator/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2023-01-11 23:11:07 +0900", "snippet": "Iterator Pattern 🧙‍♂️ 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다. 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 이터레이터 패턴 반복작업을 이터레이터에게 맡겨서 반복작업을 순서대로 처리하는 패턴　　 이터레이터 패턴 반복작업을 이터레이터에게 맡겨서 반복작업을 순서대로 처리하는 패턴{: .prompt-tip}## &lt;span style=\"color: gold\"&gt; 이터레이터 패턴이란? Iterator pattern이터레이터 패턴은 컬렉션 구현 방법을 노출시키지 않으면서도 그 집합체 안에 들어있는 모든 항목에 대해 접근할 수 있게 해준다. 또한, 모든 항목에 일일이 접근하는 컬랙션 객체가 아닌 반복자 객체가 맡고 진행한다는 점이다.(Stream같은 내부반복자는 아님)이를 통해 인터페이스와 구현이 단순해진다. 우선 이터레이터의 기본 사용법을 설명하고 이터레이터 패턴을 알아보자.이터레이터 기본 구성class AboutIterator{ public static void main (String[] args){ ArrayList list = new ArrayList(); list.add(\"1\"); ... list.add(\"5\"); // 1~5까지 넣었다고 가정 Iterator it = list.iterator(); while(it.hasNext()){ Object obj = it.next(); System.out.print(obj+\" \"); //1 2 3 4 5 } }}한 방향으로만 사용하는 이터레이터 외에 반대방향으로도 하는 사용할 수 있는 List iterator도 있다.next()대신 preivous()를 사용하면된다.리스트 이터레이터 구성ListIteratorclass AboutIterator{ public static void main (String[] args){ ArrayList list = new ArrayList(); list.add(\"1\"); ... list.add(\"5\"); // 1~5까지 넣었다고 가정 ListIterator it = list.listIterator(); while(it.hasNext()){ Object obj = it.next(); System.out.print(obj+\" \"); //1 2 3 4 5 } while(it.hasPrevious()){ Object obj = it.pervious(); System.out.print(obj+\" \"); //5 4 3 2 1 역방향 } }}자 이번에는 이터레이터 패턴을 이용해보겠다.필자는 요새 향수가 너무 많아서 향수를 한번 정리하는겸 향수로 예제를 만들겠다.import java.util.Iterator;//까먹지 않고 이터레이터를 쓰기 위한 인터페이스interface makeIteratorInterface{ Iterator createIterator();}//향수이름과 브랜드를 저장하는 객체public class Perfume { private String name; private String brand; public String getName() { return name; } public String getBrand() { return brand; } public Perfume(String brand, String name) { this.name = name; this.brand = brand; }//향수를 보관하는 수납장이다. private static class Closet implements makeIteratorInterface{ private Perfume[] perfumes; private int location = 0; //향수 마지막 위치 public Perfume getPerfume(int location) { return perfumes[location]; } public int getLocationSize() { return location; } public void collectPerfume(Perfume perfume) { if (location &lt; perfumes.length) { this.perfumes[location] = perfume; location++; }else System.out.println(\"수납장이 꽉찼습니다.\"); } public Closet(int total) { //향수 총개수 perfumes = new Perfume[total]; } @Override public Iterator createIterator() { return new ClosetIterator(this); }수납장에서 하나씩 애들을 어떻게 꺼낼지 정책을 결정하는 이터레이터 패턴의 예. private class ClosetIterator implements Iterator&lt;Perfume&gt; { private Closet closet; private int currentLocation = 0; public ClosetIterator(Closet closet) { this.closet = closet; } @Override public boolean hasNext() { return currentLocation &lt; closet.getLocationSize(); } @Override public Perfume next() { Perfume perfume = closet.getPerfume(currentLocation); currentLocation++; return perfume; } }정답을 출력하는 메서드 public static void main(String[] args) { Closet closet = new Closet(4); Perfume perfume1 = new Perfume(\"입셍로랑\", \"옴므\"); Perfume perfume2 = new Perfume(\"베르사체\", \"에로스\"); Perfume perfume3 = new Perfume(\"디올\", \"세비지\"); Perfume perfume4 = new Perfume(\"샤넬\", \"옴므\"); Perfume perfume5 = new Perfume(\"에르메스\", \"옴므\"); closet.collectPerfume(perfume1); closet.collectPerfume(perfume2); closet.collectPerfume(perfume3); closet.collectPerfume(perfume4); closet.collectPerfume(peffume5); System.out.println(\"현재 향수 개수 = \" + closet.getLocationSize()); Iterator iterator = closet.createIterator(); while (iterator.hasNext()) { Perfume next = (Perfume) iterator.next(); System.out.println(next.brand+\" \"+next.name); } } }}//수납장이 꽉찼습니다. (에르메스가 못들어감.)//현재 향수 개수 = 4// 입셍로랑 옴므// 베르사체 에로스// 몽블랑 세비지// 샤넬 옴므&lt;span style=\"color: gold\"&gt; 장점 단점장점 위에서 언급한 것처럼 모든 항목을 일일히 접근하여 작업을 하는 것이 아닌, 이터레이터가 모든 항목에 대해 접근할 수 있도록 해준다. 클래스의 응집도가 올라간다. (응집도: 한 모듈 내부의 처리 요소들이 서로 관련되어 있는 정도)단점 사실 지금과 같은 단순한 반복이라면 복잡하기만하고 필요성이 없는거 같다.&lt;span style=\"color: gold\"&gt; 출처 Head First 디자인패턴" }, { "title": "Comparator & Comparable", "url": "/posts/compare/", "categories": "Java, Syntax", "tags": "java, comparator, comparable", "date": "2023-01-09 11:11:07 +0900", "snippet": "Comparator &amp; Comparable 🧙‍♂️ Comparable “자기 자신과 매개변수 객체를 비교 + compareTo 반드시 구현” 선수 vs 선수Comparator “두 매개변수 객체를 비교” 선수 vs 선수 사이의 심판공통적으로는 비교하는 메서드이지만 실질적으로는 비교대상이 다름.Comparable 을 사용하고자 한다면 compareTo 메서드를 재정의(Override/구현)을 해야함.Comparator 에서 구현해야하는 것은 compare(T o1,T o2) 메서드이다. Comparable자바에 기본으로 적용된 Comparable을 뜯어보면 아래와 같다.public final class Integer extends Number implements Comparable&lt;Integer&gt; { public int compareTo(Integer anotherInteger) { return compare(this.value, anotherInteger.value); } //같으면 0 작으면 1 크면 -1 public static int compare(int x, int y) { return (x &lt; y) ? -1 : ((x == y) ? 0 : 1); }}주석에도 설명이 있듯이 같으면 0 작으면 1 크면 -1을 반환하는것을 볼수 있다.그렇다면 객체를 비교할 떄는 어떨까?Student class에 age와 classNumber가 있다고 가정.class Student implements Comparable&lt;Student&gt; { \tint age;\t\t\t// 나이\tint classNumber;\t// 반 번호\t\tStudent(int age, int classNumber) {\t\tthis.age = age;\t\tthis.classNumber = classNumber;\t} //정석 @Override\tpublic int compareTo(Student o) { \t\t// 자기자신의 age가 o의 age보다 크다면 양수\t\tif(this.age &gt; o.age) {\t\t\treturn 1;\t\t}\t\t// 자기 자신의 age와 o의 age가 같다면 0\t\telse if(this.age == o.age) {\t\t\treturn 0;\t\t}\t\t// 자기 자신의 age가 o의 age보다 작다면 음수\t\telse {\t\t\treturn -1;\t\t}\t} //야매? @Override\tpublic int compareTo(Student o) {\t\treturn this.age - o.age; \t}}정석의 방법과 야매스러운 방법으로 compareTo를 구현했다. 숫자를 비교할떄 큰수는 빼면 음수가되고 작은수는 양수가 되는 점을 이용해서 짠 코드이다. 다만 저 야매에는 함정이있다. int 자료형처럼 표현범위가 21억47~까지 되어있어 그 이상, 그 이하의 숫자가 들어오게 되면 오버플로우나 언더플로우로 인해 값이 잘못 반환 될 수 있다. 그리하여 이런 점은 미연에 방지하기 위해서 정석처럼 코드를 짜면 사전에 보완할 수 있다. ComparatorComparable의 compareTo()와 다르게 Comparator의 compare은 두 객체를 비교한다. 이번에는 아까 사용한 student 객체에서 classNumber을 비교하고자 한다.Student class에 age와 classNumber가 있다고 가정.class Student implements Comparator&lt;Student&gt; { \tint age;\t\t\t// 나이\tint classNumber;\t// 반 번호\t\tStudent(int age, int classNumber) {\t\tthis.age = age;\t\tthis.classNumber = classNumber;\t} @Override\tpublic int compare(Student o1, Student o2) { \t\tif(o1.classNumber &gt; o2.classNumber) {\t\t\treturn 1;\t\t}\t\telse if(o1.classNumber == o2.classNumber) {\t\t\treturn 0;\t\t}\t\telse {\t\t\treturn -1;\t\t}\t} //야매? @Override\tpublic int compare(Student o1, Student o2) {\t\treturn o1.classNumber - o2.classNumber;\t}}맨 위에서 심판이라는 표현처럼 o1과 o2와 비교를 할 뿐, Student를 호출한 객체에는 영향을 받지 않는다.comparable에서처럼 int 범위내를 넘지않는다면 야매방법을 써도 무방하다.사실 별차이없어보이는데 Comparator의 장점은 무엇일까? 바로 익명클래스를 이용해 커스텀마이징한 비교를 할수 있다는 점이다. public static void main(String[] args) { \t\tStudent a = new Student(17, 2);\t// 17살 2반\t\tStudent b = new Student(18, 1);\t// 18살 1반\t\tStudent c = new Student(15, 3); // 15살 3반 int i = classNumberCompare.compare(a,b); if(i &gt;0){...} else if(i &lt;0){...} else {...} int j = ageCompare.compare(a,b); if(j &gt;0){...} else if(j &lt;0){...} else {...} } //학생을 반별, 나이별로 비교해야하는 상황이 발생했다. 이럴땐 익명클래스를 이용해 커스텀마이징한 비교를 할수 있다. public static Comparator&lt;Student&gt; classNumberCompare= new Comparator&lt;Student&gt;() {\t\t@Override\t\tpublic int compare(Student o1, Student o2) {\t\t\treturn o1.classNumber - o2.classNumber;\t\t}\t};\t\tpublic static Comparator&lt;Student&gt; ageCompare = new Comparator&lt;Student&gt;() {\t\t@Override\t\tpublic int compare(Student o1, Student o2) {\t\t\treturn o1.age - o2.age;\t\t}\t};다양한 출력의 예를 모아봤다.import java.util.*;public class comparatorTest { public static void main(String[] args) { String[] animals = {\"cat\", \"Dog\", \"lion\", \"Tiger\"}; List&lt;String&gt; animal_list = new ArrayList&lt;String&gt;(Arrays.asList(animals)); Arrays.sort(animals); //Comparable의 정의 System.out.println(\"1 Arrays 정렬= \"+ Arrays.toString(animals)); Collections.sort(animal_list); System.out.println(\"2 컬랙션 정렬 = \"+ animal_list); Arrays.sort(animals, String.CASE_INSENSITIVE_ORDER); //대소문자 구별안하고 sort System.out.println(\"3 = \"+ Arrays.toString(animals)); Arrays.sort(animals, new Desending()); System.out.println(\"4 = \"+ Arrays.toString(animals)); Collections.sort(animal_list, (o1,o2)-&gt;{ if(o1 instanceof Comparable &amp;&amp; o2 instanceof Comparable){ Comparable c1 = (Comparable)o1; Comparable c2 = (Comparable) o2; return c1.compareTo(c2)*-1;} else return -1; }); System.out.println(\"5 = \"+ animal_list); } private static class Desending implements Comparator&lt;String&gt; { @Override public int compare(String o1, String o2) { return -(o1.compareTo(o2)); } }}// 1 Arrays 정렬= [Dog, Tiger, cat, lion]// 2 컬랙션 정렬 = [Dog, Tiger, cat, lion]// 3 = [cat, Dog, lion, Tiger]// 4 = [lion, cat, Tiger, Dog]// 5 = [lion, cat, Tiger, Dog] 출처 오라클/자바/8 자바의 정석" }, { "title": "행위패턴 - 전략패턴과 상태 패턴", "url": "/posts/strategy/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2023-01-07 10:11:07 +0900", "snippet": "Strategy Pattern &amp; State Pattern 🧙‍♂️ 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 전략 패턴은 인스턴스를 생성하고 난 후, 상태가 거의 바뀌지 않는 경우에 사용 상태 패턴은 인스턴스를 생성하고 난 후, 상태가 빈번하게 바뀌는 경우에 사용 전략 패턴이란? strategy pattern 정책패턴이라고 하며, 객체의 행위를 바꾸고 싶을떄 직접 수정하지 않고 ‘캡슐화한 알고리즘’을 컨텍스트 안에서 바꿔주면서 상호간의 교체가 가능하도록 만드는 패턴이다.결제시스템에서 카카오페이든 네이버페이든 전략만 바꿔서 결제를 진행하도록 해주는 것이 전략 패턴이다.인스턴스 오리가 태어날떄 꼭 한가지는 가지고 태어난다고 가정해보자. 날 수있는 오리 날 수없는 오리한번 인스턴스가 생성(태어나면) 살아가는 동안 날지 못하는 오리가 갑자기 날 수는 없는 것이다.즉, 상태가 바뀌지 않는다.interface Fly{ public void fly();}class canfly implements Duck{ @Override public void fly(){ System.out.print(\"날수 있다.\"); } }class cannotfly implements Duck{ @Override public void fly(){ System.out.print(\"날수 없다.\"); } }이런식으로 코드를 짜면 수정이나 기능을 추가시에 메서드의 중복문제가 발생과 OCP를 위반하게 된다.abstract class Duck{ private String name; private FlyingStrategy flyingStrategy; public Duck(String name) { this.name = name; } public void fly() { System.out.printf(name +\"는 \"); flyingStrategy.fly(); } public void setFlyingStrategy(FlyingStrategy flyingStrategy) { this.flyingStrategy = flyingStrategy; }}class blackDuck extends Duck{ public blackDuck(String name){ super(name); }}class whiteDuck extends Duck{ public whiteDuck(String name){ super(name); }}//fly 인터페이스interface FlyingStrategy{ public void fly();}//fly 구현체class canFly implements FlyingStrategy { @Override public void fly() { System.out.println(\"can fly\"); }}//fly 구현체class cannotFly implements FlyingStrategy { @Override public void fly() { System.out.println(\"cannot fly\"); }}public class Client { public static void main(String[] args) { blackDuck blackDuck = new blackDuck(\"검정오리\"); whiteDuck whiteDuck = new whiteDuck(\"흰오리\"); blackDuck.setFlyingStrategy(new canFly()); whiteDuck.setFlyingStrategy(new cannotFly()); blackDuck.fly(); whiteDuck.fly(); }}//검정오리는 can fly//흰오리는 cannot fly 상태 패턴이란? state pattern상태 객체에 일련의 행동이 캡슐화가 된다. 즉, 실행중인 객체가 여러 상태 객체중 하나인 객체에게 모든 행동을 맞기게 된다.아래와 같이 자판기기계가 있다고 가정해보자..1. 이 경우에는 기계가 HasMoney() 상태 있을때 insert_money()가 호출되면서 Sold() 상태로 전환된다. ==&gt; 돈이 부족할때 NoMoney(); ==&gt; 돈이 있을때 HasMoney();-insert_money()-&gt; Vending Machine =[현재 상태]=&gt; 거스름돈이 없을떄 NoChange(); ==&gt; 다 팔렸을때 SoldOut(); ==&gt; 팔릴떄 Sold();2. 현재 상태가 Sold 메서드로 전환되면서 음료를 반출한다. ==&gt; 돈이 부족할때 NoMoney(); ==&gt; 돈이 있을때 HasMoney(); ==&gt; 거스름돈이 없을떄 NoChange(); ==&gt; 다 팔렸을때 SoldOut();Vending Machine=[현재 상태]+ dispense()=&gt; 팔릴떄 Sold();3. 그후 음료가 있으면 NoMoney(); , 거스름돈이없으면 NoChange(), 매진 시 SoldOut()으로 이동한다.이처럼 상태를 빈번히 바뀌는 경우 상태패턴을 사용한다. 코드를 간단하게 짜보겠다.변경전 로직public class VendingMachine { public static enum State {NoMoney, HasMoney, ...} private State state = State.NoMoney; public void changeState(State state){ this.state=state; } public void insert_money(int money) { switch (state) { case NoMoney: case HasMoney: case Nochange: case SoldOut: case Sold: } }}벌써부터 case 문을 보면 속이 답답하다..변경후 로직… 우선 인터페이스를 만들자.interface State{ public void money(int money, VendingMachine machine);}class NoMoney implements State{ @Override public void money(int money, VendingMachine machine) { ... }}class HasMoney implements State{ @Override public void money(int money, VendingMachine machine){ machine.changeState(new Sold()); }}class Sold implements State{ @Override public void money(int money, VendingMachine machine){ machine.changeState(new NoMoney()); }}public class VendingMachine { private State state; public VendingMachine() { state = new NoMoney(); } public void insert_money(int money) { state.money(money, this); // 핵심포인트: 구현위임 } public void changeState(State state){ this.state = state; }} 공통점차이점은 위에 말한것처럼 state는 능동적으로 변하고 strategy는 수동적으로 변하는 성질이 있다.공통점은 실행중인 클래스의 영향을 받지않고 유연한 변환이 가능한 점이다. 결론전략 패턴: 생성 시, 비슷하면서 조금씩 다른 행동을 묶고 싶을때 사용한다.상태 패턴: if,else 조건문이 너무 많이 들어가 지저분해보일 때 사용한다. 출처 Head First 디자인패턴 면접을 위한 CS 전공지식노트" }, { "title": "Persistence Context", "url": "/posts/persistence-context/", "categories": "JPA, SQL", "tags": "jpa, sql", "date": "2023-01-06 15:11:04 +0900", "snippet": "영속성 컨텍스트JPA를 사용함에 있어 가장 중요한 개념이자 Entity를 영구 저장하는 환경이다.논리적인 개념이기에 자주 까먹어서 이참에 정리하고자 한다. 프레임워크랑 DB 사이에 있는 논리적인 공간엔티티의 생명주기왜 뜬금없이 엔티티의 생명주기냐 하겠지만, 영속성 컨텍스트를 이해하는데 땔 수 없는 관계이기에 설명하고자 한다.크게 4가지 영역으로 나뉘는데 New, managed, detached, removed 이다. 비영속 (new)는 영속성 컨텍스트와 전혀관계가 없는 말그대로 NEW인 상태이다. Member member = new Member(); //맴버 객체에는 ID와 이름이 저장된다.member.setId(1L);member.setName(\"회원A\") 영속(persist)는 객체를 생성하고 저장까지한 상태 코드가 계속 이어진다고 생각하면 된다.```javaEntityManager em = entityManagerFactory.createEntityManager(); //팩토리에서 매니저발령em.getTransaction().begin();em.persist(member); // 객체를 영속성 컨텍스트에 저장한 상태3. 준영속(detach), 삭제(remove)는 논리적인 공간에서 분리시키거나 삭제한 상태 ```javaem.detach(memeber);em.remove(member);" }, { "title": "생성 패턴 - 추상 팩토리 메서드 패턴", "url": "/posts/abstract/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2023-01-02 09:10:57 +0900", "snippet": "Abstract Factory Method Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 관련 객체들의 클래스들을 지정하지 않고 객체들의 모음을 생성하는 패턴편의점 삼각 김밥에 들어가는 재료들이 모두 다 한 공장에서 오진 않았다.재료마다 각기 다른 곳에서 와서 하나의 김밥이 되었다. 팩토리 패턴과의 차이: 팩토리 패턴은 한 종류의 객체를 생성하기 위해 사용되지만,추상 팩토리 패턴은 연관되거나 의존적인 객체로 이루어진 여러 종류의 객체를 생성하기 위해 사용된다. 추상 팩토리 메서드 패턴이란? 추상 팩토리 패턴은 상세화된 서브 클래스를 정의하지 않고, 서로 관련성이 있거나 독립적인 여러 객체를 생성하기 위한 인터페이스를 제공한다.최근 Spring Security에서 OAuth2를 쓰면서 각개의 소셜로그인에 계정에 맞는 user 정보를 api로 주게 되는데이러한 점이 추상 팩토리 메소드로 생각해 볼 수 있을꺼 같아 예제코드를 작성해보았다.팩토리메서드와 다를게 없는...abstract class User { public abstract String name(); public abstract String email();}class kakaoUser extends User{ private String name; private String email; public kakaoUser(String name, String email) { this.name = name; this.email = email; } @Override public String name() { return this.name; } @Override public String email() { return this.email; }}class googleUser extends User{ private String name; private String email; public googleUser(String name, String email) { this.name = name; this.email = email; } @Override public String name() { return this.name; } @Override public String email() { return this.email; }}추상팩토리의 역할을 하는 인터페이스 or 추상클래스가 필요interface AbstractOAuth2API { public User createUser();}class kakaoOauth2Factory implements AbstractOAuth2API { @Override public User createUser() { return new kakaoUser(\"홍길동\", \"카카오이메일\"); }}class googleOauth2Factory implements AbstractOAuth2API { @Override public User createUser() { return new googleUser(\"홍길동\", \"구글이메일\"); }}/*client 코드와의 접점이자 서브클래스를 생성하는데 도움주는 클래스*/class oauth2Factory{ public static User getUser(AbstractOAuth2API api) { return api.createUser(); }}public class codeTester { public static void main(String[] args) { User user1 = oauth2Factory.getUser(new kakaoOauth2Factory()); User user2 = oauth2Factory.getUser(new googleOauth2Factory()); System.out.println(user1.name()+\" \"+ user1.email()); System.out.println(user2.name()+\" \"+ user2.email()); }}//홍길동 카카오이메일//홍길동 구글이메일 장 단점 장점 재사용성이 좋다 * 구체적인 클래스를 분리하므로 서로가 달라도 어쨌든 묶여 있는 점에서 일관성이 있다.단점 새로운 인터페이스와 수많은 클래스가 패턴과 함께 도입되기 때문에 코드가 생각보다 복잡해질 수 있다. 결론 구현클래스에 의존하고 싶지않고 다양한 객체에 적용하고 싶을때 사용하자. 참고자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "LAMBDA?", "url": "/posts/lambda/", "categories": "Java, Syntax", "tags": "java, lambda", "date": "2022-12-28 19:41:57 +0900", "snippet": "What is Lambda?람다란? 메서드를 하나의 식으로 표현한 것. 익명함수 (Anonymous functions)와 같다.사용방법//평문int max(int a, int b){ return a&gt;b ? a : b;}//람다 (타입이 추론 가능할때 생략가능)(a,b) -&gt; { return a &gt; b ? a : b;} //리턴일때는 중괄호 생략 불가그밖에(int a) -&gt; a*a; = a-&gt; a*a; //매게변수 괄호 생략가능(String name, int i) -&gt; System.out.println(name+\"=\"+i) //중괄호 생략가능 함수형 인터페이스 (@functional interface)? 함수형 인터페이스는 람다식을 다루기 위한 인터페이스이다. 오직 하나의 추상 메서드만 정의되어 있어야 한다는 제약이 있다.그래야 람다식과 인터페이스의 메서드가 1대1로 연결된다.※ @FunctionalInterface는 컴파일러가 함수형 인터페이스를 올바르게 정의했는지 확인해주는 어노테이션이다.@FunctionalInterfaceinterface Function{ public abstract int max(int a , int b);}============================================Function f = (int a, int b) -&gt; a&gt;b ? a : b;int value = f.max(5,3); java.util.function 일반적으로 자주 쓰이는 형식의 메서드를 함수형 인터페이스로 미리 정의해놓은 패키지이다.주요 함수형 인터페이스 함수형 인터페이스 메서드 설명 java.lang.Runnable void run() 매개변수 X 반환값 x Supplier T get() 매개변수 X 반환값 O Consumer void accept(T t) 매개변수 O 반환값 X Function&lt;T,R&gt; R apply(T t) 매개변수O 반환값 O (일반적인 메서드) Predicate boolean test(T t) 매개변수 하나 반환값 boolean (조건식 표현) Predicate&lt;String&gt; some = s -&gt; s.length() == 0;String s =\"\";if(some.test(s)) // if(s.length()==0)랑 같다 sout(\"비어있다\")Supplier&lt;Integer&gt; s = ()-&gt; (int)(Math.random()*100)+1;Consumer&lt;Integer&gt; c = i -&gt;System.out.print(i);Function&lt;Integer,Integer&gt; f = i -&gt; i/10*10; // 일의자리 삭제하기Predicate&lt;Integer&gt; p = i%2 == 0;이를 이용해서 다양한 함수를 사용할 수 있다.매게변수가 두 개인 함수형 인터페이스 함수형 인터페이스 메서드 설명 BiConsumer&lt;T,U&gt; void accept(T t, U u) 두개의 매개변수 반환값 x BiPredicate&lt;T,U&gt; boolean test(T t, U u) 두개의 매개변수 반환값 boolean BiFunction&lt;T,U,R&gt; R apply(T t, U u) 두개의 매개변수 반환값 O Function의 변형 함수형 인터페이스 메서드 설명 UnaryOperator T apply(T t) function의 자손 BinaryOperator T apply(T t, T t) BiFunction의 자손 컬랙션 프레임워크 함수형 인터페이스 인터페이스 메서드 설명 Collection boolean removelf(Predicate filter) 조건에 맞는 요소를 삭제 List void replaceAll(UnarOperator operator) 모든요소를 반환하여 대체 Iterable void forEach(Consumer action) 모든 요소에 작업 action을 수행 Map V compute(K key, BiFunction&lt;K,V,V&gt;f) 지정된 키의 값에 작업 F를 수행   V computeIfAbsent(K key, Function&lt;K,V&gt;f) 키가 없으면 작업 f를 수행   V computeIfPresent(K key, BiFunction&lt;K,V,V&gt;f) 지정된 키가 있을 떄, 작업 f를 수행   V merge((K key, V value, BiFunction&lt;K,V,V&gt;f)) 모든 요소에 치환작업 병합작업 f를 수행   void forEach(BiConsumer&lt;K,V&gt; action) 모든 요소에 치환작업 작업 action을 수행   void replaceAll(BiFunction&lt;K,V,V&gt; f) 모든 요소에 치환작업 f를 수행 //list에 {1,2,3,4,5,6,7,8,9,10} 있다고 가정//map에는 [1,1],[2,2],[3,3]list.forEach(i-&gt; sout(i + \" \")); //{1,2,3,4,5,6,7,8,9,10}list.removeIf(x-&gt; x%2==0 || x%3==0); //{1,5,7}list.replaceAll(x-&gt;x*10); //{10,20,30,40,50,60,70...}map.forEach((k,v)-&gt;sout(k+\" \"+v))// 1 1 2 2 3 3 메서드 참조 람다식이 하나의 메서드만 호출하면 더 간단히 사용할 수 있다. 종류 람다 메서드 참조 Static 메서드 참조할 경우 (x)-&gt;className.method(x) className::method 인스턴스 메서드 참조할 경우 (obj,x)-&gt;obj.method(x) className::method 특정 객체 인스턴스메서드 참조할 경우 (x)-&gt;obj.method(x) obj::method 하나의 메서드만 호출하는 람다식은 클래스명::메서드명 or 참조변수::메서드명" }, { "title": "생성 패턴 - 프로토타입 패턴", "url": "/posts/prototype/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-26 15:10:57 +0900", "snippet": "Prototype Method Pattern 🧙‍♂️ 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 기존 객체를 복제함으로써 객체를 생성하여 DB,네트워크 접근 비용을 절감하는 패턴 프로토타입 패턴이란? 처음부터 일반적인 원형을 만들어 놓고, 그것을 복사한 후 필요한 부분만 수정하여 사용하는 패턴이다.생성할 객체의 원형을 제공하는 인스턴스에서 생성할 객체들의 타입이 결정되도록 설정하며, 객체를 생성할 때나,갖추어야 할 기본형태가 있을 때, 사용되는 패턴이다.public class Employees implements Cloneable { private List&lt;String&gt; nameList; public Employees() { this.nameList = new ArrayList&lt;&gt;(); } public Employees(List&lt;String&gt; list) { this.nameList = list; } public void uploadData() { nameList.add(\"Kim\"); nameList.add(\"Park\"); nameList.add(\"Lee\"); } //핵심 내용 @Override public Object clone() throws CloneNotSupportedException { List &lt;String&gt; temp = new ArrayList &lt; &gt; (); for (String str: this.nameList) { temp.add(str); } return new Employees(temp); }} public class PrototypePattern { public static void main(String[] args) throws CloneNotSupportedException { Employees employees = new Employees(); employees.uploadData(); // Kim, Park, Lee Employees employees1 = (Employees) employees.clone(); Employees employees2 = (Employees) employees.clone(); List &lt; String &gt; list1 = employees1.getList(); list1.add(\"Na\"); List &lt; String &gt; list2 = employees2.getList(); list2.remove(\"Lee\"); System.out.println(\"employees: \" + employees.getList()); System.out.println(\"employees 1: \" + list1.getList()); System.out.println(\"employees 2: \" + list2.getList()); }}/** employees : Kim, Park ,Lee* employees 1: Kim, Park ,Lee, Na* employees 2: Kim, Park*/Clone 메소드를 통해 DB로부터 한번의 호출을 통해서 데이터를 조작할 수 있었다. 장 단점 장점 객체를 생성해주기 위한 별도의 객체 생성 클래스가 필요하지 않다. 비용절감단점 생성해야할 객체들의 클래스들을 모두 clone()메서드로 구현해야함. 결론 데이터를 바꾸고 저장하는 과정이 한번에 일어난다고 가정하면, 이러한 방법으로 속도를 향상 시키자.객체를 복사하는 것이 네트워크 접근이나 DB 접근보다 훨씬 비용이 적다. 참고자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "생성 패턴 - 팩토리 메서드 패턴", "url": "/posts/factory-method/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-26 15:10:57 +0900", "snippet": "Factory Method Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 생성할 객체의 클래스를 국한하지 않고 생성한다. 추상 팩토리와의 차이: 팩토리 패턴은 한 종류의 객체를 생성하기 위해 사용되지만,추상 팩토리 패턴은 연관되거나 의존적인 객체로 이루어진 여러 종류의 객체를 생성하기 위해 사용된다. 팩토리 메서드 패턴이란? 상위클래스에서는 인스턴스를 만드는 방법을 결정하고,하위 클래스에서는 데이터의 생성을 책임지고 조작하는 함수들을 오버라이딩하여 인터페이스와 실제 객체를 생성하는 클래스를 분리할 수 있는 특징을 갖는 디자인 패턴. 팩토리 메소드 패턴 헤드 퍼스트 Productinterface Pizza { public void prepare(); public void bake(); public void box();}Creatorabstract class PizzaStore { public Pizza orderPizza(String type) { Pizza pizza = createPizza(type); // factory method 사용 pizza.prepare(); pizza.bake(); pizza.box(); return pizza; } abstract Pizza createPizza(String type); // factory method extends하면 필수구현}/*뉴욕 피자*/class NYPizzaStore extends PizzaStore { @Override Pizza createPizza(String type) { if (\"cheese\".equals(type)) { return new NYStyleCheesePizza(); } else if (\"pepperoni\".equals(type)) { return new NYStylePepperoniPizza(); } return null; }}/*시카고 피자*/class ChicagoPizzaStore extends PizzaStore { @Override Pizza createPizza(String type) { if (\"cheese\".equals(type)) { return new ChicagoStyleCheesePizza(); } else if (\"pepperoni\".equals(type)) { return new ChicagoStylePepperoniPizza(); } return null; }}Mainpsvm(){ PizzaStore nyStore = new NYPizzaStore(); PizzaStore chicagoStore = new ChicagoPizzaStore(); Pizza pizza = nyStore.orderPizza(\"cheese\"); Pizza pizza1 = chicagoStore.orderPizza(\"pepperoni\");}위 처럼 추상클래스의 특징인 상속을 통해 자손 클래스에서 완성을 유도하는 방식으로(미완성 설계도) 구현한 패턴이다. 장 단점 장점 OCP와 DIP를 잘 지킴 느슨한 결합도 유지단점 자식 클래스가 많아지면서 코드가 복잡해질 가능성이 있음 결론 팩토리 메소드 패턴은 클래스간의 결합도를 낮추기 위함이다.객체를 직접 생성해서 사용하는 것을 방지하고 서브 클래스에 위임해서 효과적인 코드제어와 의존성을 제거함이다. 참고자료 참고 자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "생성패턴 - 싱글톤 패턴", "url": "/posts/singleton/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-22 12:15:07 +0900", "snippet": "Singleton Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 클래스의 인스턴스가 딱 1개만 생성되는 것을 보장하는 디자인패턴데이터베이스 연결 모듈에서 많이 쓰이는 패턴이다. 싱글톤 패턴이란? 전역 변수를 사용하지 않고 객체를 하나만 생성하도록 하며, 생성된 객체를 어디에 서든지 참조 할 수있도록 하는 디자인 패턴public class SingletonService(){ private static final SingletonService instance = new SingletonService(); public static SingletonService getInstance(){ return instance; } private SingletonService(){ } public void logic(){ //로직 }}// 다른 클래스public static void main(String[] args){ ... = new SingletonService() // 생성자가 private이기에 막을 수 있다.}위의 코드처럼 client가 요청할 때마다 객체를 생성하는것이 아닌, 이미 만들어진 객체를 공유해서 효율적으로 사용할 수 있다. 다만 수많은 문제점들이 있다. 장점과 단점 장점 객체보장 객체공유단점 기본 셋팅 코드가 많이 들어간다. (1번부터 15번 라인까지) DIP, OCP 위반한다. *의존 관계상 클라이언트가 구현 클래스를 의존함 단위 테스트를 하기 어렵다. 각각의 테스트마다 독립적인 인스턴스를 만들기 어려움 내부 속성을 변경하거나 초기화 하기 어렵다 아니 그럼 왜 이렇게 문제가 많은데 왜 쓰는거지? -&gt; 의존성 주입 (feat. 싱글톤 컨테이너!!) 메인 모듈이 직접 다른 하위 모듈에 대한 의존성을 주기보다는 중간에 의존성 주입(DI)을 통해 메인 모듈이 간접적으로 의존성을 주입하는 방식. `디커플링` 이라고도 한다. 의존성 주입의 장점: 모듈 간의 테스트를 쉽게하고 의존성 방향이 일관되고 관계가 명확해짐 단점: 클래스 수가 늘어나 복잡해지고 약간의 런타임 패널티가 생김스프링 컨테이너는 위에 언급한 문제점을 해결하면서 싱글톤의 장점을 살린다. `스프링 빈을 싱글톤 패턴으로 관리` 김영한 강의 자료중 일부 발췌 위의 그림처럼 싱글톤의 장점을 볼 수 있다.　　 　 결론 싱글톤 패턴은 안티패턴이라는 말이 있듯이 단독으로 사용되면 OOP설계를 위반하기 쉽다.하지만 위에서 소개한 내용대로 스프링 컨테이너의 도움을 받으면 싱글톤 패턴의 단점을 보완하면서 사용할 수 있다.*스프링 빈은 컨테이너의 도움을 받아 싱글톤 스콥으로 관리되고 있는걸 확인 할 수 있다. 참고자료 인프런 김영한 스프링 기본 강의" }, { "title": "생성패턴 - 빌더 패턴", "url": "/posts/builder/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-19 23:11:07 +0900", "snippet": "Builder Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 복잡한 객체를 생성할떈 setter, new 대신 빌더를 이용해서 생성과 표기를 분리하자! 빌더 패턴이란? 복잡한 인스턴스를 조립하여 만드는 구조로써 복합한 객체를 생성할때,객체를 생성하는 과정과 객체를 구현하는 방법을 분리함으로써,동일한 생성 절차에서 서로 다른 표현 결과를 만들 수 있는 디자인 패턴이다.필자는 StringBuilder를 통해 간접적으로? 쓰고 있었던 패턴이다.개발을 하다보면 유저에 포함된 정보가 엄청 많이 들어가진다. 그러다보면 필드값만 10가지가 넘는경우가 허다하다.그렇다고 유저를 생성할떄마다 필드값 전부를 다 쓰지않는다. email을 저장해도 되고 안해도 된다는 상황이 있다고 가정해보자.이럴 경우 생성자나 정적메소드를 이용하는 경우에는 필요할 떄마다 생성자를 만들거나 email에 의미없는 값을 넣어줘야한다.순서로부터 상관없는 Setter를 써도 되지만 불필요하게 확장 가능성을 열어두기에 SOLID원칙인 Open-Closed 법칙에 위배된다.그러므로 클래스 변수는 final로 객체 생성은 빌더를 사용하는게 좋다. //생성자 호출보단Member member = new Member(\"name\", age, height, email);//Setter 보단member.setName(\"name\"); member.setAge(age); Member member = member.builder() .name(\"name\") .age(age) ...//생략 이런식의 빌더를 쓰자! 결론 필요한 데이터만 설정가능하다 가독성 향상 유연성 불변성하지만 주로 웹 개발시, 엔티티 객체 또는 도메인객체로 DTO를 생성해서 다루기에 직접 빌더를 만들고 하는 작업이 번거로우니 MapStruct나 Model mapper에게 생성을 위임하자 참고자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "구조패턴 - 컴포지트 패턴", "url": "/posts/composite/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-12 15:11:04 +0900", "snippet": "Composite Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　 하나의 operation을 사용할때 client는 Component에 있는 operation만 쓰면된다. 컴포지트 패턴이란? 객체들의 관계를 트리구조로 구성하여 부분 - 전체 계층을 표현하는 패턴으로 사용자가 단일 객체와 복합 객체 모두 동일하게 다루도록 하는 패턴이다. 아래의 예제는 복합객체와 단일객체를 동일하게 취급하는 경우를 나타냈다.//기본 요소(basic component) 두개의 leaf가 필요로하는 메서드public interface Department { void printDepartmentName();}// LEAFS 1@RequiredConstructor @Getter @Setterpublic class FinancialDepartment implements Department { private Integer id; private String name; public void printDepartmentName() { System.out.println(getClass().getSimpleName()); } }// LEAFS 2@RequiredConstructor @Getter @Setterpublic class SalesDepartment implements Department { private Integer id; private String name; public void printDepartmentName() { System.out.println(getClass().getSimpleName()); }}복합 요소(Composite Element)public class HeadDepartment implements Department { private Integer id; private String name; private List&lt;Department&gt; childDepartments; public HeadDepartment(Integer id, String name) { this.id = id; this.name = name; this.childDepartments = new ArrayList&lt;&gt;(); } public void printDepartmentName() { childDepartments.forEach(Department::printDepartmentName); } public void addDepartment(Department department) { childDepartments.add(department); } public void removeDepartment(Department department) { childDepartments.remove(department); }}public class CompositeDemo { public static void main(String args[]) { Department salesDepartment = new SalesDepartment( 1, \"Sales department\"); Department financialDepartment = new FinancialDepartment( 2, \"Financial department\"); HeadDepartment headDepartment = new HeadDepartment( 3, \"Head department\"); headDepartment.addDepartment(salesDepartment); headDepartment.addDepartment(financialDepartment); headDepartment.printDepartmentName(); }}// SalesDepartment와 FinacialDepartment가 출력된다.위에는 계층구조로 된 회사 조직도를 코드로 나타낸것이다.재정부서, 판매부서, HR 이렇게 3곳을 나타냈다.HR은 복합, 재정,판매는 단일객체의 형태를 띄고있다. 즉, 단일객체와 복합객체를 구분하지않고 동일한 형태로 사용할때의 예시이다.아래의 main쪽을 보면 코드가 단순해지고 객체들이 모두 같은 타입으로 취급되므로 새로운 클래스를 쉽게 추가 할 수 있다.다만, 지나치게 범용성을 가진다면 이를 제어하기 어려워질 수가 있다. 결론 객체들 간에 계급 및 계층구조가 있고 이를 표현해야할 경우 클라이언트가 단일 객체와 집합 객체를 구분하지 않고 동일한 형태로 사용하고자 할 경우 개방 폐쇄 원칙을 지킬 수 있다. 참고자료 Source ⅠHead First 디자인패턴면접을 위한 CS 전공지식노트—" }, { "title": "구조패턴 - 플라이웨이트 패턴", "url": "/posts/flyweight/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-12-05 15:11:04 +0900", "snippet": "flyweight Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　 다수의 인스턴스를 가능한대로 공유시켜서 new처럼 불필요한 생성을 막아 메모리 낭비 최소화 100만원이 있는데 구매하고자 하는 메모리 점퍼가 120만원이다.점퍼를 매일 입지않는이상 60씩 지불하고 같이 돌려입으면된다.　　 플라이웨이트 패턴이란? 다수의 객체가 생성되는 경우(new Class) 모두가 갖는 본질적인 요소를 클래스화해서 공유함으로써 메모리를 절약하고,클래스의 경량화를 목적으로 하는 디자인 패턴이다. 여러개의 가상 인스턴스를 제공하여 메모리 절감을 함. 　　TreeType은 Tree 클래스에서 반복되는 상태를 추출한 클래스TreeFactory는 기존 TreeType을 사용할지 새로운 객체를 생성할지 결정하는 공간.Tree와 Forest는 flyweight의 클라이언트이며, Tree를 변경할 계획이 없으면 병합해도 된다.같은 데이터를 여러 객체에 저장하는 방법 대신에 몇개의 플라이웨이트 객체들에 보관해서 메모리를 효율적으로 운용하는 방식의 패턴 결론 프로그램이 많은 수의 객체들을 지원해야하는데 RAM이 꽉 찼을때 쓸만한 패턴 앱이 수많은 유사 객체들을 생성해야 할 경우 장치에서 사용할 수 있는 모든 RAM을 소모할 경우 여러 중복 상태들이 포함되어 있으며, 추출된 후 객체 간에 공유될 수 있을 경우 참고자료 Source ⅠHead First 디자인패턴면접을 위한 CS 전공지식노트—" }, { "title": "구조패턴 - 데코레이터 패턴", "url": "/posts/decorator/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-11-30 15:11:04 +0900", "snippet": "Decorator Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　 객체의 결합을 통해 기능을 동적으로 유연하게 확장(주요 기능에 무엇인가를 추가)신발끈 색만 바꾸고 싶을 때, 똑같은 신발을 살 필요 없이 신발끈만 사서 바꾸면 된다. Proxy 패턴과의 차이: 주요기능을 다양한 방식으로 컨트롤 해주는 것 데코레이터 패턴이란? 기존에 구현되어 있는 클래스에 필요한 기능을 추가해 나가는 설계 패턴으로써 기능확장이 필요할 때,객체간의 결합을 통해 기능을 동적으로 유연하게 확장할 수 있게 해주어 상속의 대안으로 사용하는 디자인 패턴이다. 데코레이터 패턴의 예 - Baeldung 　　위의 그림구조는 런타임에 원하는 만큼 데코레이터를 추가할 수 있는 유연성을 제공한다.기존의 장신구들이 있다면 굳이 트리를 살때, 똑같은 장신구를 살 필요없듯이 인터페이스로 받아서 사용하는 패턴이다.기본 윈도우interface Window { public void draw(); // draws the Window public String getDescription(); // returns a description of the Window}class SimpleWindow implements Window { public void draw() { } public String getDescription() { return \"simple window\"; }}데코레이터 클래스// abstract decorator class - note that it implements Windowabstract class WindowDecorator implements Window { protected Window decoratedWindow; // the Window being decorated public WindowDecorator (Window decoratedWindow) { this.decoratedWindow = decoratedWindow; }}// 첫번째 데코레이터 패턴 수직스크롤기능 추가class VerticalScrollBarDecorator extends WindowDecorator { public VerticalScrollBarDecorator (Window decoratedWindow) { super(decoratedWindow); } public void draw() { drawVerticalScrollBar(); decoratedWindow.draw(); } private void drawVerticalScrollBar() { // draw the vertical scrollbar } public String getDescription() { return decoratedWindow.getDescription() + \", including vertical scrollbars\"; }}// 두번째 데코레이터 패턴 수평스크롤 기능 추가class HorizontalScrollBarDecorator extends WindowDecorator { public HorizontalScrollBarDecorator (Window decoratedWindow) { super(decoratedWindow); } public void draw() { drawHorizontalScrollBar(); decoratedWindow.draw(); } private void drawHorizontalScrollBar() { // draw the horizontal scrollbar } public String getDescription() { return decoratedWindow.getDescription() + \", including horizontal scrollbars\"; }}데코레이터 패턴이 적용된 객체 호출public class DecoratedWindowTest { public static void main(String[] args) { // create a decorated Window with horizontal and vertical scrollbars Window decoratedWindow = new HorizontalScrollBarDecorator ( new VerticalScrollBarDecorator(new SimpleWindow())); }} 결론 객체에 단순히 동작이나 상태를 CRUD할 경우 클래스의 하나의 object 기능을 수정하고 다른 개체는 변경 할 필요 없을 경우 참고자료 Source ⅠSource ⅡHead First 디자인패턴면접을 위한 CS 전공지식노트—" }, { "title": "구조패턴 - 브릿지 패턴", "url": "/posts/Bridge/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-11-23 18:21:07 +0900", "snippet": "Bridge Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　 기존의 시스템에 부수적인 새로운 기능을 추가할떄 사용하는 패턴하나의 클래스, 메서드를 통해서 징검다리 역할 브릿지 패턴이란? 기능의 클래스 계층과 구현의 클래스 계층을 연결하고, 구현부에서 추상 계층을 분리하여 추상화된 부분과 실제 구현 부분을 독립적으로 확장할 수 있는 디자인 패턴구현뿐만 아니라, 추상화된 부분까지 변경해야하는 경우 활용할 수 있다. 브릿지 패턴의 예 - Baeldung 　　세모와 네모는 다른 생김새지만 Shape이라는 특징이 같다. 그러므로 Shape으로 묶고 색상도 색은 다르지만 Color로 묶음으로써 사용자는 원하는 shape과 color를 사용할 수 있게 하는 구조이다.색 관련 코드public interface Color { String fill();}public class Red implements Color { @Override public String fill() { return \"발간색\"; }}public class Blue implements Color { @Override public String fill() { return \"파란색\"; }}그리는 툴 추상클래스public abstract class Brush { protected Color color; protected Brush(Color color) { this.color = color; } public abstract String draw(); }public class HBPencil extends Brush { public static final String type = \"[연필]\"; public HBPencil(Color color) { super(color); } @Override public String draw() { return type + \" \" + color.fill(); }}public class MonoLine extends Brush { public static final String type = \"[붓]\"; public MonoLine(Color color) { super(color); } @Override public String draw() { return type + \" \" + color.fill(); }}메인 테스트 코드class BrushTest { @Test @DisplayName(\"브리지 패턴 테스트\") void brushColorTest() { Brush redBrush = new HBPencil(new Red()); Assertions.assertThat(\"[연필] 빨간색\".equals(redBrush.draw())); Brush blueBrush = new MonoLine(new Blue()); Assertions.assertThat(\"[붓] 파란색\".equals(blueBrush.draw())); }} 결론 부모 추상클래스가 규칙을 정의할수 있고, 클래스에 규칙을 추가하고 싶을 경우 객체에 대한 참조가 있는 추상클래스가 있고, 각각의 클래스에서 정의될 추상 메서드가 있는 경우 참고자료 Source ⅠHead First 디자인패턴면접을 위한 CS 전공지식노트—" }, { "title": "구조패턴 - 어댑터 패턴", "url": "/posts/adapter/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-11-16 21:21:07 +0900", "snippet": "Adapter Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　 기존의 시스템에 새로운 써드파티 라이브러리를 추가하거나 레거시 인터페이스를 새로운 인터페이스로 교체하는 경우다른 인터페이스를 자신의 인터페이스 스타일로 변경하겠다. Facade 패턴과의 차이: 복잡한 기능을 중간에서 감추고 심플하게 단방향 통신하겠다 어댑터 패턴이란? 해외 여행 어댑터 우리가 해외여행을 가면 220V를 110V에 바로 전기를 꼽지못하지만 사용할 수 있도록 도와주는 친구가 어댑터다.이 개념을 똑같이 코드에 가져가서 생각하면된다. 상황 Object 어뎁터 Client는 Target 인터페이스를 구현한 Adaptee가 필요하다.Adaptee는 Target인터페이스를 구현하지 않고 있다.Adaptee는 이미 개발이 완료되어 사용중이다.Adaptee를 변경하는 것이 적절하지 않은 상황이다.// Adaptee는 이미 개발이 완료되어 사용중이고 변경하는 것이 적절하지 않음.public interface Plugin { public void connect();}public class Plugin220V implements Plugin { @Override public void connect() { System.out.println(\"220V\"); }해결 방법 (많은 사람들이 사용하는 방식인 Object Adapter 방식으로 구현)대부분의 코드를 구현해야하지만 Composition을 사용하기에 유연함으로 많은사람이 채택함.Adapter// 어뎁터 클래스를 만든다.public interface PluginAdapter { public void connect();}clientpublic class Adapter110V implements PluginAdapter { private Plugin plugin;\t public Adapter110V(Plugin plugin) { this.plugin=plugin; } @Override public void connect() { System.out.println(\"110v convert\"); this.plugin.connect(); }//mainpublic class AdapterPattern { public static void main(String[] args) { PluginAdapter plugin = new Adapter110V(new Plugin220V()); plugin.connect(); }}기존에 생성된 클래스를 재사용할 수 있도록 중간에서 맞춰주는 역할을 하는 인터페이스를 만드는 패턴으로써상속을 이용하는 클래스 패턴과 위임을 이용하는 인스턴스 패턴의 두 가지 형태로 사용되는 디자인 패턴이다.인터페이스가 호환되지 않는 클래스들을 함께 이용할 수 있도록 다른 클래스의 인터페이스를 기존 인터페이스에 덧씌운다.Class 어댑터에서는 어댑터를 만들 때 타겟과 어댑티 모두의 서브 클래스로 만들고,Object 어댑터 에서는 구성을 통해서 어댑티에 요청을 전달한다는 점을 제외하면 별다른 차이점이 없다 결론 변경할 수 없는 내부 구현, 라이브러리 등에 추가적인 기능을 만들고 싶을 때 유용하게 활용할 수 있다.사용해야하는 인터페이스가 현재의 시스템과 호환되지 않는다고 해서 굳이 현존하는 시스템을 호환되도록 변경할 필요는 없다. 참고자료 Source ⅠHead First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "구조패턴 - 파사드 패턴", "url": "/posts/fasade/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-11-07 20:11:07 +0900", "snippet": "Facade Pattern 🧙‍♂️ 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 Problem 프로젝트 때, 하나의 메서드에서 여러가지 객체들을 호출하는 구조가 있었다.그러다보니, 코드의 가독성이 떨어지고 여러 객체들이 의존성을 갖게 되기 떄문에 문제가 발생되었다. 이를 해결하기 위해 파사드 패턴을 도입했다. 입금만 가능한 기계, 출금만 가능한 기계가 있는게 아니듯이 하나의 ATM기에서 여러 일을 처리하는 것 Adapter 패턴과의 차이: 다른 인터페이스를 자신의 인터페이스 스타일 대로 변경 파사드 패턴이란? 출처- 나무위키 　　파사드 패턴은 하위 객체들을 쉽게 사용할 수 있도록 고수준 객체를 만들어서 문제를 해결하는 패턴이다.복잡한 시스템에 대하여 단순한 인터페이스를 제공함으로써 사용자와 시스템 간의 결합도를 낮추어 시스템 구조에 대한 파악을 쉽게 하는 패턴으로 오류에 대해서 단위별로 확인 할 수있게 하며, 사용자의 측면에서 단순한 인터페이스 제공을 통해 접근성을 높일 수 있는 디자인 패턴이다. 해당 내용을 이해하기 위해 아래의 코드를 보자./* 저수준 하위 객체들 */class CPU {\tpublic void freeze() { ... }\tpublic void jump(long position) { ... }\tpublic void execute() { ... }}class Memory {\tpublic void load(long position, byte[] data) {\t\t...\t}}class HardDrive {\tpublic byte[] read(long lba, int size) {\t\t...\t}}/* 파사드 역할 */class Computer {\tpublic void startComputer() { CPU cpu = new CPU(); Memory memory = new Memory(); HardDrive hardDrive = new HardDrive();\t\tcpu.freeze();\t\tmemory.load(BOOT_ADDRESS, hardDrive.read(BOOT_SECTOR, SECTOR_SIZE));\t\tcpu.jump(BOOT_ADDRESS);\t\tcpu.execute();\t}}/* Client */class Client {\tpublic static void main(String[] args) throws ParseException {\t\tComputer facade = /* 파사드 인스턴스 */;\t\tfacade.startComputer();\t}} 클라이언트가 파사드(컴퓨터)를 통해서 컴퓨터를 제어하는 예제이다. 　　이처럼 하나의 클래스로 저수준의 객체를 모아서 관리하므로써 클라이언트는 컴퓨터만 신경쓰면 되는 구조로 바뀌었다. 필요한 기능만 들어간 단순한 인터페이스를 구현함으로써 문제발생이 줄어듬과 동시에 코드가 명료해진다.다만, 잦은 파사드 패턴은 하나로 모아 관리하는 객체가 복잡해진다는 것이다. 따라서 무조건적으로 넣는게 아닌 저수준의 객체들도 최대한 간단하게 설계해서 만들어야 파사드 패턴의 이점을 가져갈 수 있다.　 참고자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "Basic Confusing Questions Ⅱ 🤷‍♂️ (17개)", "url": "/posts/java-basic-2/", "categories": "CS, Questions", "tags": "cs, questions", "date": "2022-11-06 19:20:57 +0900", "snippet": "Basic Confusing Questions Ⅱ 🤷‍♂️ 클릭하면 정답이 나옵니당~자바의 정석(남궁성 지음)에서 인용한 코드와 내용을 담고 있습니다. REST API란 무엇인가요?\t 택배 송장번호에 우리가 맞춰서 양식을 작성하듯이…일종의 형식이다.각 요청이 어떤 동작이나 정보를 위한 것인지를 추론 가능하게 해야하는 형식. www.도메인/(명사들로) 이부분을 작성하는거며, GET,POST DELETE,PUT,PATCH 같은 기능으로 비교적 안전하게 보낼수있다.PUT은 정보를 통째로 갈아 끼울떄, patch는 정보중 일부를 특정방식으로 교체할떄 씀 장점 Uniform InterfaceHttp 표준을 따르면 어떠한 플랫폼이든 기술에 종속되지않고 URI로 지정한 리소스에 대한 조작이 가능한 아키텍처 스타일 무상태성 Stateless상태정보를 저장하고 관리하지않는다. 세션정보, 쿠기정보를 별도로 저장하고 관리하지않는다. API요청만 처리할뿐… 캐시가 가능하다.HTTP가 가진 캐싱기능을 적용할 수있다. Last-Modified 태그나 E-Tag를 이용하면 캐싱 구현이 가능. 계층형 구조REST는 다중 계층으로 구성가능하면서 보안, 로드 밸런싱, 보안계층을 추가해서 구조의 유연함을 챙길수 있다. 또한, 프록시 게이트웨이 같은 중간 매체를 사용할 수 있게 된다. 단점 HTTP 메소드가 제한적이다. 표준이 없다. DNS의 정의와 DNS가 필요한 이유에 대해 설명해주세요.\t\t 도메인의 이름을 통해 IP주소를 가져오는 프로토콜입니다. DNS가 필요한 이유는 우리가 모든 ip주소 알지않아도 해당 주소값을 도메인이름을 통해 찾아오게 해줍니다. A Record - IP와 도메인과의 직통 연결CNAME (canonical name) - IP가 유동적으로 변하는 서버를 위한 도메인 방식 (aws, firebase를 사용할 때) URL과 URI의 차이점이 무엇인가요?\t URL ⊂ URI URI는 식별하고, URL은 위치를 가르킨다. URI는 Uniform Resource Identifer 통합자원식별자로써 웹 기술에서 사용하는 논리적 또는 물리적 리소스를 식별하는 문자열 시퀀스. URL은 웹주소로 네트워크 사에서 리소스가 어디에 있는지 알려주기 위한 규약을 지칭하는것이다. URI의 구조 scheme:[//[user[:password]@]host[:port]][/path][?query][#fragment] scheme:사용하는 프로토콜[user[:password]@]host[:port]: 사용자의 이름,비번 + 접근할 호스트명,포트번호[/path]: 접근할 대상의 경로 [?query][#fragment]: “ 대상에게 전달하는 추가적인 정보(파라미터) + 메인 리소스 내에 존재하는 서브 리소스에 접근할 때 식별하기 위한 정보 웹 브라우저에서 CORS 이슈가 발생하는 원인은 무엇이며, 서버에서 어떻게 해결할 수 있나요? CORS의 경우 Origin을 기반으로 리소스에 접근하는것을 제한하는 기능입니다. 이는 다른 출처에서 리소스 접근을 제한하는 보안 기능입니다. 이를 해결하기 위해, 서버측에서는 허용하기로한 Origin을 서버 프로그램에 등록하는 것입니다. 또한, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Access-Control-Allow-Methods 등의 헤더를 사용하여 CORS에러를 해결할 수 있습니다. 이진 탐색 알고리즘(BST)이 데이터를 효율적으로 찾기 위해 탐색하는 과정을 설명해주세요.\t 이진 탐색 트리는 데이터를 효율적으로 검색하기 위한 알고리즘입니다.루트노드를 시작으로 데이터의 크고 작음을 기반으로 해서 리프노드까지 찾아나가는 방식입니다.시간 복잡도의 평균은 O(logN)이고 최악은 O(N)이 될 수 있습니다. (모든 노드가 한쪽으로 치우쳐 있을 경우) 추가 삭제의 경우에도 검색을 먼저한후 실행합니다. 탐욕(Greedy) 알고리즘을 사용하기 위해 성립해야 하는 조건에 대해 설명해주세요. (가장 적은 개수로 구하는 동전개수 알고리즘) 다른 알고리즘과 다르게 모든 선택지를 고려해보고 답을 정하는 방식이 아닌, 재귀하는 각 단계마다 남은 선택들에 대해서는 고려하지않은채 가장 베스트 옵션을 선택해서 진행하는 방식이다. 이 알고리즘을 사용하기 위해서는 앞의 선택이 이후의 선택에 영향을 주어선 안되고 문제에 대한 최종 해결방법은 부분문제에 대한 최적 문제해결방법으로 구성된다. (탐욕적 선택 속성, 최적 부분 구조) 이러한 구조를 메트로이드라 한다. 인접 행렬과 인접 리스트의 차이점은 무엇인가요?\t\t 인접 행렬은 노드(1),엣지(0)을 모두 표현해야하므로 노드가 늘수록 메모리를 많이 차지한다. 대신 검색속도는 빠르다. 반면 인접리스트는 리스트(-&gt;)로 표현했기 때문에 연결된 노드들만 표현하기에 메모리를 덜차지하지만 검색속도는 느리다. Stack과 Queue의 차이점에 대해 설명해주세요.\t queue는 FIFO 방식으로 된 구조로써 처음 들어간 인자가 처음에 나오는 형태입니다. 반면 stack의 경우 LIFO방식으로 나중에 들어간 인자가 처음에 나오는 형태입니다. stack LIFO ex) 웹페이지 방문기록. 실행취소(뒤돌아가기), 후위표기법 계산.. Queue FIFO ex) 너비우선탐색, 프린터 인쇄 대기열 DI(Dependency Injection)에 대한 설명과 해당 기술의 장점\t 다형성만으로는 유지보수를 쉽게 할수없다. 역할과 구현체를 따로 분리하여 역할(인터페이스)끼리 의존관계를 설정해서 구현체가 바뀌더라도 큰 로직은 일정하게 유지되는 인터페이스를 의존하고 구현체는 분리하는 방법을 의미한다.이러한 구조는 구현클래스만 바꾸면서 유지보수, 클래스 교체를 쉽게 할 수 있다. 스프링 컨테이너(Spring Container)에 대해 설명 개발자가 직접 빈의 생명주기를 관리하는 것이 아닌 스프링 컨테이너에게 위임하므로써, 의존관계 설정을 자동으로 해주는 역할을 한다. 또한, 기본적으로 싱글톤으로 빈들을 관리하기떄문에 일관된 객체 인스턴스를 사용함으로써 재사용성과 메모리의 효율적인 사용을 합니다. new, 인터페이스 호출, 팩토리 호출 방식으로 객체 생성과 소멸을 개발자가 할수 있지만, 제어흐름을 컨테이너에게 맡겨서 관리해주는 컨테이너이다. 의존관계 또한 런타임 과정에서 알아서 만들어준다. ApplicationContext는 BeanFactory + 부가 기능(국제화 기능, 환경 변수 관련 처리, 애플리케이션 이벤트, 리소스 조회)을 가진다.스프링 컨테이너는 기본적으로 빈을 싱글톤으로 관리해준다. 따라서 싱글톤 컨테이너라고 불리기도 한다. 스프링 컨테이너가 빈을 싱글톤으로 관리해주면서 기존 싱글턴 패턴의 문제점(싱글톤 패턴 구현을 위한 코드가 추가되어야함, 구체 클래스에 의존, 유연성이 떨어짐 etc)은 없어지고, 싱글톤의 장점(매번 인스턴스를 생성할 필요없이 단 하나만 생성해서 비용을 줄일 수 있다.)만 가져갈 수 있다. Spring에서 AOP가 필요한 이유에 대해 설명 모든 컨트롤러단에서 필요한 기능이 생겼을때, 중복된 코드를 사용하지않고 어노테이션으로 묶거나 특정 범위를 지정하여 일을 처리하는데 용이한 기능입니다. 예를 들어, 로깅이나 트랜잭션처럼 모두 적용해야하는 기능이 있을때 쉽게 처리할수 있습니다. 둘째, 시스템의 유연성을 높일 수 있습니다. AOP를 사용하면 여러 모듈에서 공통적으로 사용되는 기능을 모듈화할 수 있습니다. 이를 통해 시스템의 유연성을 높이고, 필요에 따라 모듈을 추가하거나 제거할 수 있습니다. 셋째, 관심사의 분리(Separation of Concerns)를 구현할 수 있습니다. AOP를 사용하면 비즈니스 로직과 시스템의 부가적인 기능(로깅, 보안 등)을 분리하여 구현할 수 있습니다. 이를 통해 코드의 가독성을 높이고, 유지보수를 용이하게 할 수 있습니다. 넷째, 프로그램의 성능을 향상시킬 수 있습니다. AOP를 사용하면 필요한 시점에만 코드를 실행할 수 있습니다. 이를 통해 불필요한 코드 실행을 방지하고, 프로그램의 성능을 향상시킬 수 있습니다. Foreign Key와 Primary Key에 대해 설명 둘다 레코드를 식별하는 곳에 사용됩니다. 차이점으로는… 우선 기본키는 각 레코드를 식별하는 키이고 외래키는 다른 테이블의 기본키를 참조하는 키입니다. 기본키는 널값을 가질수 없는 반면 외래키는 널값을 가질수 있고 기본키는 필수사항이지만 외래키는 필수사항이아닙니다. 하지만 참조 무결성을 위해 외래키를 사용하는 것이 좋습니다. 트랜잭션에 대해 설명 트랜잭션은 커밋, 롤백의 2가지 기능만으로 해당 작업이 성공했으면 커밋 실패했으면 롤백을 통해, 데이터의 일관성을 지키는 것입니다. 트랜잭션은 ACID의 원칙을 지켜야하며 이는 원자성, 지속성, 독립성, 영속성 4가지가 있습니다. Client Side Rendering 과 Server Side Rendering 의 차이점에 대해서 설명 “SSR - 서버쪽에서 랜더링 준비를 끝마치고 클라이언트에게 전달하는 방식.. 초기 구동속도가 빠르고 검색 엔진 최적화(SEO)에 유리하다 하지만 서버부하와 로딩중에 화면 깜빡임이 있다. CSR - 초기로딩과 SEO에 불리하지만 화면 깜빡이는 현상, 서버부하에 영향을 덜 준다. TTV (time to view) 와 TTI (time to interact) 사이의 간격이 없다” 재귀 함수와 반복문의 차이점에 대해 설명 재귀함수는 자기자신을 호출하면서 반복하는 행동이고 반복문은 for, while문을 통해 반복하는 행동입니다.재귀는 호출을 많이 할수록 스택에 쌓이면서 메모리를 많이 차지합니다. 반면, for문은 재귀에 비해 상대적으로 빠르고 메모리사용도 적습니다. 하지만, 특정경우에는 재귀함수가 더 빠르게 작동할때도 있습니다. @component, @Configuration 차이\t Component의 경우 개발자가 구현한 메서드를 빈에다가 등록하는 것이고 Configuration 같은 경우에는 구현된 외부 라이브러리를 받아와 재구성하여 등록하는 경우 사용하는 어노테이션입니다. 내가 직접만든 메소드를 빈에 등록해서 사용한다면 @component 외부라이브러리나 어디서 끌어써야한다~ @bean + @configuration 사용해야함. 다이나믹 알고리즘을 사용하기 위한 성립 조건에 대해 말해줘\t 큰문제를 작은 문제의 단위로 잘게 쪼개면서 작은 문제를 해결한뒤 메모이제이션을 통해 얻은 해답에 대한 값을 또 구하지않도록 설정하면서 문제를 해결해 나아가는 알고리즘입니다. " }, { "title": "구조패턴 - 프록시 패턴", "url": "/posts/proxy/", "categories": "CS, Design Pattern", "tags": "cs, design pattern", "date": "2022-11-02 15:10:57 +0900", "snippet": "Proxy Pattern 디자인 패턴이란? 디자인 패턴이란? 디자인 패턴은 소프트웨어 공학의 소프트웨어 설계에서 공통으로 발생하는 문제를 자주 쓰이는 설계 방법을 정리한 패턴이다. 디자인 패턴을 참고하여 개발하면 효율성과 유지보수성, 운용성이 높아지며, 프로그램 최적화가 된다고 한다.　 디자인 패턴을 목적과 범위로 나눌수 있다 구분 유형 설명   생성 객체 인스턴스 생성에 관여, 클래스 정의와 객체 생성 방식을 구조화, 캡슐화를 수행 목적 구조 더 큰 구조 형성 목적으로 클래스나 객체의 조합을 다루는 패턴   행위 클래스나 객체들이 상호작용하는 방법과 역할 분담을 다루는 패턴 범위 클래스 클래스간 관련성(상속), 컴파일 시 정적으로 결정   객체 객체 간 관련성을 다루는 패턴, 런타임 시 동적으로 결정 　　 프록시 패턴이란? 구조 패턴 중 하나로 실체 객체에 대한 대리 객체로 실체 객체에 대한 접근 이전에 필요한 행동을 취할수 있게 만들어준다. 이 점을 이용해서 미리 할당하지 않아도 상관없는 것들을 실제 이용할때 할당하게 하여 메모리용량을 아낄 수 있으며 실체 객체를 드러나지 않게 하여 정보은닉의 역할도 수행하는 디자인 패턴이다. 프록시? 일종의 대리자이자 비서 (주요기능을 다양한 방식으로 컨트롤 해주는 것)팀장님한테 바로 보고하는게 아니라 사수한테 먼저 물어보는 방식 Decorator 패턴과의 차이: 주요기능에 기능을 추가하는 것 프록시 패턴 from wiki 대표적인 프록시 가상 프록시 : 프록시 클래스에서 자잘한 작업들을 처리하고 리소스가 많이 요구되는 작업들이 필요할 때에만 주체 클래스를 사용하도록 구현e.g) 해상도가 아주 높은 이미지를 처리해야 하는 경우 작업을 분산처리 　　 - 용량이 큰 이미지와 글이 있는 문서를 화면에 띄울떄, 텍스트를 먼저 불러오고 이미지는 추후처리 원격 프록시: 서로 다른 주소 공간에 있는 객체에 대해 마치 같은 주소 공간에 있는 것처럼 동작하는 방식. e.g) google Docs 브라우저는 브라우저대로 필요한 자원을 로컬에 가지고 있고 또다른 자원은 Google 서버에 있는 형태 보호 프록시: 객체에 대한 접근 권한을 제어하거나 객체마다 접근 권한을 달리하고 싶을때 사용하는 방식.e.g) 권한을 가진 사용자만이 정보열람을 할 수 있는 프로그램이는 SOLID의 OCP(open closed principle), DIP (Dependency Inversion principle)의 설계원칙을 적용한 패턴으로 볼 수있다.실제 이미지public interface Image { void displayImage();}public class Real_Image implements Image { private String fileName; public Real_Image(String fileName) { this.fileName = fileName; loadFromDisk(fileName); } private void loadFromDisk(String fileName) { System.out.println(\"Loading \" + fileName); } @Override public void displayImage() { System.out.println(\"Displaying \" + fileName); }}프록시 이미지public class Proxy_Image implements Image { private Real_Image realImage; private String fileName; public Proxy_Image(String fileName) { this.fileName = fileName; } @Override public void displayImage() { if (realImage == null) { realImage = new Real_Image(fileName); } realImage.displayImage(); }}//mainpublic class Proxy_Main { public static void main(String[] args) { Image image1 = new Proxy_Image(\"test1.png\"); Image image2 = new Proxy_Image(\"test2.png\"); image1.displayImage(); System.out.println(); image2.displayImage(); }} 장 단점 장점 사이즈가 큰 이미지(객체)가 로딩되기 전에도 프록시를 통해 참조가능 실제 객체의 public, protected 메소드들을 숨기고 인터페이스를 통해 사용가능 로컬에 있지않은 객체,메소드를 사용할 수 있다. 객체의 접근에 대해 사전 처리가능.단점 객체를 생성할때 한 단계를 더 수행하기 떄문에, 자주 사용 시 성능저하 가독성 저하 프록시 내부에서 객체 생성을 위해 스레드 생성, 동기화가 구현되어야하므로 성능저하 결론 직접 실행 메서드를 호출하는 것을 피하면서 흐름을 제어하는데 큰 도움을 주는 패턴이다. 참고자료 코드 자료Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "AOP", "url": "/posts/Aop/", "categories": "Aop", "tags": "java, spring", "date": "2022-10-26 13:52:57 +0900", "snippet": "“AOP? 횡단관심사?” 사용하게 된 계기 토이 프로젝트에서 여러명이서 각기 다른 컨트롤러를 개발하다보니 컨트롤러 단에서 중복되는 불필요한 코드가 많아졌다.또한, 컨트롤러에서 핵심로직에 대한 가독성이 떨어지는 결과가 나타났다.　 서로 다른 컨트롤러 끼리 묶음 　위와 같이 서로 다른 컨트롤들에 공통적으로 필요한 기능들을 횡단관심사로 묶어서 AOP기술을 사용했다.토큰으로부터 얻고자하는 관심사를 묶고 컨트롤러 앞단에서 해당 로직을 처리하여 컨트롤러에서 보내주도록 리팩토링했고그 결과 컨트롤러에 불필요한 코드가 줄어들고 파라미터 또한 줄어들어, 작업속도 좋은 영향을 주었다.　 어노테이션으로 묶어서 진행 이 글은 공식문서의 AOP부분을 참고하여 작성하였습니다.스프링 공식문서 AOP의 탄생 배경 개발을 하다 보면 여러 메서드에서 동일한 부가기능을 필요로 하게된다.그렇다면 무식하게 복붙 스킬을 써서 적용하면 된다고 생각할 수 있다. 하지만 이게 100개 이상이라면? 번거롭고 다른사람이 해당 작업을 할때 굉장히 부담스러워진다.결국 위와같은 문제를 해결하기 위해 나온 것이 AOP이다.핵심 로직과 부가 기능을 분리하고 한곳에 로직을 관리하는 기능을 만들었다. 이것이 @aspect 이다.aop는 oop와 같은 하나의 패러다임이고 많은 언어들이 지원하고 있고, Java에서는 AspectJ라는 방식으로 사용되고 있다.하지만 필자는 스프링을 사용하고 스프링에서는 AOP 프록시를 사용하기에 스프링 aop가 제공하는 기능을 말할 예정이다.   Spring AOP Aspect J join point 메서드 레벨만 지원함 생성자, 필드, 메서드 등 다양하게 지원 weaving 런타임 시에만 가능 런타임은 제공안하고 컴파일때,post컴파일 load time 때 제공 대상 Spring 컨테이너가 관리하는 bean만 모든 java Object에 가능 위빙: 옷감을 짜다 애스펙트와 실제 코드를 연결해서 붙이는 것 그래서 AOP 넌 뭔데? AOP를 알기 위해서는 우선 용어를 알아야한다.@Aspect : 여러 클래스에 흩어진 관심사의 모듈화Target : 어떤 대상에 부가기능을 부여할것인가Advice : before, afterReturning 등등 언제 사용할지? 아래 그림 참조Join point : 어디에 적용할 것인지? 메서드 (필드, 객체, 생성자)Point cut : 실제 advice가 적용될 지점, 즉 적용될 메서드 위치　 용어는 알겠고… 주의사항 스프링은 앞서 말했듯이 프록시 방식의 AOP를 사용한다. 이는 메서드 내부 호출에 프록시를 적용할 수 없는 치명적인 문제가 일어난다. ㅡ (해결방안 수정예정) 결론 AOP는 다양한 방면에서 우리가 알게 모르게 쓰고있다. filter, 인터셉터, @Transactional도 aop의 한 종류이다." }, { "title": "인터넷 사용법?", "url": "/posts/internetworks/", "categories": "CS, Internet", "tags": "cs, internet", "date": "2022-10-19 09:41:57 +0900", "snippet": "Internet 너는 대체 무엇인고? 🤷‍♂️전 세계에 걸쳐 파일 전송 등의 데이터 통신 서비스를 받을 수 있는 컴퓨터 네트워크 시스템이다.www.google.com을 찾아가는 데 있어서 바로 가는 것처럼 보이지만 수많은 노드들을 통해 지나간다.그런 과정들을 아래에 풀어보고자 한다.우선 처음으로 인지해야 하는 점은 계층에서 무슨 일이 일어나는지에 대한 로드맵이다.이는 인터넷에서 서로 다른 기종의 컴퓨터들이 서로 정보를 주고받는데 쓰이는 프로토콜의 집합을 뜻한다.아래의 방식의 규칙을 통해 우린 인터넷을 사용하고 있다.각 계층마다 무슨 액션을 했는지 알았으니,이젠 구글 URL 검색 시 무슨 일이 일어나는지… 컴퓨터가 구글닷컴을 어떻게 이해하는지 한번 보자.우선 Https://를 사용하기로 했으니 TCP연결을 한다는 것이고.. TCP 연결할 서버 주소를 찾아야한다. 그것이 바로 DNSDNS? Domain Name Systemwww.google.com을 예로 들면 www를 제외한 나머지를 지칭하는 말이다.왜 이 말은 처음으로 시작했냐면….원래는 IP 주소인 123.456.789.000을 검색해서 들어가야 하는데 일일이 다 외울 수 없지 않은가? 우리도 누군가에게 전화할 때 전화번호부에서 이름을 검색해서 찾듯이 우리에게 도움 주는 프로토콜이 바로 DNS다.물론 host 파일이나 DNS cache 데이터가 있으면 아래와 같은 일 작동하지않는다.BUT 우린 지금은 둘다 정보가 없다는 가정하에 설명을 하겠다. PC가 아래의 순서대로 질의를 시작한다.DNS 작동원리 브라우저에서 구글로 접속하려고 하는데 구글 서버의 IP를 모르는 상황 브라우저는 pc에 설정된 로컬 dns서버로 이동함. (통신사마다 local서버가 다르고, 또한 주소가 캐싱되어있다면 바로 반환함) 주소 값이 어딨는지 모르면 root 서버에게 요청을 보냄 (root dns 서버는 전 세계에 13군데가 있음) root서버는. com이라는 주소 값을 local dns서버로 반환함 그걸 토대로. com 담당 서버에게 보내줘서 해당 주소를 반환함. com서버가 보내준 결과를 토대로 google.com서버에 가서 주소 값을 얻어와서 마침내 브라우저에게 반환하고… ※ 여기서 장난질 치는 게 dns 스푸핑 브라우저에서 반환된 주소 값으로 구글 서버로 접속하게 된다. A Record는 뭐고 CNAME은 또 뭐지?A Record - IP와 도메인과의 직통 연결 구글 행님과의 직통전화010.123.12.123 &lt;=&gt; 주소CNAME (canonical name) - IP가 유동적으로 변하는 서버를 위한 도메인 방식 (aws, firebase를 사용할 때 쓰는 방식)A record는 직접적으로 IP가 할당되어 있기 때문에 IP가 변경되면 직접적으로 도메인에 영향을 미치지만, CNAME은 도메인에 도메인이 매핑되어 있기 때문에 IP의 변경에 직접적인 영향을 받지 않는다. 나의 블로그도 CNAME으로 매핑되어있는 상황이다. 원주소는 ms92kim/github.io 였다.그럼 HTTP request 메시지를 구글 웹서버(포트 80)에게 보내는 것이다. 이 request를 위해서는 패킷을 만들어야 한다. 기본적인 HTTP 구조         Start Line 시작라인       Header 헤더       empty line 공백라인       Message body 메시지 바디       자세한 구조가 궁금하다면 CLI 창에 아래와같이 치면된다. curl -v www.google.com?query==http위와 같은 패킷을 통해 전송계층으로 진행한다면 TCP가 두두둥장한다.TCP/전송계층Transport layer(전송계층)은 한 줄로 요약하면 \"End point 간 신뢰성 있는 데이터 전송을 담당하는 계층\"이다여기서 신뢰성은 데이터를 순차적, 안정적으로 전달 하는 걸 의미하고전송은 포트 번호에 해당하는 프로세스에 데이터를 전달하는 것을 의미한다.이외에도 TCP 프로토콜은 양방향 통신(3 way handshake), 흐름 제어, 혼합 제어, 오류 감지를 한다. (flow control,Congestion Control, Error Detection)TCP에서는 프로토콜 데이터 단위(PDU)로 세그먼트(Segment)를 사용하는데 큰 데이터를 잘게 잘라서BIG Data → (TCP Header + Data) + (TCP Header + Data) + (TCP Header + Data) 식으로 만든다.좀 더 자세히 알아보기 위해 아래 그림을 보자#TCP IP HEADER처음 보면 이거 뭐고…?라는 생각이 들것이다. 물론 당연한 생각이다. 하지만 여기선 빨간색으로 된 부분에 대한 얘기만 할 것이다. header에 이런 내용이 담겨있구나 정도만 알면 된다. 빨간색 부분 즉 컨트롤 비트를 이해하기 위해 3-way handshake로 설명하겠다.#3way handshake (connetion 연결) 처음 클라이언트가 서버에게 연결 요청할 때. SYN 플래그를 사용한다. SYN에다가 비트를 1로 설정해 패킷을 송신한다. 그럼 서버에서 ACK를 통해서 “내가 받았어!” 이런 제스처를 보낸다. 즉 ACK 비트를 1로 설정해서 패킷을 송신한다. 하지만, 그림에서는 서버에서 보낼 때 SYN도 비트를 1로 한다. 이유는 바로 앞서 말한 양방향 통신이기에 서버 또한 클라이언트한테 요청을 요하는 SYN을 사용한다. 그럼 클라이언트는 서버가 “오 나랑 연결에 응했네?”라며 ACK를 보내어 “나도 받았어”를 전달하는 방식이다.#3줄 요약.- SYN 연결 뚫을 때 사용함- ACK 뭔가를 받았을 때 보내야 하는 패킷, 만약 못 받았다? 그럼 일정 시간 있다가 또 패킷을 쏜다.- 이를 토대로 packet을 왔다 갔다 함.4 way handshake (connection close)통신을 종료할 때 사용되면서, 3 way와 비슷하게 “다 보냈어?”를 확인하는 FIN을 이용하는 것이 추가되었다.#이렇게 신뢰성도 보장해주고 흐름 제어도 해주고 만능인 것 같은 TCP도 사실 문제점이 있다.패킷을 중간에 잃어버리거나 도달하지 못하면 재전송해야 하는 점과 시간 손실이 발생된다.그래서 나온 게 UDP이다.순차 전송도 안 하고 흐름 제어도 안되고 혼잡 제어도 안되지만 전송 속도가 빠른 프로토콜이다.이유는 TCP는 데이터를 쪼개는 반면 UDP는 데이터 앞에 header만 장착 후 발송하기 때문이다.그래서 영상 스트리밍에서 자주 사용된다. (데이터의 신뢰성이 중요하지 않기 때문이다.)자 아무튼 이렇게 HandShaking을 통해서 드디어 연결이 이루어지고 데이터가 오가게 된다.그럼 데이터를 우쨰 보내야 하나….?IP 인터넷 계층 + Network Access Layer우리가 쓰는 컴퓨터는 보통 Private IP를 사용하고 있다. 그래서 공유기가 우리 소중한 IP주소를 public ip주소로 변환해준다.이것을 NAT (Network Address Translation)이라 한다. 그럼 변환된 친구는 수많은 라우터를 거쳐 목적지 서버까지 도착하게 된다.이제 아래의 그림을 보자.ARP 구도방식라우팅을 거쳐 구글 서버와 연결된 라우터에 데이터가 도착하면 시스템 A 상황에 온다. 그럼 노란색 말풍선처럼 IP해더가 기록된 구글 서버의 IP주소를 통해 MAC 주소를 얻어오려고 한다. 이때 사용되는 친구가 ARP다. 이 친구는 라우터가 연결된 네트워크로 브로드캐스팅시켜주는 프로토콜이다. 요청을 받은 system B (구글 서버)는 오케이! 너구나 하고 MAC 주소로 응답해준다.이제야 목적지 구글 서버의 MAC 주소를 이해했으니 데이터가 물리적으로 전달될 수 있는 것이다.데이터가 전송되었으니 이제 상호 간의 교류를 할 수 있다. Transport layer 전송계층을 목적지 포트번호를 통해서 이것을 보고 해당 번호에 데이터를 전달해야 주고 Application layer에 다다르면 웹 서버가 사용될 HTTP Request 데이터를 GET 요청을 통해 적절하게 데이터를 얻을 수 있게 된다. # 자주 사용되는 포트번호이러한 HTTP 요청과 응답 과정이 끝나면 연결을 종료해야 하는데 앞서 말한 4 handshaking 가 사용된다. 추가적으로 모든 과정이 끝나도 도착하지 못한 패킷이 있을 수도 있어서 일정 시간 소캣을 열어놓는다. 그런 잉여 패킷을 기다리는 상태를 TIME_WAIT이라 한다." }, { "title": "Java Syntex - hashmap", "url": "/posts/hashmap/", "categories": "Java, Algorithm", "tags": "java, algorithm", "date": "2022-10-12 13:11:04 +0900", "snippet": " Java Collections : Hashmap, linkedHashMap , TreeMap 차이 TreeMap 정렬이 되는데 오름차순이다.   Hashmap LinkedHashMap TreeMap 순서 X O O 정렬 X X O HashMap HashMap 생성 HashMap&lt;String,String&gt; map1 = new HashMap&lt;&gt;();//BasicHashMap&lt;String,String&gt; map2 = new HashMap&lt;&gt;(map1);//map1 복사HashMap&lt;String,String&gt; map3 = new HashMap&lt;&gt;(10);//사이즈 지정HashMap&lt;String,String&gt; map4 = new HashMap&lt;&gt;(10, 0.7f);//사이즈,load factor지정 HashMap 삭제 map.remove(1); //key값 1 제거map.clear(); //모든 값 제거 EntrySet() for (Entry&lt;Integer, String&gt; entry : map.entrySet()) { System.out.println(\"[Key]:\" + entry.getKey() + \" [Value]:\" + entry.getValue());}//IteratorIterator&lt;Entry&lt;Integer, String&gt;&gt; entries = map.entrySet().iterator();while(entries.hasNext()){ Map.Entry&lt;Integer, String&gt; entry = entries.next(); System.out.println(\"[Key]:\" + entry.getKey() + \" [Value]:\" + entry.getValue());} KeySet(), values()도있음 for(Integer i : map.keySet()){ //저장된 key값 확인 System.out.println(\"[Key]:\" + i + \" [Value]:\" + map.get(i));}//IteratorIterator&lt;Integer&gt; keys = map.keySet().iterator();while(keys.hasNext()){ int key = keys.next(); System.out.println(\"[Key]:\" + key + \" [Value]:\" + map.get(key));} getOrDefalut() 찾고자하는 Key가 존재한다면 key의 value값을 반환하고 없으면 default값을 반환한다.key가 중복되면 가지고 있던 값에다가 value값에 덮어쓰겠다.public static void main(String arg[]) { String [] abc = { \"A\", \"B\", \"C\" ,\"C\", \"C\"}; HashMap&lt;String, Integer&gt; hm = new HashMap&lt;&gt;(); for(String key : abc) { \thm.put(key, hm.getOrDefault(key, 0) + 1); } System.out.println(hm); //{A=1, B=1, C=3} } 참고자료 Head First 디자인패턴면접을 위한 CS 전공지식노트" }, { "title": "Basic Confusing Questions Ⅰ 🤷‍♂️ (13개)", "url": "/posts/java-basic-1/", "categories": "CS, Questions", "tags": "cs, questions", "date": "2022-10-07 19:41:57 +0900", "snippet": "Basic Confusing Questions Ⅰ 🤷‍♂️ 클릭하면 정답이 나옵니당~자바의 정석(남궁성 지음)에서 인용한 코드와 내용을 담고 있습니다. 데이터 타입중 기본형과 참조형의 차이 기본형 변수의 실제 데이터를 저장참조형 주소값의 데이터를 저장한다. 자바는 C와 다르게 참조형 변수끼리 연산이 안된다. 클래스와 객체에 대해 설명 객체 : 실제의 사물의 속성과 동작을 가지고 있고 다른것과 식별가능하냐… (붕어빵)클래스: 필드, 메서드, 생성자로 구성되어있는 객체의 설계도 (붕어빵 틀) 메서드 오버라이딩과 메서드 오버로딩의 차이   오버로딩 오버라이딩 메서드 이름 same same 메게변수, 타입 different same 리턴 타입 doesn`t matter smame 오버라이딩 : 상위 메서드에서 사용된 메서드를 자식 클래스에서 다시 호출해서 새로운 형태로 사용하는 행위, 리턴 타입이 동일해야함 부모에게서 상속받은 메소드의 내용과 자식클래스와 맞지않을 경우 자식클래스에서 동일한 메소드를 재정의/*-----------------------------------부모 클래스--------------------------------------*/class Man{ public String name; public int age; public void info(){ System.out.println(\"이 남자의 이름은 \"+name+\", 나이는 \"+age+\"살\"); } }/*----------------------------------자식 클래스---------------------------------------*/class Job extends Man{ String job; public void info() {//부모클래스에 있는 info()메서드를 재정의 super.info(); // 오버라이딩을 위한 super선언 필수 System.out.println(\"이 자의 직업은 \"+job); }}/*-------------------------------------메인 클래스-----------------------------------*/public class OverRidding { public static void main(String[] args) { Job job = new Job(); //Job 객체 생성 //변수 설정 job.name = \"민섭\"; job.age = 30; job.job = \"백엔드\"; job.info(); } } 오버로딩: 같은 이름으로 된 메서드를 매개변수, 타입만 다르게 해서 사용하는 행위 리턴타입 상관없음 하나의 클래스 안의 같은 이름의 메서드를 여러번 정의class Shape { public void area() { // 메서드 오버로딩. 같은 이름의 메서드 4개. System.out.println(\"넓이\"); } public void area(int r) { System.out.println(\"원 넓이 = \" + 3.14 * r * r); } public void area(int w, int l) { System.out.println(\"직사각형 넓이 = \" + w * l); } public void area(double b, double h) { System.out.println(\"삼각형 넓이 = \" + 0.5 * b * h); } jvm 동작 방식 [1] .Java → compiler → .class(바이트 코드) → JVM 코드를 입력하면 JVM머신으로 보내주기전에 Java Compiler에게 소스코드를 검사를 받고 컴파일을 진행한다..java 확장자를 가졌던 코드 → .class 확장자를 가진 java byte code로 변한다. [2] JVM 코드 실행을 위한 메모리 할당을 OS로 부터 받음 (메모리 할당) [3] Class Loader가 바이트코드 파일 → RuntimeData Area로 적재시킴 (자바소스코드 메모리 로드) [4] 로드 완료 후, Execution가 런타임 데이터 영역에 적재된 바이트 코드 실행 (2가지 방식으로 바이트 코드 실행) 4-1. 인터프리터 → 코드를 한줄씩 기계어로 번역하고 실행 4-2. Jit 컴파일러 → just in time complier로 바이트 코드 전부를 기계어로 번역하고 실행 ※ 차이 - 인터프리터를 기본으로 하다가 ‘반복되는 문장이 자주 실행된다’로 판단되면 jit 컴파일러 실행 자바의메모리 영역에 대해 설명 JVM에서 Runtime Data Area를 더 디테일하게 표현한 부분이다. 메서드 영역 (Method Area)클래스 멤버 변수의 이름, 데이터 타입, 접근 제어자 정보와 같은 각종 필드 정보들과 메서드 정보, 데이터 Type 정보, Constant Pool, static변수, final class 등이 생성되는 영역이다. 힙 영역(Heap Area)JVM에는 하나의 heap영역만 존재함. 객체, 인스턴스 변수, 배열이되는 영역이다가비지컬랙션이 주기적으로 활동하는 영역이다 스택 영역 (Stack Area)지역변수, 파라미터, 리턴 값, 연산에 사용되는 임시 값 등이 생성되는 영역이다 PC 레지스터 (PC Register)Thread가 생성될 때마다 생성되는 영역으로 프로그램 카운터, 즉 현재 스레드가 실행되는 부분의 주소와 명령을 저장하고 있는 영역이다 네이티브 메서드 스택 (Native Method Stack)JVM에서 C와 같은 Java 언어 이외의 네이티브 메서드를 지원하기 위해 사용하는 스택 구조의 메모리 영역이다 ※ 자바 이외의 언어(C++, 어셈블리 등)로 작성된 네이티브 코드를 실행할 때 사용되는 메모리 영역으로 일반적인 C 스택을 사용한다고 함. static, final 키워드에 대해 설명하고 언제 사용해야하는지 static = 공통적인 의 의미를 지니고 있다. 인스턴스에 상관없이 하나의 변수를 모든 인스턴스가 공유하기 떄문이다. final = 변경될수 없는의 의미를 지니고있다. 변수에 이용되면 상수가 되고, 메서드에 사용되면 오버라이딩이 불가능하며, 클래스에서 사용된다면 자손클래스를 정의할 수 없다. static 초기화 블럭은 클래스가 메모리에 로드될 때, 단 한번만 수행됨. //static 변수static int width = 200;&gt; 모든 인스턴스에 공통적으로 사용되는 클래스 변수가 됨&gt; 클래스변수는 인스턴스를 생성하지않아도 사용가능&gt; 클래스 메모리에 로드될때 생성//static 메서드public static Method(){ ...}&gt; 인스턴스를 생성하지 않고도 호출이 가능한 static 메서드가 된다.&gt; static 메서드 내에 인스턴스맴버들을 직접 사용 할 수 없다. final class Final{ //조상이 될 수 없는 클래스 final int MAX_SIZE = 10; //값을 변경할 수 없는 상수 final void getSize(){ //오버라이딩 불가능한 메서드 final int LV = MAX_SIZE;//값 변경이 안되는 지역변수 return MAX_SIZE; }} OOP 장단점과 설명 절차 지향 대신 왜 우린 객체지향 프로그래밍을 하는 것인가? 절차 지향은 말처럼 순차적인 처리가 중요시하는 프로그램이다. 대표적으로는 C언어가 있다.컴퓨터의 일처리 방식과 유사해 실행 속도가 빠르다.하지만 리팩터링, 디버깅의 어려움, 순서가 바뀌면 결과가 바뀌는 등 단점이 많아서 나온 이론이 객체지향이다. 객체지향은... 실제 존재하는것과 객체들 간 상호작용을 컴퓨터 프로그래밍을 통해 구현하고자 함또한 이렇게 프로그램을 작성한다면 재사용성, 유지보수 용이, 중복 코드 감소 효과가 나타남. 단점으로는 설계에 많은 시간과 절차지향언어에 비해 상대적으로 실행속도가 느리다. 캡.상.추.다! 상속 (inherutance) = 확장과 분류용이, 중복코드 제거, 재사용성↑ 기존의 클래스를 기반으로 새로운 클래스를 작성 (a.k.a 자식 클래스가 부모 클래스의 특징과 기능을 따라 받는 것) 다중 상속 안됨 extends 키워드 사용 캡슐화 (encaspulation) = 데이터 보호와 은닉 속성(변수)과 기능(메서드)을 하나로 묶어서, public, private 같은 접근 지정자를 통해 제어하는 방법. getter/setter 사용 높은 응집도(Cohension) 낮은 결합도(Coupling)를 유지할 수 있도록 해주는 설계 방식 다형성 (polymorphism) = 오버 라이딩… 상위 클래스가 같은 메서드로 하위 클래스들을 서로 다르게 동작시킬 수 있다. 부모 클래스가 자식 클래스의 동작 방식을 알 수 없어도 오버 라이딩을 통해 자식 클래스를 접근할 수 있습니다. 상위 클래스 타입의 참조 변수로 하위 클래스 객체를 참조 (반대로 참조하는 경우는 안됨) 유지보수가 쉽고 재사용성이 좋고 결합이 느슨하도록 유지하는 방식 ex) SportCar() -&gt; Car() 일 경우 Car car = new car();SportCar Scar = new SportCar();Car Scar = new SportCar(); //가능SportCar Scar = new Car(); //불가능 추상화(Abstraction) = 공통된 특징을 하나의 개념화 abstract 키워드를 사용 공통된 특징인 만큼 반드시 사용되어야 하는 메서드를 선언해서 추상 클래스를 상속받는 모든 클래스들은 추상 메소드를 재정의 해야 함 다중 상속 불가능. 객체 생성 불가능 접근제어자의 특징과 종류에 대해서 설명 public: 접근 제한이 없다.default: 같은 패키지 내에서 접근 가능하다.protected: 같은 패키지와 다른 패키지의 자손클래스에서 접근이 된다.private: 같은 클래스 내에서만 접근이 가능하다. 추상 클래스와 인터페이스의 차이 추상클래스는 IS - A “~이다”. (다중상속 X)인터페이스는 HAS - A “~을 할 수 있는 (다중상속 O) 추상화(Abstraction) = 공통된 특징을 하나의 개념화 abstract 키워드를 사용 공통된 특징인 만큼 반드시 사용되어야 하는 메서드를 선언해서 추상 클래스를 상속받는 모든 클래스들은 추상 메소드를 재정의 해야 함 다중 상속 불가능. 객체 생성 불가능 인터페이스 (interface) = 역할과 구현의 구분 implements 키워드 사용 *상속보단 구현 모든 기능을 추상화로 정의만 하고 클래스 내에서 구현은 하지 않은 것. (미리 정해진 규칙에 맞게 구현하도록 표준을 제시) 인터페이스와 추상화의 차이점 - 기본 설계도와 미완성 설계도 추상클래스는 인스턴스 생성보다는 상속을 목적으로 하는 반면 인터페이스는 주로 제공할 기능을 정의하는 데 사용.추상클래스는 생성자 필드 일반, 추상 메서드를 포함할수있는 반면 인터페이스는 상수와 추상 메소드만 포함 할수 있다. 추상 클래스는 자신의 기능들을 하위 클래스로 확장 -&gt; 메서드를 자신 특징에 맞게 확장해서 사용, 변숫값 지정 없이 상황에 맞게끔 사용하면 된다. 인터페이스에 정의된 메소드를 각 클래스의 목적에 맞게 기능을 구현 -&gt; 클래스를 감싸서 직접적인 클래스 간의 종속관계를 벗어나게 해 줌 (독립성 확보) 이것은 유지보수에 있어서 유리함 또한 변숫값을 사용하려면 고정값을 줘야 함 이너클래스와 익명클래스, 장단점 내부 클래스는 클래스 내에 선언된 클래스이다.하나의 클래스를 다른 클래스의 내부 클래스로 선언하면 두 클래스의 맴버들간에 서로 쉽게 접근 할 수 있다는 점과외부의 불필요한 클래스를 감춤으로써 코드의 복잡성을 줄일수있다 -&gt; 캡슐화. class A{}class B{}----class A{ class B{ //내부 클래스 B }} 익명클래스: 이름이 없고, 클래스 선언과 동시에 객체를 생하기에 한번만 사용가능하며,오직 하나의 객체만을생성 할 수있는 일회용 클래스다시사용하지않는다고 하면 클래스를 만드는것보단 좋다. 득보다 실이 커보인다. 컬랙션과 스트림의 차이 설명 컬렉션과 배열의 차이는 메모리를 정적할당하냐 동적할당하냐의 차이이다. 컬렉션은 배열이 가장 기본적인 자료구조이며, DTO 또한 자료를 담는 하나의 방식 스트림은 선언형 코드로써 간결하고 가독성이 올라감. 어떻게 처리할 것인가 보단 무엇을 처리할지에 포커싱 데이터의 처리시점이 다르다. 컬렉션은 필요한 모든값이 계산되어 자료구조에 담겨야한다. 즉 저장하기 전에 모든 요소가 계산되어야 한다. 반면, 스트림은 데이터를 요청할 때만 계산함. 한번 소비하면 재사용이 되냐 안되냐컬렉션은 재사용이 가능하나 스트림은 한번 소비되면 재사용이 안된다. 컬렉션은 '외부반복', 스트림은 '내부반복'컬렉션을 반복하려면 iterator나 for를 써서 요소를 반복해야한다. 이를 외부반복이라 함스트림은 내부적으로 알아서 반복해서 결과를 알려준다. filter, map등의 연산 메소드에서는 반복이 내부적으로 숨겨져있고 추상화되어있다. 또한, 내부반복은 병렬성의 이점이 있다. 외부 반복을 사용하면 병렬성을 스스로 관리해야 한다. 병렬성을 스스로 관리한다는 것은 동기화 문제가 일어날 수 있는 부분들을 개발자가 신경써서 관리해야 한다는 말이다. 미처 파악하지 못한 사소한 이유로 문제가 발생할 가능성을 증가시킨다. parallel() 함수를 통해 병렬 처리를 지원하는데 이 때 병렬성 구현을 자동으로 선택해서 실행해준다. 스트림은 Java를 만든 개발자들에 의해 만들어졌다. Java의 내부 동작을 깊이있게 알고 있는 프로그래머들에 의해 만들어져 신뢰할 수 있다. 우리는 숨겨지고 추상화된 병렬 처리를 공개 API를 통해 간단히 사용할 수 있는 것이다. 물론 스트림이 내부적으로 사용하는 ForkJoin 프레임워크에 대한 이해와 병렬 연산을 올바르게 사용하기 위한 지식이 필요한건 물론이다. ※fork-join 프레임워크는 태스크(Task)를 재귀적으로 여러 개의 작은 작업 단위로 분할(fork)하여 처리한다. 처리된 서브 태스크들의 결과를 합쳐 전체 결과로 합친다(join). 참고 블로그 list ,set, map 차이점 List는 기본적으로 데이터들이 순서대로 저장되며 중복을 허용한다. Map은 순서가 보장되지 않고 Key값의 중복은 허용하지 않지만 Value값의 중복은 허용된다. Set은 순서가 보장되지 않고 데이터들의 중복을 허용하지 않는다. 제네릭에 대해서 설명하고 컬렉션 클래스에서 왜 제네릭을 사용하는지?\t 다양한 타입의 객체들을 다루는 메서드나 컬랙션 클래스에 컴파일 시 타입 체크를 해주는 기능. 타입의 안정성을 주고 타입체크와 형변환을 생략할 수 있어 코드가 간결해짐 " }, { "title": "상습적으로 틀리는 알고리즘 Hashmap", "url": "/posts/record-al/", "categories": "Note, Algorithm", "tags": "note, hashmap", "date": "2022-10-06 09:41:57 +0900", "snippet": "내가 자주 틀리는 알고리즘 유형 정리 🤷‍♂️ Hash, sliding window : 시간복잡도 O(n)key point는 pointer 개념을 이용해서 풀어야한다. 초기값 세팅시 -1 만큼 map에 저장 방향 lp, rp 개념을 이용하기 String에 저장하기보단 동적 메모리 arraylist를 쓰자. Map&lt;Character, Integer&gt; map = new HashMap&lt;&gt;(); Map&lt;Character, Integer&gt; compare = new HashMap&lt;&gt;(); int counter = 0; //초기값 세팅 for (int i = 0 ; i &lt; word.length() ; i++){ map.put(word.charAt(i), map.getOrDefault(word.charAt(i),0)+1); compare.put(str.charAt(i), compare.getOrDefault(str.charAt(i), 0) + 1); } compare.put(str.charAt(word.length() - 1), compare.getOrDefault(str.charAt(word.length() - 1),0)-1); int lp = 0; // 왼쪽 좌표 for (int rp = word.length() - 1; rp &lt; str.length(); rp++) { char Rchar = str.charAt(rp); char Lchar = str.charAt(lp); compare.put(Rchar, compare.getOrDefault(Rchar,0)+1); //rp 한칸 전진 if(map.equals(compare)) counter++; compare.put(Lchar, compare.getOrDefault(Lchar,0)- 1); //왼쪽 값 삭제 if(compare.get(Lchar)==0) compare.remove(Lchar); lp++; } System.out.println(counter); 재귀함수 메모이제이션import java.io.*;import java.util.*;public class Main { static int[] fibo; private static int solution(int i) { if(fibo[i]&gt;0) return fibo[i]; // 메모이제이션 포인트 //어차피 배열은 0으로 세팅되어있는데 값이 바뀌면 계산해놓은걸 참고해서 쓰면 좋지않은가 if (i == 1) return fibo[i] = 1; else if (i == 2) return fibo[i] = 1; else return fibo[i] = solution(i - 2) + solution(i - 1); } public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int i = Integer.parseInt(br.readLine()); fibo = new int[i + 1]; solution(i); for (int x = 1 ; x &lt; fibo.length ; x++) System.out.printf(fibo[x]+\" \"); }}" }, { "title": "[Spring] @Component와 @Configuration", "url": "/posts/spring-1/", "categories": "Component", "tags": "java, spring", "date": "2022-09-30 11:41:57 +0900", "snippet": " @Configuration의 선언부를 보면 @Component가 정의되어 있다. @Component는 개발자가 작성한 클래스를 Bean으로 등록하고자 할 때 사용한다.개발자가 직접 제어 가능 : @Component개발자가 직접 제어 불가능 : @Configuration, @Bean{. :prompt-tip}@Component 개발자가 직접 작성한 클래스를 Bean으로 등록할때 사용하는 어노테이션 @Controller, @Service, @Repository 등의 어노테이션에서 상속받아 사용 @Componentpublic class MyComponent{ //내가 직접 작성한 클래스} @Configuration 외부 라이브러리 또는 내장 클래스를 Bean으로 등록하고자 할 경우 사용한다. 1개 이상의 @Bean을 제공하는 클래스의 경우 반드시 @Configuration을 사용한다.즉, 해당 클래스에서 한 개 이상의 Bean을 생성하고 있을때 선언한다.//시큐어리티 중 일부@Configuration@EnableWebSecuritypublic class SecurityConfig extends WebSecurityConfigurerAdapter { @Bean\tpublic PasswordEncoder passwordEncoder() { \treturn new BCryptPasswordEncoder();\t}}" }, { "title": "[Spring] Annotation", "url": "/posts/annotation/", "categories": "annotation", "tags": "java, spring", "date": "2022-09-27 15:41:57 +0900", "snippet": "Spring AnnotationAnnotation이란? 소스코드에 제공되는 메타데이터이다. 앱이 처리하는 데이터가 아닌 컴파일 과정,실행 과정에서 코드를 어떻게 처리해야 하는지 알려주는 용도로 사용된다.어노테이션에는 크게 2가지가 있다. built-in 어노테이션 Java 코드에 적용되는 어노테이션 @Override, @Deprecated, @SuppressWarnings 등… meta 어노테이션 다른 어노테이션에 적용되기 위한 어노테이션 @Retention, @Documneted, @Target, @Inherited, @Repeatable 등이 중에 나는 meta 어노테이션인, 개발자가 직접 작성한 클래스를 Bean으로 등록할때 사용하는 어노테이션인 @Component의 특징을 보자@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Indexedpublic @interface Component { String value() default \"\";}위처럼 Component에는 @Target, @Rentetion, @Documneted, @Indexed 가 있다.차례대로 설명해보겠다.@Target어노테이션을 작성할 곳이다. default값은 모든 대상이다. 만약 구체적으로 지정한다면 다른부분에서 적용시 에러가 난다. ElementType.??? ??? 호출 시 사용하겠다 ElementType.TYPE (class, interface, enum) ElementType.FIELD (instance variable) ElementType.METHOD ElementType.PARAMETER ElementType.CONSTRUCTOR ElementType.LOCAL_VARIABLE ElementType.ANNOTATION_TYPE (on another annotation) ElementType.PACKAGE (remember package-info.java)이런식으로 다양한 종류가 있다.@Retention리텐션은 보유를 의미하는 뜻으로 어노테이션의 지속시간, 얼마나 보유할지에 대한 설정을 하는 설정이다. RetentionPolicy.CLASS : default 값 입니다. 컴파일 타임 때만 .class 파일에 존재하고, 런타임 때는 없어진다. 바이트 코드 레벨에서 어떤 작업을 해야할 때 유용하다. Reflection 사용이 불가능. RetentionPolicy.SOURCE : 컴파일 후에 정보들이 사라진다. 이 어노테이션은 컴파일이 완료된 후에는 의미가 없어진다.그러기에 바이트 코드에 기록되지 않는다. 예시로는 @Override와 @SuppressWarnings 어노테이션이 있다. RetentionPlicy.RUNTIME : 이 어노테이션은 런타임시에도 .class 파일에 존재한다. 커스텀 어노테이션을 만들 때 주로 사용한다. Reflection 사용 가능이 가능@DocumentedJava doc에 문서화 여부를 결정한다.@Indexed해당 주석이 달린 요소가 인덱스에 대한 스테레오타입임을 나타내고 이 타입 기반으로 후보구성요소 (ex: 정규화된 이름)을 검색할 수 있다.@Inherited해당 어노테이션을 하위 클래스에 적용한다.커스텀 어노테이션간단하게 AOP를 위해 만든 실제 어노테이션을 이용한 예를 들겠다.그 전에, 커스텀 어노테이션을 만들떄는 몇가지 규칙이 있다. Annotation 타입은 java.lang.Annotation 인터페이스를 상속받기 떄문에 @interface로 정의해야한다. 파라미터 맴버들의 접근자는 public or Default여야한다. 파라미터 멤버들은 byte,short,char,int,float,double,boolean의 기본타입과 String, Enum, Class 어노테이션만 사용할 수 있다. 클래스 메소드와 필드에 관한 어노테이션 정보를 얻고 싶으면, 리플렉션만 이용해서 얻을 수 있다. 다른 방법으로는 어노테이션 객체를 얻을 수 없다.@Target(ElementType.METHOD)//메소드 호출시 사용하겠다@Retention(RetentionPolicy.RUNTIME) //런타임시 유지되도록하겠다public @interface NeedEmail {}해당 어노테이션은 메소드 호출시 사용되고 런타임 환경에서는 꾸준히 기능을 사용하겠다는 뜻이다.출처docs.spring.io" }, { "title": "Transaction, Normalization", "url": "/posts/transaction/", "categories": "SQL, transaction", "tags": "sql, transaction", "date": "2022-09-23 10:41:57 +0900", "snippet": "트랜잭션이란? 성공, 실패 두결과만 존재한다.트랜잭션은 여러개의 작업을 하나로 묶은 실행 유닛이다.각 트랜잭션은 하나의 특정 작업으로 시작을 해 묶여 있는 모든 작업들을 다 완료해야 정상적으로 종료된다. 여러개의 작업 중 단 하나의 작업을 실패하면 실패한 트랜잭션이라는 소리다.(롤백) 아래의 코드가 롤백과 커밋을 나타낸 예이다.public class Main { public static void main(String[] args) { EntityManagerFactory emf = Persistence.createEntityManagerFactory(\"test\"); EntityManager em = emf.createEntityManager(); // 엔티티매니저 EntityTransaction tx = em.getTransaction(); //트랜젝션의 시작 tx.begin(); try { //저장할 데이터~~ Member member = new Member(); member.setId(1L); member.setName(\"Student A\"); em.persist(member); // 저장 tx.commit(); //커밋 } catch (Exception e) { tx.rollback(); // 문제 발생시 롤백 } finally { em.close(); //트랜잭션 종료 } emf.close(); //엔티니매니저 종류 }}ACIDACID는 데이터베이스 내에서 일어나는 하나의 트랜잭션(transaction)의 안전성을 보장하기 위해 필요한 성질이다.Atomicity(원자성)원자성은 하나의 트랜잭션에 속해있는 모든 작업이 전부 성공하거나 전부 실패해서 결과를 예측할 수 있어야 한다. 예를 들어 계좌이체를 할 때에는… A 계좌에서 출금합니다.B 계좌에 입금합니다.계좌이체를 하려는데 A 계좌에서는 출금이 이뤄지고, B 계좌에 입금되지 않았다고 가정해보자. 어디서 문제가 발생했는지 파악할 수 없다면, A 계좌에서 출금된 돈은 세상에서 사라지는 돈이 된다. 만약 은행에서 이런 일이 발생한다면, 그 은행은 문을 닫아야한다. A 계좌에서 출금하는 일에 성공했지만, B 계좌에 입금하는 작업에 실패한다면 계좌 A에서 출금하는 작업을 포함하여 모든 작업이 실패로 돌아가야 한다는 것이 Atomicity(원자성)SQL에서도 마찬가지이다. 특정 쿼리를 실행했는데 부분적으로 실패하는 부분이 있으면, 전부 실패하도록 구현되어 있다. 때때로 충돌 요인에 대해서 선택지를 제공한다.Consistency(일관성)데이터베이스의 상태가 일관되어야 한다는 성질이다. 하나의 트랜잭션 이전과 이후, 데이터베이스의 상태는 이전과 같이 유효해야 한다. 다시 말해, 트랜잭션이 일어난 이후의 데이터베이스는 데이터베이스의 제약이나 규칙을 만족해야한다.예를 들어 ‘모든 고객은 반드시 이름을 가지고 있어야 한다’는 데이터베이스의 제약이 있다고 가정해보자. 그러면 다음과 같은 트랜잭션은 Consistency(일관성)를 위반한다. 이름 없는 새로운 고객을 추가하는 쿼리기존 고객의 이름을 삭제하는 쿼리데이터베이스의 유효한 상태는 다를수 있지만, 데이터의 상태에 대한 일관성은 변하지 않아야한다. 이 예시는 ‘이름이 있어야 한다’ 라는 제약을 위반한다. 따라서 예시처럼 트랜잭션이 일어난 이후의 데이터베이스는 일관되지 않는 상태를 가지게 된다.Isolation(격리성, 고립성)Isolation(격리성) 은 모든 트랜잭션은 다른 트랜잭션으로부터 독립되어야 한다.실제로 동시에 여러 개의 트랜잭션들이 수행될 때, 각 트랜젝션은 고립(격리)되어 있어 연속으로 실행된 것과 동일한 결과를 나타낸다. A에게 계좌에 만원이 있는 상태A 계좌로부터 계좌 B로 6천 원을, 계좌 C로 6천 원을 동시에 계좌 이체하는 경우, 계좌 B에 먼저 송금한 뒤 계좌 C에 보내는 결과와 동일한다.동시에 트랜잭션을 실행한다고 해서 계좌 B와 C에 각각 6천 원씩 송금하여 마이너스 통장이 되는 것이 아니다. 각각의 송금 작업을 연속으로 실행하는 것과 동일한 결과가 나타나야 한다. 격리성을 지키는 각 트랜젝션은 철저히 독립적이기 때문에, 다른 트랜젝션의 작업 내용을 알 수 없어야 하고 데이터베이스 상태가 동일해야 한다.Durability(지속성)Durability(지속성)는 하나의 트랜잭션이 성공적으로 수행되었다면, 해당 트랜잭션에 대한 로그가 남아야 한다. 만약 런타임 오류나 시스템 오류가 발생하더라도, 해당 기록은 영구적으로 남아야한다.은행에서 게좌이체를 성공적으로 실행한 뒤에, 해당 은행 데이터베이스에 오류가 발생해 종료되더라도 계좌이체 내역은 기록으로 남아야한다.마찬가지로 계좌이체를 로그로 기록하기 전에 시스템 오류 등에 의해 종료가 된다면, 해당 이체 내역은 실패로 돌아가고 각 계좌들은 계좌이체 이전 상태들로 돌아가게 된다.데이터베이스 정규화정규화(Normalization)의 기본 목표는 테이블 간에 중복된 데이터를 허용하지 않는다는 것이다. 중복된 데이터를 허용하지 않음으로써 무결성(Integrity)를 유지할 수 있으며, DB의 저장 용량 역시 줄일 수 있다. 이를 지키지 않았을떄 어떤 문제점이 생기는지 나열해보겠다.Data Redundancy데이터 중복 (data redundancy) 는 실제 데이터의 동일한 복사본이나 부분적인 복사본을 뜻한다.물론 이러한 중복성으로 데이터를 복구할 때에 더 수월할 수도 있겠지만 데이터베이스 내에서는 몇가지 문제점들을 대체로 지닌다. 일관된 자료 처리의 어려움 저장 공간 낭비 데이터 효율성 감소Data Integrity데이터 무결성 (data integrity) 는 데이터의 수명 주기 동안 정확성과 일관성을 유지하는 것을 뜻한다.즉, 입력된 데이터가 오염되지 않고 입력된 그대로 데이터를 사용할 수 있다는 뜻이다.Anomaly데이터 이상 현상 (anomaly) 와 같은 경우에는 데이터에서 기대한 것과 다른 이상 현상을 가리킨다.Update Anomaly갱신 이상 (update anomaly) 는 동일한 데이터가 여러 행 (레코드) 에 걸쳐 있을 때에 어느 데이터를 갱신해야 하는지에 대한 논리적 일관성이 없어 발생하게 되는 경우다. 사원ID 사원주소 스킬스택 123 강남구 대치동 파이썬 123 강남구 대치동 C++ 321 강남구 도곡동 자바 321 강원도 양양시 C 다음과 같은 테이블이 존재하고 두 개의 레코드가 동일한 사람일 때에 (321번) 갱신을 하게 되는 경우 어떤 데이터를 해야 하는지에 대한 문제가 발생한다.Insertion Anomaly삽입 이상 (insertion anomaly) 는 데이터 삽입을 못하는 경우를 가리킨다.|사원ID|사원이름|배정받은 부서||—|—|—||123|아무개|홍보||321|김철수|기획||213|이영희|개발|갈곳 없음↓ |654|홍길동| | |—|—|—|다음과 같은 경우 새로운 직원이 들어왔을 때에 (홍길동) 아직 가르칠 부서가 정해지지 않은 경우에는 데이터에 추가되지 못하게 된다. (이럴 경우 NULL값으로 삽입하면 된다.)Deletion Anomaly삭제 이상 (deletion anomaly) 와 같은 경우에는 데이터의 특정 부분을 지울 때에 의도치 않게 다른 부분들도 함께 지워지는 이상 현상이다.예를들어 한 직원 데이터의 수업 관련 데이터를 지우기 위해서는 레코드 전체가 사라져서 결국에는 의도치 않게 직원의 다른 데이터들도 같이 삭제되는 현상이 발생하게 되는 경우다." } ]
